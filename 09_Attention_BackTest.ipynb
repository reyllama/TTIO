{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_Attention_BackTest.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN/v0850FYi2Mo5ZYgFO7za",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reyllama/TTIO/blob/master/09_Attention_BackTest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FksDzFak6KCX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "aa6eec0c-7acc-4027-ac44-6c529850230b"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from google.colab import drive\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnf_-5wW6RLz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6f0cc208-35bd-4258-d6a9-fd05d6040bfe"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/core_stocks.csv\", dtype={'stock_id': str})\n",
        "data['stock_id'] = data['stock_id'].astype(str)\n",
        "print(data.shape[0]//979)\n",
        "df = pd.read_csv('/content/drive/My Drive/corr1.csv')\n",
        "df = df.set_index(keys='stock_id')\n",
        "df.columns = df.columns.astype(str)\n",
        "df.index = df.index.astype(str)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1586\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdGNfj9Z68az",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(corr_df=None, n_epochs=100, emb_dim=32, lr=0.01, silent=False):\n",
        "  dtype = torch.FloatTensor\n",
        "  epochs = n_epochs\n",
        "  embeddings = Variable(torch.randn(emb_dim, len(corr_df)).type(dtype), requires_grad=True) # Initialize with Standard Gaussian\n",
        "  optimizer = optim.Adam([embeddings], lr=lr)\n",
        "  mean = np.abs(corr_df).mean().mean()\n",
        "  coef = 1/mean # Hyper Parameter\n",
        "  loss_track = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    loss = 0\n",
        "    for i in range(len(corr_df)):\n",
        "      v1 = embeddings[:, i].view(emb_dim, -1)\n",
        "      dist = torch.norm(v1 - embeddings, dim=0).view(len(corr_df), 1)\n",
        "      corrs = torch.from_numpy(np.abs(coef*np.array(corr_df.iloc[:, i]))-1).view(1, len(corr_df)).type(torch.FloatTensor)\n",
        "    #   corrs = torch.from_numpy(np.array(df.iloc[:, i])).view(1, len(df)).type(torch.FloatTensor) # rho 교수님 버전\n",
        "      loss += torch.mm(corrs, dist)/2\n",
        "\n",
        "    #   v1 = embeddings[:, i].view(-1, emb_dim)\n",
        "    #   mm = torch.mm(v1, embeddings)\n",
        "    #   mm[:, i] = torch.zeros(1) # 자기 자신과의 dot product은 0으로 만들어줌. 그렇지 않으면 각각이 다 0 벡터가 될 우려\n",
        "    #   corrs = torch.from_numpy(coef*np.array(df.iloc[:, i])).view(len(df), 1).type(torch.FloatTensor)\n",
        "    #   loss += torch.mm(mm, corrs)\n",
        "\n",
        "    loss_track.append(loss.item())\n",
        "    if not silent:\n",
        "        if (epoch+1) % 20 == 0:\n",
        "            print(\"{0}th epoch in process\".format(epoch+1))\n",
        "            print('running loss: {}'.format(loss.item()))\n",
        "            print()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for element in embeddings:\n",
        "        element.clamp_(0,1)\n",
        "\n",
        "  return embeddings"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivwTmGX-6_01",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_preparer(n=1, n_epochs=100, lr=0.05, silent=False, corr=True):\n",
        "    if corr:\n",
        "        path = \"/content/drive/My Drive/corr{0}.csv\".format(n)\n",
        "    if not corr:\n",
        "        path = \"/content/drive/My Drive/cov{0}.csv\".format(n)\n",
        "    df = pd.read_csv(path)\n",
        "    df = df.set_index(keys='stock_id')\n",
        "    df.columns = df.columns.astype(str)\n",
        "    df.index = df.index.astype(str)\n",
        "\n",
        "    if n==1:\n",
        "        st, ed = 1, 121\n",
        "    elif n==2:\n",
        "        st, ed = 62, 186\n",
        "    elif n==3:\n",
        "        st, ed=124,248\n",
        "    elif n==4:\n",
        "        st, ed=186,310\n",
        "    elif n==5:\n",
        "        st, ed=248, 368\n",
        "    elif n==6:\n",
        "        st, ed=310, 432\n",
        "    elif n==7:\n",
        "        st, ed=368,489\n",
        "    elif n==8:\n",
        "        st, ed=432, 550\n",
        "    else:\n",
        "        print(\"Too Big A Number\")\n",
        "        return None\n",
        "\n",
        "    embeddings = get_embeddings(corr_df=df, n_epochs=n_epochs, lr=lr, silent=silent)\n",
        "\n",
        "    return df, embeddings, st, ed"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGHOAe1F7AgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a1198aba-e248-41a5-facf-d82c3c82f01b"
      },
      "source": [
        "!pip install ta\n",
        "import ta\n",
        "\n",
        "def bias(close=None, m=7):\n",
        "  return close - close.rolling(m).mean()\n",
        "\n",
        "def preprocessing(data=data, start=125, end=125+62, corr_df = None):\n",
        "\n",
        "  data['stock_id'] = data['stock_id'].astype(str)\n",
        "  data['year'] = data['date'].apply(lambda x: int(x[0:4]))\n",
        "  data['month'] = data['date'].apply(lambda x: int(x[5:7]))\n",
        "\n",
        "  data = data[(data['date_index']<=end)&(data['date_index']>=start)]\n",
        "  data = data[data['stock_id'].isin(df.columns)]\n",
        "\n",
        "  data['KLength'] = data['closing_price'] - data['opening_price']\n",
        "  data['KUpperLength'] = data['highest_price'] - data[['opening_price', 'closing_price']].max(axis=1)\n",
        "  data['temp'] = data['opening_price']-data['lowest_price']\n",
        "  data['KLowerLength'] = data[['closing_price', 'temp']].min(axis=1)\n",
        "  data['EMA'] = ta.trend.ema_indicator(close=data['closing_price'])\n",
        "  data['MACD'] = ta.trend.macd(close=data['closing_price'])\n",
        "  data['ROC'] = ta.momentum.roc(close=data['closing_price'])\n",
        "  data['BIAS'] = bias(data['closing_price'])\n",
        "  data['return'] = data['closing_price'].diff()\n",
        "  data = data.drop(columns=['temp'])\n",
        "\n",
        "  \n",
        "  \n",
        "\n",
        "  return data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ta\n",
            "  Downloading https://files.pythonhosted.org/packages/90/ec/e4f5aea8c7f0f55f92b52ffbafa389ea82f3a10d9cab2760e40af34c5b3f/ta-0.5.25.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ta) (1.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->ta) (1.12.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.5.25-cp36-none-any.whl size=24880 sha256=afce9f943cc92ca1bbb5f40df3a824a085130ee710e47e9f010b5c86cbe31908\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/93/b7/cf649194508e53cee4145ffb949e9f26877a5a8dd12db9ed5b\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.5.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6JBnLIX7BqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attention_optimize(train_data=None, valid_data=None, lr=0.02, n_epochs=20, embeddings=None, silent=False):\n",
        "\n",
        "    tdmin = train_data['date_index'].min()\n",
        "    tdmax = train_data['date_index'].max()\n",
        "    vdmin = valid_data['date_index'].min()\n",
        "    vdmax = valid_data['date_index'].max()\n",
        "    train = train_data[train_data['date_index']>=tdmin+25]\n",
        "    valid = valid_data[valid_data['date_index']>=vdmin]\n",
        "    train_data = train[['stock_id', 'date_index', 'EMA', 'MACD', 'KLength', 'KUpperLength', 'KLowerLength', 'ROC', 'BIAS']].melt(id_vars=['stock_id', 'date_index'], var_name='indicator', value_name='indicator_values')\n",
        "    valid_data = valid[['stock_id', 'date_index', 'EMA', 'MACD', 'KLength', 'KUpperLength', 'KLowerLength', 'ROC', 'BIAS']].melt(id_vars=['stock_id', 'date_index'], var_name='indicator', value_name='indicator_values')\n",
        "\n",
        "    dtype = torch.FloatTensor\n",
        "    weights = Variable(torch.randn(7, 32).type(dtype), requires_grad=True) # 7: num_indicators, 32: dim_embeddings\n",
        "    optimizer = optim.Adam([weights], lr=lr)\n",
        "    base_loss = np.Inf\n",
        "\n",
        "    retur = np.array(train[train['date_index']>=tdmin+26].pivot(index='date_index', columns='stock_id', values='return')) # (days-1) x 1586\n",
        "    v_retur = np.array(valid[valid['date_index']>=vdmin+1].pivot(index='date_index', columns='stock_id', values='return')) # (days-1) x 1586\n",
        "    final_factor = None\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        weighted_indicator = None\n",
        "        v_weighted_indicator = None\n",
        "\n",
        "        # C = torch.mm(weights, embeddings) # 7 x 1586, dot-product attention\n",
        "        C = torch.mm(weights, embeddings)/torch.sqrt(torch.FloatTensor([32])) # 7 x 1586, scaled dot-product attention\n",
        "        C = F.softmax(C, dim=0)           # 7 x 1586, columnwise softmax\n",
        "\n",
        "        for day in range(tdmin+25, tdmax):\n",
        "            indic = np.array(train_data[train_data['date_index']==day].pivot(index='indicator', columns='stock_id', values='indicator_values')) # 7 x 1586\n",
        "            rescaled_I = torch.sum(C*torch.from_numpy(indic), axis=0).view(1, 1586) # 1 x 1586, elementwise\n",
        "            if weighted_indicator == None:\n",
        "                weighted_indicator = rescaled_I\n",
        "            else:\n",
        "                weighted_indicator = torch.cat((weighted_indicator, rescaled_I), dim=0)\n",
        "        vx = torch.from_numpy(retur) - torch.mean(torch.from_numpy(retur), axis=0) \n",
        "        vy = weighted_indicator - torch.mean(weighted_indicator, axis=0) \n",
        "        # loss = -torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2))) # 1st Loss\n",
        "        # loss = -torch.abs(torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))) # 2nd Loss\n",
        "        loss = -torch.sum(vx * vy) / 1586 # 3rd loss, covariance-like loss\n",
        "\n",
        "        if not silent:\n",
        "            if (epoch+1) % 100 == 0:\n",
        "                print(\"{0}th epoch in process, loss: {1:.2f}\".format(epoch+1, loss))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for day in range(vdmin, vdmax):\n",
        "                indic = np.array(valid_data[valid_data['date_index']==day].pivot(index='indicator', columns='stock_id', values='indicator_values')) # 7 x 1586\n",
        "                rescaled_I = torch.sum(C.detach()*torch.from_numpy(indic), axis=0).view(1, 1586) # 1 x 1586\n",
        "                if v_weighted_indicator == None:\n",
        "                    v_weighted_indicator = rescaled_I\n",
        "                else:\n",
        "                    v_weighted_indicator = torch.cat((v_weighted_indicator, rescaled_I), dim=0)     \n",
        "\n",
        "            ux = torch.from_numpy(v_retur) - torch.mean(torch.from_numpy(v_retur), axis=0)\n",
        "            uy = v_weighted_indicator - torch.mean(v_weighted_indicator, axis=0)\n",
        "            v_loss = (-torch.abs(torch.sum(ux * uy) / (torch.sqrt(torch.sum(ux ** 2)) * torch.sqrt(torch.sum(uy ** 2))))).detach().numpy()\n",
        "\n",
        "            if v_loss < base_loss:\n",
        "                base_loss = v_loss\n",
        "                final_factor = C\n",
        "\n",
        "    if final_factor == None:\n",
        "        print('Something is wrong')\n",
        "    return final_factor"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEYc2yqYaPys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attention_topK(data=None, corr_df=None, start=None, end=None, window=62, embeddings=None, e=20):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    first_term = preprocessing(data=data, corr_df=corr_df, start=start, end=end+2*window)\n",
        "    train_df = first_term[(first_term['date_index']>=start) & (first_term['date_index']<=end)]\n",
        "    valid_df = first_term[(first_term['date_index']>=end+1) & (first_term['date_index']<=end+window)]\n",
        "\n",
        "    indicators=['EMA', 'MACD', 'KLength', 'KUpperLength', 'KLowerLength', 'ROC', 'BIAS']\n",
        "    result = defaultdict(list)\n",
        "\n",
        "    C = attention_optimize(train_data=train_df, valid_data=valid_df, n_epochs=30, embeddings=embeddings, silent=True).detach().numpy() # 7 x 1586 (num_indicators x num_stocks)\n",
        "\n",
        "    for k in range(3, 26): # Selecting Top K\n",
        "\n",
        "        for indicator in indicators: # Out of 7 Indicators\n",
        "\n",
        "            j = 0 # To average the results\n",
        "\n",
        "            for _ in range(e): # Number of backtests to conduct, averaging out later\n",
        "\n",
        "                base_cap = 1e7 # Seed Capital\n",
        "                a = [1e7] # Trajectory of capital possession\n",
        "\n",
        "                for day in range(end+window, end+2*window):\n",
        "\n",
        "                    base_top10 = np.array(first_term[first_term['date_index']==day][indicator]).T.argsort()[-k:][::-1]\n",
        "                    base_top10_close = first_term[first_term['date_index']==day+1].iloc[base_top10, :]['closing_price']\n",
        "                    base_top10_open = first_term[first_term['date_index']==day+1].iloc[base_top10, :]['opening_price']\n",
        "                    base_cap += ((base_top10_close*0.997 - base_top10_open)/base_top10_open*base_cap/k).sum()\n",
        "                    a.append(base_cap)\n",
        "\n",
        "\n",
        "                j += a[-1]\n",
        "\n",
        "            result['start'].append(start)\n",
        "            result['end'].append(end)\n",
        "            result['k'].append(k)\n",
        "            result['indicator'].append(indicator)\n",
        "            result['output'].append(j/e)\n",
        "\n",
        "\n",
        "        sor_first_term = first_term.sort_values(by=['date_index', 'stock_id'])\n",
        "        indicator_matrix = sor_first_term[(sor_first_term['date_index']>=end+1) & (sor_first_term['date_index']<end+window)][indicators].T # 7 x 1586*days\n",
        "        daily_indicator = np.array((np.tile(C, window-1) * indicator_matrix).sum()).reshape(-1, 1586)\n",
        "\n",
        "        s = 0\n",
        "\n",
        "        for _ in range(e):\n",
        "\n",
        "            cap = 1e7\n",
        "            b = [1e7]\n",
        "\n",
        "            for i, day in enumerate(list(range(end+1, end+window))):\n",
        "                topk = daily_indicator[i, ].argsort()[-k:][::-1]\n",
        "                top10_close = first_term[first_term['date_index']==day+1].iloc[topk, :]['closing_price']\n",
        "                top10_open = first_term[first_term['date_index']==day+1].iloc[topk, :]['opening_price']\n",
        "                cap += ((top10_close*0.997 - top10_open)/top10_open*cap/k).sum()\n",
        "                b.append(cap)\n",
        "\n",
        "            s += b[-1]\n",
        "\n",
        "        result['start'].append(start)\n",
        "        result['end'].append(end)\n",
        "        result['k'].append(k)\n",
        "        result['indicator'].append(\"Weighted\")\n",
        "        result['output'].append(s/e)\n",
        "\n",
        "\n",
        "    return result"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUMDQK7d8WVp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attention_backtest(data=None, corr_df=None, start=None, end=None, window=62, embeddings=None, e=5, k=8):\n",
        "\n",
        "    from collections import defaultdict\n",
        "\n",
        "    first_term = preprocessing(data=data, corr_df=corr_df, start=start, end=end+2*window)\n",
        "    train_df = first_term[(first_term['date_index']>=start) & (first_term['date_index']<=end)]\n",
        "    valid_df = first_term[(first_term['date_index']>=end+1) & (first_term['date_index']<=end+window)]\n",
        "    indicators=['EMA', 'MACD', 'KLength', 'KUpperLength', 'KLowerLength', 'ROC', 'BIAS']\n",
        "    result = defaultdict(list)\n",
        "\n",
        "    for indicator in indicators: # Out of 7 Indicators\n",
        "\n",
        "        j = 0 # To average the results\n",
        "\n",
        "        for _ in range(e): # Number of backtests to conduct, averaging out later\n",
        "\n",
        "            base_cap = 1e7 # Seed Capital\n",
        "            a = [1e7] # Trajectory of capital possession\n",
        "\n",
        "            for day in range(end+window, end+2*window):\n",
        "\n",
        "                base_top10 = np.array(first_term[first_term['date_index']==day][indicator]).T.argsort()[-k:][::-1]\n",
        "                base_top10_close = first_term[first_term['date_index']==day+1].iloc[base_top10, :]['closing_price']\n",
        "                base_top10_open = first_term[first_term['date_index']==day+1].iloc[base_top10, :]['opening_price']\n",
        "                base_cap += ((base_top10_close*0.997 - base_top10_open)/base_top10_open*base_cap/k).sum()\n",
        "                a.append(base_cap)\n",
        "\n",
        "\n",
        "            j += a[-1]\n",
        "\n",
        "        result['start'].append(start)\n",
        "        result['end'].append(end)\n",
        "        result['indicator'].append(indicator)\n",
        "        result['output'].append(j/e)\n",
        "        result['k'].append(k)\n",
        "        # result['scaled'].append(s/e)\n",
        "    \n",
        "    C = attention_optimize(train_data=train_df, valid_data=valid_df, n_epochs=30, embeddings=embeddings, silent=True).detach().numpy() # 7 x 1586 (num_indicators x num_stocks)\n",
        "    sor_first_term = first_term.sort_values(by=['date_index', 'stock_id'])\n",
        "    indicator_matrix = sor_first_term[(sor_first_term['date_index']>=end+window) & (sor_first_term['date_index']<end+2*window)][indicators].T # 7 x 1586*days\n",
        "    daily_indicator = np.array((np.tile(C, window) * indicator_matrix).sum()).reshape(-1, 1586)\n",
        "\n",
        "    s = 0\n",
        "\n",
        "    for _ in range(e):\n",
        "\n",
        "        cap = 1e7\n",
        "        b = [1e7]\n",
        "\n",
        "        for i, day in enumerate(list(range(end+window, end+2*window))):\n",
        "            topk = daily_indicator[i, ].argsort()[-k:][::-1]\n",
        "            top10_close = first_term[first_term['date_index']==day+1].iloc[topk, :]['closing_price']\n",
        "            top10_open = first_term[first_term['date_index']==day+1].iloc[topk, :]['opening_price']\n",
        "            cap += ((top10_close*0.997 - top10_open)/top10_open*cap/k).sum()\n",
        "            b.append(cap)\n",
        "\n",
        "        s += b[-1]\n",
        "\n",
        "        result['start'].append(start)\n",
        "        result['end'].append(end)\n",
        "        result['indicator'].append(\"Weighted\")\n",
        "        result['output'].append(s/e)\n",
        "        result['k'].append(k)\n",
        "\n",
        "\n",
        "    return result"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbc-cqebyFLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMWi3pZoyFFq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "45bb23ce-e4eb-4699-a9b7-c7a9cf5c3069"
      },
      "source": [
        "# Execute Top K selection on Validation Set\n",
        "\n",
        "# topk_output = pd.DataFrame(columns=['start', 'end', 'k', 'indicator', 'output'])\n",
        "topk_output = pd.read_csv('/content/drive/My Drive/attention_topK_validation_3_25_20_epochs_real.csv')\n",
        "# period 8 continued\n",
        "for n_ in range(8,9):\n",
        "    df, embeddings, st, ed = data_preparer(n=n_, silent=True, n_epochs=100)\n",
        "    output_dict = attention_topK(data=data, corr_df=df, start=st, end=ed, embeddings=embeddings, e=20)\n",
        "    topk_output = pd.concat([topk_output, pd.DataFrame(output_dict)])\n",
        "    print(\"Epoch {} Complete\".format(n_))\n",
        "\n",
        "topk_output.to_csv('attention_topK_validation_3_25_20_epochs_FULL.csv', index=False)\n",
        "topk_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 8 Complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>k</th>\n",
              "      <th>indicator</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>3</td>\n",
              "      <td>EMA</td>\n",
              "      <td>9.615434e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>3</td>\n",
              "      <td>MACD</td>\n",
              "      <td>7.746237e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>3</td>\n",
              "      <td>KLength</td>\n",
              "      <td>7.627000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>3</td>\n",
              "      <td>KUpperLength</td>\n",
              "      <td>7.456177e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>3</td>\n",
              "      <td>KLowerLength</td>\n",
              "      <td>9.021456e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>432</td>\n",
              "      <td>550</td>\n",
              "      <td>25</td>\n",
              "      <td>KUpperLength</td>\n",
              "      <td>7.323026e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>432</td>\n",
              "      <td>550</td>\n",
              "      <td>25</td>\n",
              "      <td>KLowerLength</td>\n",
              "      <td>7.298865e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>432</td>\n",
              "      <td>550</td>\n",
              "      <td>25</td>\n",
              "      <td>ROC</td>\n",
              "      <td>5.565466e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>432</td>\n",
              "      <td>550</td>\n",
              "      <td>25</td>\n",
              "      <td>BIAS</td>\n",
              "      <td>6.886126e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>432</td>\n",
              "      <td>550</td>\n",
              "      <td>25</td>\n",
              "      <td>Weighted</td>\n",
              "      <td>7.851505e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1472 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     start  end   k     indicator        output\n",
              "0        1  121   3           EMA  9.615434e+06\n",
              "1        1  121   3          MACD  7.746237e+06\n",
              "2        1  121   3       KLength  7.627000e+06\n",
              "3        1  121   3  KUpperLength  7.456177e+06\n",
              "4        1  121   3  KLowerLength  9.021456e+06\n",
              "..     ...  ...  ..           ...           ...\n",
              "179    432  550  25  KUpperLength  7.323026e+06\n",
              "180    432  550  25  KLowerLength  7.298865e+06\n",
              "181    432  550  25           ROC  5.565466e+06\n",
              "182    432  550  25          BIAS  6.886126e+06\n",
              "183    432  550  25      Weighted  7.851505e+06\n",
              "\n",
              "[1472 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nw50XIOqyFCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "6b7f8dd5-09eb-456c-d84d-98948a74c7da"
      },
      "source": [
        "topk_output.to_csv('/content/drive/My Drive/attention_topK_validation_3_25_20_epochs_real.csv', index=False)\n",
        "topk_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>k</th>\n",
              "      <th>indicator</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>3</td>\n",
              "      <td>EMA</td>\n",
              "      <td>9.615434e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>3</td>\n",
              "      <td>MACD</td>\n",
              "      <td>7.746237e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>3</td>\n",
              "      <td>KLength</td>\n",
              "      <td>7.627000e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>3</td>\n",
              "      <td>KUpperLength</td>\n",
              "      <td>7.456177e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>3</td>\n",
              "      <td>KLowerLength</td>\n",
              "      <td>9.021456e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>368</td>\n",
              "      <td>489</td>\n",
              "      <td>25</td>\n",
              "      <td>KUpperLength</td>\n",
              "      <td>7.707401e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>368</td>\n",
              "      <td>489</td>\n",
              "      <td>25</td>\n",
              "      <td>KLowerLength</td>\n",
              "      <td>8.536690e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>368</td>\n",
              "      <td>489</td>\n",
              "      <td>25</td>\n",
              "      <td>ROC</td>\n",
              "      <td>6.612173e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>368</td>\n",
              "      <td>489</td>\n",
              "      <td>25</td>\n",
              "      <td>BIAS</td>\n",
              "      <td>6.428494e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>368</td>\n",
              "      <td>489</td>\n",
              "      <td>25</td>\n",
              "      <td>Weighted</td>\n",
              "      <td>8.651586e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1288 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    start  end   k     indicator        output\n",
              "0       1  121   3           EMA  9.615434e+06\n",
              "1       1  121   3          MACD  7.746237e+06\n",
              "2       1  121   3       KLength  7.627000e+06\n",
              "3       1  121   3  KUpperLength  7.456177e+06\n",
              "4       1  121   3  KLowerLength  9.021456e+06\n",
              "..    ...  ...  ..           ...           ...\n",
              "179   368  489  25  KUpperLength  7.707401e+06\n",
              "180   368  489  25  KLowerLength  8.536690e+06\n",
              "181   368  489  25           ROC  6.612173e+06\n",
              "182   368  489  25          BIAS  6.428494e+06\n",
              "183   368  489  25      Weighted  8.651586e+06\n",
              "\n",
              "[1288 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aOjE7PTDLjA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "14b5e2d2-77f0-4b28-d869-b0d0485db73b"
      },
      "source": [
        "# Actual Backtest on Test Set\n",
        "\n",
        "import time\n",
        "\n",
        "backtest_output = pd.DataFrame(columns=['start', 'end', 'k', 'indicator', 'output'])\n",
        "\n",
        "for n_ in range(1, 9):\n",
        "\n",
        "    if n_==1:\n",
        "        t0 = time.time()\n",
        "\n",
        "    df, embeddings, st, ed = data_preparer(n=n_, silent=True, n_epochs=100)\n",
        "\n",
        "    if n_==1:\n",
        "        t1 = time.time()\n",
        "        print(\"Embedding 획득에 소요된 시간: {:.1f}분\".format((t1-t0)/60))\n",
        "        t2 =time.time()\n",
        "\n",
        "    for k_ in [23, 24, 22, 25, 21]:\n",
        "\n",
        "        result_dict = attention_backtest(data=data, corr_df=df, start=st, end=ed, embeddings=embeddings, e=1, k=k_)\n",
        "        backtest_output = pd.concat([backtest_output, pd.DataFrame(result_dict)])\n",
        "\n",
        "    if n_==1:\n",
        "        t3 = time.time()\n",
        "        print(\"한 Period 도는데 걸리는 시간: {:.1f}분\".format((t3-t2)/60))\n",
        "    \n",
        "    print(\"Epoch {} Complete\".format(n_))\n",
        "\n",
        "backtest_output.to_csv(\"/content/drive/My Drive/Attention_Backtest_k_23_24_22_25_21.csv\", index=False)\n",
        "print(\"Saved!\")\n",
        "\n",
        "backtest_output"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding 획득에 소요된 시간: 3.0분\n",
            "한 Period 도는데 걸리는 시간: 4.0분\n",
            "Epoch 1 Complete\n",
            "Epoch 2 Complete\n",
            "Epoch 3 Complete\n",
            "Epoch 4 Complete\n",
            "Epoch 5 Complete\n",
            "Epoch 6 Complete\n",
            "Epoch 7 Complete\n",
            "Epoch 8 Complete\n",
            "Saved!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>k</th>\n",
              "      <th>indicator</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>23</td>\n",
              "      <td>EMA</td>\n",
              "      <td>7.776338e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>23</td>\n",
              "      <td>MACD</td>\n",
              "      <td>7.419183e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>23</td>\n",
              "      <td>KLength</td>\n",
              "      <td>7.346115e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>23</td>\n",
              "      <td>KUpperLength</td>\n",
              "      <td>7.123484e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>121</td>\n",
              "      <td>23</td>\n",
              "      <td>KLowerLength</td>\n",
              "      <td>7.519974e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>432</td>\n",
              "      <td>550</td>\n",
              "      <td>21</td>\n",
              "      <td>KUpperLength</td>\n",
              "      <td>7.266042e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>432</td>\n",
              "      <td>550</td>\n",
              "      <td>21</td>\n",
              "      <td>KLowerLength</td>\n",
              "      <td>7.160804e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>432</td>\n",
              "      <td>550</td>\n",
              "      <td>21</td>\n",
              "      <td>ROC</td>\n",
              "      <td>5.334275e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>432</td>\n",
              "      <td>550</td>\n",
              "      <td>21</td>\n",
              "      <td>BIAS</td>\n",
              "      <td>6.824341e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>432</td>\n",
              "      <td>550</td>\n",
              "      <td>21</td>\n",
              "      <td>Weighted</td>\n",
              "      <td>7.887271e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>320 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   start  end   k     indicator        output\n",
              "0      1  121  23           EMA  7.776338e+06\n",
              "1      1  121  23          MACD  7.419183e+06\n",
              "2      1  121  23       KLength  7.346115e+06\n",
              "3      1  121  23  KUpperLength  7.123484e+06\n",
              "4      1  121  23  KLowerLength  7.519974e+06\n",
              "..   ...  ...  ..           ...           ...\n",
              "3    432  550  21  KUpperLength  7.266042e+06\n",
              "4    432  550  21  KLowerLength  7.160804e+06\n",
              "5    432  550  21           ROC  5.334275e+06\n",
              "6    432  550  21          BIAS  6.824341e+06\n",
              "7    432  550  21      Weighted  7.887271e+06\n",
              "\n",
              "[320 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnNcHI-ivy5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = pd.DataFrame(backtest_output.groupby(['k', 'indicator'])['output'].mean()).reset_index().pivot(index='k', columns='indicator', values='output')\n",
        "t['maximum'] = t.drop(columns=['Weighted']).max(axis=1)\n",
        "t['diff'] = t.Weighted - t.maximum\n",
        "t.sort_values(by='diff', ascending=False).to_csv('/content/drive/My Drive/Attention_Backtest_k_23_24_22_25_21_pivot.csv', index=False)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAHLWaoUvy2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "5084423f-88c5-4696-d193-f032d29b34b0"
      },
      "source": [
        "t.sort_values(by='diff', ascending=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>indicator</th>\n",
              "      <th>BIAS</th>\n",
              "      <th>EMA</th>\n",
              "      <th>KLength</th>\n",
              "      <th>KLowerLength</th>\n",
              "      <th>KUpperLength</th>\n",
              "      <th>MACD</th>\n",
              "      <th>ROC</th>\n",
              "      <th>Weighted</th>\n",
              "      <th>maximum</th>\n",
              "      <th>diff</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>k</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>7.191609e+06</td>\n",
              "      <td>8.149864e+06</td>\n",
              "      <td>7.337540e+06</td>\n",
              "      <td>8.110195e+06</td>\n",
              "      <td>8.120950e+06</td>\n",
              "      <td>7.844128e+06</td>\n",
              "      <td>5.772344e+06</td>\n",
              "      <td>8.189400e+06</td>\n",
              "      <td>8.149864e+06</td>\n",
              "      <td>39536.078202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>7.148686e+06</td>\n",
              "      <td>8.132747e+06</td>\n",
              "      <td>7.343637e+06</td>\n",
              "      <td>8.067382e+06</td>\n",
              "      <td>8.141312e+06</td>\n",
              "      <td>7.824942e+06</td>\n",
              "      <td>5.796739e+06</td>\n",
              "      <td>8.160825e+06</td>\n",
              "      <td>8.141312e+06</td>\n",
              "      <td>19512.594008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>7.222204e+06</td>\n",
              "      <td>8.149548e+06</td>\n",
              "      <td>7.380849e+06</td>\n",
              "      <td>8.137331e+06</td>\n",
              "      <td>8.122260e+06</td>\n",
              "      <td>7.816352e+06</td>\n",
              "      <td>5.895823e+06</td>\n",
              "      <td>8.159930e+06</td>\n",
              "      <td>8.149548e+06</td>\n",
              "      <td>10381.434214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>7.068975e+06</td>\n",
              "      <td>8.156886e+06</td>\n",
              "      <td>7.301871e+06</td>\n",
              "      <td>8.070987e+06</td>\n",
              "      <td>8.072886e+06</td>\n",
              "      <td>7.843657e+06</td>\n",
              "      <td>5.679396e+06</td>\n",
              "      <td>8.117835e+06</td>\n",
              "      <td>8.156886e+06</td>\n",
              "      <td>-39051.194702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>7.120944e+06</td>\n",
              "      <td>8.171936e+06</td>\n",
              "      <td>7.336365e+06</td>\n",
              "      <td>8.059467e+06</td>\n",
              "      <td>8.105514e+06</td>\n",
              "      <td>7.833318e+06</td>\n",
              "      <td>5.708791e+06</td>\n",
              "      <td>8.126519e+06</td>\n",
              "      <td>8.171936e+06</td>\n",
              "      <td>-45417.673022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "indicator          BIAS           EMA  ...       maximum          diff\n",
              "k                                      ...                            \n",
              "24         7.191609e+06  8.149864e+06  ...  8.149864e+06  39536.078202\n",
              "23         7.148686e+06  8.132747e+06  ...  8.141312e+06  19512.594008\n",
              "25         7.222204e+06  8.149548e+06  ...  8.149548e+06  10381.434214\n",
              "21         7.068975e+06  8.156886e+06  ...  8.156886e+06 -39051.194702\n",
              "22         7.120944e+06  8.171936e+06  ...  8.171936e+06 -45417.673022\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vOBYedhvyzy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b31P6X9Kvyxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCSDUGEYKWXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "backtest_output.pivot(index='start', columns='indicator', values='output').to_csv('backtest_scaled_attention_covariance_loss_top10.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZGbgDgmdpoB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "ee38de1f-c419-4a04-90de-a164919c43df"
      },
      "source": [
        "pd.DataFrame(backtest_output.groupby('indicator')['output'].mean())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>indicator</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BIAS</th>\n",
              "      <td>6.801616e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EMA</th>\n",
              "      <td>8.442260e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KLength</th>\n",
              "      <td>7.209335e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KLowerLength</th>\n",
              "      <td>8.140336e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KUpperLength</th>\n",
              "      <td>8.047801e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MACD</th>\n",
              "      <td>8.024281e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ROC</th>\n",
              "      <td>5.843367e+06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weighted</th>\n",
              "      <td>8.397495e+06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    output\n",
              "indicator                 \n",
              "BIAS          6.801616e+06\n",
              "EMA           8.442260e+06\n",
              "KLength       7.209335e+06\n",
              "KLowerLength  8.140336e+06\n",
              "KUpperLength  8.047801e+06\n",
              "MACD          8.024281e+06\n",
              "ROC           5.843367e+06\n",
              "Weighted      8.397495e+06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-yo8YBeoFql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e06140f-d36e-4002-b952-a5198b2d648b"
      },
      "source": [
        "1+1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88EbwEctB3f9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}