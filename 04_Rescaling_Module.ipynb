{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Rescaling_Module.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOqNu0IAlvOBdI0pLUlfzNd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reyllama/TTIO/blob/master/04_Rescaling_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-cACHlkT1j7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "3be9c469-1e79-4e6d-a38a-38e11bddc97e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRuAieuzUfMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/drive/My Drive/corr3.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df = df.set_index(keys='stock_id')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnEB9b_MUxd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor\n",
        "epochs = 100\n",
        "emb_dim = 32\n",
        "embeddings = Variable(torch.randn(emb_dim, len(df)).type(dtype), requires_grad=True)\n",
        "lr = 0.01\n",
        "optimizer = optim.Adam([embeddings], lr=lr)\n",
        "mean = np.abs(df).mean().mean()\n",
        "coef = 1/mean\n",
        "loss_track = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  loss = 0\n",
        "  for i in range(len(df)):\n",
        "    v1 = embeddings[:, i].view(emb_dim, -1)\n",
        "    dist = torch.norm(v1 - embeddings, dim=0).view(len(df), 1)\n",
        "    corrs = torch.from_numpy(np.abs(coef*np.array(df.iloc[:, i]))-1).view(1, len(df)).type(torch.FloatTensor)\n",
        "    loss += torch.mm(corrs, dist)/2\n",
        "  loss_track.append(loss.item())\n",
        "  if (epoch+1) % 5 == 0:\n",
        "    print(\"{0}th epoch in process\".format(epoch+1))\n",
        "    print('running loss: {}'.format(loss.item()))\n",
        "    print()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward(retain_graph=False)\n",
        "  optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for element in embeddings:\n",
        "      element.clamp_(0,1)\n",
        "\n",
        "embeddings[:, 1]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZKoad26yNlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.plot(list(range(epochs)), loss_track)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IajAQ7rIZc4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "03eb6c3d-15c4-481a-da8c-54767bf657c0"
      },
      "source": [
        "embeddings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5709, 0.5711, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
              "        [0.5379, 0.5357, 0.0000,  ..., 1.0000, 0.0000, 1.0000],\n",
              "        [0.5088, 0.5078, 1.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [0.5198, 0.5197, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
              "        [0.5329, 0.5329, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.5397, 0.5382, 0.0000,  ..., 0.0000, 1.0000, 0.0000]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8eWvhCbdrYw",
        "colab_type": "text"
      },
      "source": [
        "## Rescaling Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34fi0Cg8Zlvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "3d0419f2-24ba-4b6e-b74a-ee69fc42f44d"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/stocks.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock_id</th>\n",
              "      <th>name</th>\n",
              "      <th>date</th>\n",
              "      <th>opening_price</th>\n",
              "      <th>highest_price</th>\n",
              "      <th>lowest_price</th>\n",
              "      <th>closing_price</th>\n",
              "      <th>trading_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>8130</td>\n",
              "      <td>8150</td>\n",
              "      <td>7920</td>\n",
              "      <td>8140</td>\n",
              "      <td>281440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>8040</td>\n",
              "      <td>8250</td>\n",
              "      <td>8000</td>\n",
              "      <td>8190</td>\n",
              "      <td>243179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>8200</td>\n",
              "      <td>8590</td>\n",
              "      <td>8110</td>\n",
              "      <td>8550</td>\n",
              "      <td>609906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>8470</td>\n",
              "      <td>8690</td>\n",
              "      <td>8190</td>\n",
              "      <td>8380</td>\n",
              "      <td>704752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>8210</td>\n",
              "      <td>8900</td>\n",
              "      <td>8130</td>\n",
              "      <td>8770</td>\n",
              "      <td>802330</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  stock_id  name        date  ...  lowest_price  closing_price  trading_volume\n",
              "0   000020  동화약품  2016-01-04  ...          7920           8140          281440\n",
              "1   000020  동화약품  2016-01-05  ...          8000           8190          243179\n",
              "2   000020  동화약품  2016-01-06  ...          8110           8550          609906\n",
              "3   000020  동화약품  2016-01-07  ...          8190           8380          704752\n",
              "4   000020  동화약품  2016-01-08  ...          8130           8770          802330\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uFYSgurgjNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['KLength'] = data['closing_price'] - data['opening_price']\n",
        "data['KUpperLength'] = data['highest_price'] - data[['opening_price', 'closing_price']].max(axis=1)\n",
        "data['temp'] = data['opening_price']-data['lowest_price']\n",
        "data['KLowerLength'] = data[['closing_price', 'temp']].min(axis=1)\n",
        "data['return'] = data['closing_price'].diff()\n",
        "data = data.drop(columns=['temp'])\n",
        "data['stock_id'] = data['stock_id'].astype(str)\n",
        "## 첫날 빼줘야됨 (종목 바뀔때 섞여들어갔다)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53Wo9fFTw6mI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2383f6bf-b412-4640-c926-89d945a00c56"
      },
      "source": [
        "def year_parser(column):\n",
        "  return int(column[0:4])\n",
        "\n",
        "def month_parser(column):\n",
        "  return int(column[5:7])\n",
        "\n",
        "data['year'] = data['date'].apply(year_parser)\n",
        "data['month'] = data['date'].apply(month_parser)\n",
        "\n",
        "data = data[(data['year']==2016)&(data['month']<=6)]\n",
        "data = data[data['stock_id'].isin(df.columns)]\n",
        "# data = data.fillna(0)\n",
        "\n",
        "KL = data.pivot(index='date', columns='stock_id', values='KLength')\n",
        "R = data.pivot(index='date', columns='stock_id', values='return')\n",
        "\n",
        "KL.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121, 1863)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1CvO91HxkNB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8dde22d3-a9ef-41e8-ea0c-2c7451dd7ee3"
      },
      "source": [
        "print(KL.shape, R.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(121, 2018) (121, 2018)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHYLk-Jf2h6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KL = KL.iloc[:-1, ]\n",
        "R = R.iloc[1:, ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg2JtgELonzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor\n",
        "weights = Variable(torch.rand(1, 32).type(dtype), requires_grad=True)\n",
        "lr = 0.005\n",
        "optimizer = optim.Adam([weights], lr=lr)\n",
        "epochs = 3000\n",
        "indic = np.array(KL)\n",
        "returns = np.array(R)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  loss = 0\n",
        "\n",
        "  rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "  opt_ind = torch.from_numpy(indic) * rescale_fc # element-wise\n",
        "  # print('opt_ind: ', opt_ind)\n",
        "  mean_ind = torch.mean(opt_ind, axis=0)\n",
        "  # print('mean_ind: ', mean_ind)\n",
        "  mean_ret = torch.mean(torch.from_numpy(returns), axis=0)\n",
        "  # print('mean_ret: ', mean_ret)\n",
        "\n",
        "  vx = opt_ind - mean_ind\n",
        "  vy = torch.from_numpy(returns) - mean_ret\n",
        "  # print('vx: ', vx)\n",
        "  # print('vy: ', vy)\n",
        "  loss = -torch.abs(torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2))))\n",
        "  # print('loss: ', loss)\n",
        "\n",
        "  if (epoch+1) % 100 == 0:\n",
        "    print(\"{0}th epoch in process\".format(epoch+1))\n",
        "    print('running loss: {}'.format(loss.item()))\n",
        "    print()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward(retain_graph=False)\n",
        "  optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for weight in weights:\n",
        "      weight.clamp_(0,1)\n",
        "\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfXGFQLcLkwr",
        "colab_type": "text"
      },
      "source": [
        "### Comparison: Raw KLength vs Rescaled KLength"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UGMCx-TLqsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_KL = np.mean(indic, axis=0)\n",
        "mean_return = np.mean(returns, axis=0)\n",
        "\n",
        "vx = indic - mean_KL\n",
        "vy = returns - mean_return\n",
        "\n",
        "corr1 = np.abs(np.sum(vx*vy) / (np.sqrt(np.sum(vx ** 2)) * np.sqrt(np.sum(vy ** 2))))\n",
        "\n",
        "rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "opt_ind = torch.from_numpy(indic) * rescale_fc # element-wise\n",
        "mean_ind = torch.mean(opt_ind, axis=0)\n",
        "mean_ret = torch.mean(torch.from_numpy(returns), axis=0)\n",
        "\n",
        "wx = opt_ind - mean_ind\n",
        "wy = torch.from_numpy(returns) - mean_ret\n",
        "corr2 = torch.abs(torch.sum(wx * wy) / (torch.sqrt(torch.sum(wx ** 2)) * torch.sqrt(torch.sum(wy ** 2))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_alQ2muNTTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f89dd32d-a36f-43c5-977a-1e73c56658bf"
      },
      "source": [
        "print(\"Correlation of Raw vs Recaled: {0:.4f} vs {1:.4f}\".format(corr1, corr2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correlation of Raw vs Recaled: 0.2428 vs 0.2473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5zZJLxF3icT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDVXPF4v3iaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "02f6ec97-c730-42d7-eec6-11c402f77a33"
      },
      "source": [
        "!pip install ta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ta\n",
            "  Downloading https://files.pythonhosted.org/packages/90/ec/e4f5aea8c7f0f55f92b52ffbafa389ea82f3a10d9cab2760e40af34c5b3f/ta-0.5.25.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ta) (1.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->ta) (1.12.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.5.25-cp36-none-any.whl size=24880 sha256=570a505dd5ce4b2c21a3fd9fc98c7c94b2e2c03ca52682f343b7a5f830117ce6\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/93/b7/cf649194508e53cee4145ffb949e9f26877a5a8dd12db9ed5b\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.5.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jmyvrxf3iUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJlhSXFs3iR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssMhq0J53iXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ta\n",
        "\n",
        "def bias(close=None, m=7):\n",
        "  return close - close.rolling(m).mean()\n",
        "\n",
        "soda = data.copy()\n",
        "soda['EMA'] = ta.trend.ema_indicator(close=data['closing_price'])\n",
        "soda['MACD'] = ta.trend.macd(close=data['closing_price'])\n",
        "soda['ROC'] = ta.momentum.roc(close=data['closing_price'])\n",
        "soda['BIAS'] = bias(soda['closing_price'])\n",
        "soda.iloc[3:28]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2dS9IsTIx94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BxGS-NHIx8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "05ae65d7-cb18-402c-ebca-56ef10fb3962"
      },
      "source": [
        "path = \"/content/drive/My Drive/stocks_merged.csv\"\n",
        "merg = pd.read_csv(path)\n",
        "merg.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>stock_id</th>\n",
              "      <th>name</th>\n",
              "      <th>date</th>\n",
              "      <th>opening_price</th>\n",
              "      <th>highest_price</th>\n",
              "      <th>lowest_price</th>\n",
              "      <th>closing_price</th>\n",
              "      <th>trading_volume</th>\n",
              "      <th>industry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>8130</td>\n",
              "      <td>8150</td>\n",
              "      <td>7920</td>\n",
              "      <td>8140</td>\n",
              "      <td>281440</td>\n",
              "      <td>의약품 제조업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>8040</td>\n",
              "      <td>8250</td>\n",
              "      <td>8000</td>\n",
              "      <td>8190</td>\n",
              "      <td>243179</td>\n",
              "      <td>의약품 제조업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>8200</td>\n",
              "      <td>8590</td>\n",
              "      <td>8110</td>\n",
              "      <td>8550</td>\n",
              "      <td>609906</td>\n",
              "      <td>의약품 제조업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>8470</td>\n",
              "      <td>8690</td>\n",
              "      <td>8190</td>\n",
              "      <td>8380</td>\n",
              "      <td>704752</td>\n",
              "      <td>의약품 제조업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>8210</td>\n",
              "      <td>8900</td>\n",
              "      <td>8130</td>\n",
              "      <td>8770</td>\n",
              "      <td>802330</td>\n",
              "      <td>의약품 제조업</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 stock_id  name  ... closing_price  trading_volume  industry\n",
              "0           0       20  동화약품  ...          8140          281440   의약품 제조업\n",
              "1           1       20  동화약품  ...          8190          243179   의약품 제조업\n",
              "2           2       20  동화약품  ...          8550          609906   의약품 제조업\n",
              "3           3       20  동화약품  ...          8380          704752   의약품 제조업\n",
              "4           4       20  동화약품  ...          8770          802330   의약품 제조업\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tASXwZN7I5en",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f404685-0c0f-4d1f-dbd4-99ecfadbb9c0"
      },
      "source": [
        "merg['industry'].unique().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(148,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB0RMXF4I5Jo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "ea9d4453-d278-4417-b267-1328df04f24e"
      },
      "source": [
        "merg['industry'].unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['의약품 제조업', '그외 기타 운송장비 제조업', '종합 소매업', '보험업', '기타 금융업', nan,\n",
              "       '알코올음료 제조업', '도로 화물 운송업', '회사 본부 및 경영 컨설팅 서비스업', '토목 건설업',\n",
              "       '통신 및 방송 장비 제조업', '자동차 신품 부품 제조업', '기타 전문 도매업', '내화, 비내화 요업제품 제조업',\n",
              "       '특수 목적용 기계 제조업', '절연선 및 케이블 제조업', '육상 여객 운송업', '반도체 제조업',\n",
              "       '1차 비철금속 제조업', '상품 종합 도매업', '기타 화학제품 제조업',\n",
              "       '시멘트, 석회, 플라스터 및 그 제품 제조업', '방적 및 가공사 제조업', '가전제품 및 정보통신장비 소매업',\n",
              "       '펄프, 종이 및 판지 제조업', '직물직조 및 직물제품 제조업', '1차 철강 제조업', '상품 중개업',\n",
              "       '곡물가공품, 전분 및 전분제품 제조업', '전구 및 조명장치 제조업', '금융 지원 서비스업',\n",
              "       '기초 화학물질 제조업', '봉제의복 제조업', '비료, 농약 및 살균, 살충제 제조업',\n",
              "       '기타 비금속 광물제품 제조업', '기타 식품 제조업', '건물 건설업',\n",
              "       '건축기술, 엔지니어링 및 관련 기술 서비스업', '가죽, 가방 및 유사제품 제조업',\n",
              "       '측정, 시험, 항해, 제어 및 기타 정밀기기 제조업; 광학기기 제외', '낙농제품 및 식용빙과류 제조업',\n",
              "       '골판지, 종이 상자 및 종이용기 제조업', '고무제품 제조업', '영화, 비디오물, 방송프로그램 제작 및 배급업',\n",
              "       '악기 제조업', '기계장비 및 관련 물품 도매업', '나무제품 제조업', '석유 정제품 제조업',\n",
              "       '기타 운송관련 서비스업', '화학섬유 제조업', '해상 운송업', '동물용 사료 및 조제식품 제조업',\n",
              "       '연료용 가스 제조 및 배관공급업', '항공 여객 운송업', '기타 비금속광물 광업', '수산물 가공 및 저장 처리업',\n",
              "       '재 보험업', '플라스틱제품 제조업', '가구 제조업', '일반 목적용 기계 제조업', '기타 금속 가공제품 제조업',\n",
              "       '일차전지 및 축전지 제조업', '생활용품 도매업', '전자부품 제조업', '그외 기타 제품 제조업', '어로 어업',\n",
              "       '유리 및 유리제품 제조업', '과실, 채소 가공 및 저장 처리업', '기초 의약물질 및 생물학적 제제 제조업',\n",
              "       '의료용 기기 제조업', '은행 및 저축기관', '전기 통신업', '일반 및 생활 숙박시설 운영업',\n",
              "       '산업용 농·축산물 및 동·식물 도매업', '구조용 금속제품, 탱크 및 증기발생기 제조업',\n",
              "       '건축자재, 철물 및 난방장치 도매업', '컴퓨터 프로그래밍, 시스템 통합 및 관리업',\n",
              "       '전동기, 발전기 및 전기 변환 · 공급 · 제어 장치 제조업', '편조원단 제조업', '영상 및 음향기기 제조업',\n",
              "       '기타 상품 전문 소매업', '가정용 기기 제조업', '선박 및 보트 건조업', '광고업', '무기 및 총포탄 제조업',\n",
              "       '기반조성 및 시설물 축조관련 전문공사업', '스포츠 서비스업', '건물설비 설치 공사업',\n",
              "       '항공기,우주선 및 부품 제조업', '기타 종이 및 판지 제품 제조업', '경비, 경호 및 탐정업',\n",
              "       '자동차용 엔진 및 자동차 제조업', '부동산 임대 및 공급업', '기타 사업지원 서비스업',\n",
              "       '컴퓨터 및 주변장치 제조업', '기타 전기장비 제조업', '신탁업 및 집합투자업', '초등 교육기관',\n",
              "       '자료처리, 호스팅, 포털 및 기타 인터넷 정보매개 서비스업', '금속 주조업', '전문디자인업',\n",
              "       '그외 기타 개인 서비스업', '소프트웨어 개발 및 공급업', '제재 및 목재 가공업', '음·식료품 및 담배 도매업',\n",
              "       '귀금속 및 장신용품 제조업', '도축, 육류 가공 및 저장 처리업', '텔레비전 방송업', '폐기물 처리업',\n",
              "       '기타 정보 서비스업', '인쇄 및 인쇄관련 산업', '섬유, 의복, 신발 및 가죽제품 소매업', '음식점업',\n",
              "       '섬유제품 염색, 정리 및 마무리 가공업', '여행사 및 기타 여행보조 서비스업', '창작 및 예술관련 서비스업',\n",
              "       '해체, 선별 및 원료 재생업', '기록매체 복제업', '유원지 및 기타 오락관련 서비스업', '무점포 소매업',\n",
              "       '서적, 잡지 및 기타 인쇄물 출판업', '오디오물 출판 및 원판 녹음업', '전기 및 통신 공사업',\n",
              "       '그외 기타 전문, 과학 및 기술 서비스업', '일반 교습 학원', '연료 소매업', '사업시설 유지·관리 서비스업',\n",
              "       '실내건축 및 건축마무리 공사업', '의료용품 및 기타 의약 관련제품 제조업', '환경 정화 및 복원업',\n",
              "       '기타 과학기술 서비스업', '자연과학 및 공학 연구개발업', '합성고무 및 플라스틱 물질 제조업',\n",
              "       '사진장비 및 광학기기 제조업', '작물 재배업', '기타 전문 서비스업', '교육지원 서비스업', '철도장비 제조업',\n",
              "       '석탄 광업', '자동차 재제조 부품 제조업', '기타 교육기관', '자동차 판매업', '운송장비 임대업',\n",
              "       '증기, 냉·온수 및 공기조절 공급업', '기타 섬유제품 제조업', '산업용 기계 및 장비 임대업',\n",
              "       '비알코올음료 및 얼음 제조업', '자동차 부품 및 내장품 판매업'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsx8pthRIx4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THIQOXgYIx2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssdqBr-q3iPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxMnV8IzSgcv",
        "colab_type": "text"
      },
      "source": [
        "### Modulate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8g0r5FYJ92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "e7c0c201-ed75-47b3-bbb2-a8fd02dfa071"
      },
      "source": [
        "path = \"/content/drive/My Drive/corr1.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df = df.set_index(keys='stock_id')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000020</th>\n",
              "      <th>000040</th>\n",
              "      <th>000050</th>\n",
              "      <th>000060</th>\n",
              "      <th>000070</th>\n",
              "      <th>000075</th>\n",
              "      <th>000080</th>\n",
              "      <th>000087</th>\n",
              "      <th>000100</th>\n",
              "      <th>000105</th>\n",
              "      <th>000120</th>\n",
              "      <th>000140</th>\n",
              "      <th>000145</th>\n",
              "      <th>000150</th>\n",
              "      <th>000155</th>\n",
              "      <th>000157</th>\n",
              "      <th>000180</th>\n",
              "      <th>000210</th>\n",
              "      <th>000215</th>\n",
              "      <th>000220</th>\n",
              "      <th>000225</th>\n",
              "      <th>000227</th>\n",
              "      <th>000230</th>\n",
              "      <th>000240</th>\n",
              "      <th>000250</th>\n",
              "      <th>000270</th>\n",
              "      <th>000300</th>\n",
              "      <th>000320</th>\n",
              "      <th>000325</th>\n",
              "      <th>000370</th>\n",
              "      <th>000390</th>\n",
              "      <th>000400</th>\n",
              "      <th>000430</th>\n",
              "      <th>000440</th>\n",
              "      <th>000480</th>\n",
              "      <th>000490</th>\n",
              "      <th>000500</th>\n",
              "      <th>000520</th>\n",
              "      <th>000540</th>\n",
              "      <th>000545</th>\n",
              "      <th>...</th>\n",
              "      <th>95190</th>\n",
              "      <th>95270</th>\n",
              "      <th>95340</th>\n",
              "      <th>95500</th>\n",
              "      <th>95570</th>\n",
              "      <th>95610</th>\n",
              "      <th>95660</th>\n",
              "      <th>95700</th>\n",
              "      <th>95720</th>\n",
              "      <th>95910</th>\n",
              "      <th>96040</th>\n",
              "      <th>96240</th>\n",
              "      <th>96300</th>\n",
              "      <th>96350</th>\n",
              "      <th>96530</th>\n",
              "      <th>96610</th>\n",
              "      <th>96630</th>\n",
              "      <th>96640</th>\n",
              "      <th>96760</th>\n",
              "      <th>96770</th>\n",
              "      <th>96775</th>\n",
              "      <th>96870</th>\n",
              "      <th>97230</th>\n",
              "      <th>97520</th>\n",
              "      <th>97780</th>\n",
              "      <th>97800</th>\n",
              "      <th>97870</th>\n",
              "      <th>97950</th>\n",
              "      <th>97955</th>\n",
              "      <th>98120</th>\n",
              "      <th>98460</th>\n",
              "      <th>98660</th>\n",
              "      <th>99190</th>\n",
              "      <th>99220</th>\n",
              "      <th>99320</th>\n",
              "      <th>99340</th>\n",
              "      <th>99350</th>\n",
              "      <th>99410</th>\n",
              "      <th>99440</th>\n",
              "      <th>99520</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stock_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000020</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.221514</td>\n",
              "      <td>-0.037755</td>\n",
              "      <td>-0.021159</td>\n",
              "      <td>0.230919</td>\n",
              "      <td>0.259171</td>\n",
              "      <td>0.176753</td>\n",
              "      <td>0.195048</td>\n",
              "      <td>0.215654</td>\n",
              "      <td>0.175516</td>\n",
              "      <td>0.208703</td>\n",
              "      <td>0.139837</td>\n",
              "      <td>0.071031</td>\n",
              "      <td>0.116629</td>\n",
              "      <td>0.085471</td>\n",
              "      <td>0.165149</td>\n",
              "      <td>0.124488</td>\n",
              "      <td>0.078928</td>\n",
              "      <td>0.049496</td>\n",
              "      <td>0.537236</td>\n",
              "      <td>0.512802</td>\n",
              "      <td>0.303855</td>\n",
              "      <td>0.483129</td>\n",
              "      <td>0.017378</td>\n",
              "      <td>0.482491</td>\n",
              "      <td>-0.072407</td>\n",
              "      <td>0.017935</td>\n",
              "      <td>0.133918</td>\n",
              "      <td>0.041311</td>\n",
              "      <td>0.148041</td>\n",
              "      <td>0.110374</td>\n",
              "      <td>0.294617</td>\n",
              "      <td>0.040400</td>\n",
              "      <td>0.118770</td>\n",
              "      <td>-0.026300</td>\n",
              "      <td>0.162403</td>\n",
              "      <td>0.135262</td>\n",
              "      <td>0.439909</td>\n",
              "      <td>0.150139</td>\n",
              "      <td>0.018031</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.019455</td>\n",
              "      <td>0.068774</td>\n",
              "      <td>0.035582</td>\n",
              "      <td>0.072378</td>\n",
              "      <td>0.177056</td>\n",
              "      <td>0.094984</td>\n",
              "      <td>0.257213</td>\n",
              "      <td>0.118036</td>\n",
              "      <td>0.061175</td>\n",
              "      <td>0.049229</td>\n",
              "      <td>-0.120927</td>\n",
              "      <td>0.027107</td>\n",
              "      <td>0.229460</td>\n",
              "      <td>0.137070</td>\n",
              "      <td>0.333912</td>\n",
              "      <td>0.253663</td>\n",
              "      <td>-0.004647</td>\n",
              "      <td>0.073918</td>\n",
              "      <td>0.436779</td>\n",
              "      <td>0.070719</td>\n",
              "      <td>0.038662</td>\n",
              "      <td>-0.009037</td>\n",
              "      <td>-0.067703</td>\n",
              "      <td>0.160585</td>\n",
              "      <td>0.272692</td>\n",
              "      <td>0.061822</td>\n",
              "      <td>0.225241</td>\n",
              "      <td>0.039099</td>\n",
              "      <td>-0.051827</td>\n",
              "      <td>0.112372</td>\n",
              "      <td>0.146558</td>\n",
              "      <td>0.079731</td>\n",
              "      <td>0.119611</td>\n",
              "      <td>0.284219</td>\n",
              "      <td>0.065122</td>\n",
              "      <td>-0.193870</td>\n",
              "      <td>-0.055491</td>\n",
              "      <td>0.170469</td>\n",
              "      <td>0.298094</td>\n",
              "      <td>0.101488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000040</th>\n",
              "      <td>0.221514</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.084175</td>\n",
              "      <td>0.125700</td>\n",
              "      <td>0.048086</td>\n",
              "      <td>0.144288</td>\n",
              "      <td>-0.026518</td>\n",
              "      <td>0.139692</td>\n",
              "      <td>0.059997</td>\n",
              "      <td>0.230597</td>\n",
              "      <td>0.052476</td>\n",
              "      <td>0.017729</td>\n",
              "      <td>0.078381</td>\n",
              "      <td>0.209605</td>\n",
              "      <td>0.249582</td>\n",
              "      <td>0.245019</td>\n",
              "      <td>0.194707</td>\n",
              "      <td>0.179482</td>\n",
              "      <td>0.216908</td>\n",
              "      <td>0.249301</td>\n",
              "      <td>0.259880</td>\n",
              "      <td>0.179810</td>\n",
              "      <td>0.216462</td>\n",
              "      <td>0.096105</td>\n",
              "      <td>0.369667</td>\n",
              "      <td>0.131545</td>\n",
              "      <td>0.340488</td>\n",
              "      <td>0.217145</td>\n",
              "      <td>-0.060981</td>\n",
              "      <td>0.220581</td>\n",
              "      <td>0.082751</td>\n",
              "      <td>0.271047</td>\n",
              "      <td>0.300337</td>\n",
              "      <td>0.120322</td>\n",
              "      <td>0.053789</td>\n",
              "      <td>0.174838</td>\n",
              "      <td>0.239307</td>\n",
              "      <td>0.215961</td>\n",
              "      <td>0.197419</td>\n",
              "      <td>0.051451</td>\n",
              "      <td>...</td>\n",
              "      <td>0.268494</td>\n",
              "      <td>0.198407</td>\n",
              "      <td>0.206406</td>\n",
              "      <td>0.414345</td>\n",
              "      <td>0.101782</td>\n",
              "      <td>0.059960</td>\n",
              "      <td>0.227716</td>\n",
              "      <td>0.063983</td>\n",
              "      <td>0.198506</td>\n",
              "      <td>0.071940</td>\n",
              "      <td>-0.059623</td>\n",
              "      <td>0.270323</td>\n",
              "      <td>0.338363</td>\n",
              "      <td>0.194589</td>\n",
              "      <td>0.144394</td>\n",
              "      <td>0.157667</td>\n",
              "      <td>0.114744</td>\n",
              "      <td>0.003995</td>\n",
              "      <td>0.296121</td>\n",
              "      <td>0.238160</td>\n",
              "      <td>0.193186</td>\n",
              "      <td>0.199345</td>\n",
              "      <td>0.176108</td>\n",
              "      <td>0.322742</td>\n",
              "      <td>0.215993</td>\n",
              "      <td>0.116542</td>\n",
              "      <td>0.265938</td>\n",
              "      <td>-0.006009</td>\n",
              "      <td>-0.078675</td>\n",
              "      <td>0.207658</td>\n",
              "      <td>0.136085</td>\n",
              "      <td>0.270371</td>\n",
              "      <td>0.137788</td>\n",
              "      <td>0.219789</td>\n",
              "      <td>0.093931</td>\n",
              "      <td>-0.145495</td>\n",
              "      <td>-0.084699</td>\n",
              "      <td>0.106058</td>\n",
              "      <td>0.374286</td>\n",
              "      <td>0.271006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000050</th>\n",
              "      <td>-0.037755</td>\n",
              "      <td>-0.084175</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.026910</td>\n",
              "      <td>0.194396</td>\n",
              "      <td>0.145192</td>\n",
              "      <td>0.064836</td>\n",
              "      <td>0.065237</td>\n",
              "      <td>0.176480</td>\n",
              "      <td>0.184645</td>\n",
              "      <td>0.139954</td>\n",
              "      <td>0.074693</td>\n",
              "      <td>-0.034289</td>\n",
              "      <td>0.035887</td>\n",
              "      <td>0.030783</td>\n",
              "      <td>-0.029888</td>\n",
              "      <td>0.065450</td>\n",
              "      <td>-0.033895</td>\n",
              "      <td>0.003912</td>\n",
              "      <td>-0.018252</td>\n",
              "      <td>-0.050283</td>\n",
              "      <td>-0.105596</td>\n",
              "      <td>0.237094</td>\n",
              "      <td>0.159021</td>\n",
              "      <td>0.055958</td>\n",
              "      <td>-0.161801</td>\n",
              "      <td>0.105222</td>\n",
              "      <td>0.147823</td>\n",
              "      <td>0.026685</td>\n",
              "      <td>0.059532</td>\n",
              "      <td>0.117234</td>\n",
              "      <td>0.064063</td>\n",
              "      <td>0.016387</td>\n",
              "      <td>-0.015661</td>\n",
              "      <td>0.142240</td>\n",
              "      <td>0.177168</td>\n",
              "      <td>-0.066760</td>\n",
              "      <td>0.106400</td>\n",
              "      <td>0.167397</td>\n",
              "      <td>0.047480</td>\n",
              "      <td>...</td>\n",
              "      <td>0.185434</td>\n",
              "      <td>0.091975</td>\n",
              "      <td>0.040803</td>\n",
              "      <td>0.066808</td>\n",
              "      <td>-0.015634</td>\n",
              "      <td>-0.007347</td>\n",
              "      <td>0.165473</td>\n",
              "      <td>0.041894</td>\n",
              "      <td>0.193574</td>\n",
              "      <td>0.004915</td>\n",
              "      <td>0.085066</td>\n",
              "      <td>0.082473</td>\n",
              "      <td>-0.012954</td>\n",
              "      <td>-0.084595</td>\n",
              "      <td>0.112413</td>\n",
              "      <td>0.189654</td>\n",
              "      <td>0.146540</td>\n",
              "      <td>-0.075025</td>\n",
              "      <td>-0.006074</td>\n",
              "      <td>0.014898</td>\n",
              "      <td>0.053050</td>\n",
              "      <td>0.100744</td>\n",
              "      <td>0.187599</td>\n",
              "      <td>0.086372</td>\n",
              "      <td>-0.100047</td>\n",
              "      <td>-0.065204</td>\n",
              "      <td>-0.016283</td>\n",
              "      <td>0.050333</td>\n",
              "      <td>0.018721</td>\n",
              "      <td>0.032135</td>\n",
              "      <td>0.194629</td>\n",
              "      <td>-0.034360</td>\n",
              "      <td>0.241911</td>\n",
              "      <td>-0.094872</td>\n",
              "      <td>0.076623</td>\n",
              "      <td>0.101066</td>\n",
              "      <td>-0.186058</td>\n",
              "      <td>0.078683</td>\n",
              "      <td>0.081244</td>\n",
              "      <td>-0.111201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000060</th>\n",
              "      <td>-0.021159</td>\n",
              "      <td>0.125700</td>\n",
              "      <td>-0.026910</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.178085</td>\n",
              "      <td>0.176415</td>\n",
              "      <td>0.025524</td>\n",
              "      <td>0.103304</td>\n",
              "      <td>0.094681</td>\n",
              "      <td>0.087511</td>\n",
              "      <td>0.031110</td>\n",
              "      <td>0.115337</td>\n",
              "      <td>0.369805</td>\n",
              "      <td>0.158645</td>\n",
              "      <td>0.135941</td>\n",
              "      <td>0.104001</td>\n",
              "      <td>0.026601</td>\n",
              "      <td>0.296269</td>\n",
              "      <td>0.305429</td>\n",
              "      <td>0.199097</td>\n",
              "      <td>0.127579</td>\n",
              "      <td>0.156409</td>\n",
              "      <td>-0.046473</td>\n",
              "      <td>0.031214</td>\n",
              "      <td>0.126763</td>\n",
              "      <td>0.006368</td>\n",
              "      <td>0.272023</td>\n",
              "      <td>0.066901</td>\n",
              "      <td>0.042691</td>\n",
              "      <td>0.142887</td>\n",
              "      <td>0.253146</td>\n",
              "      <td>0.276613</td>\n",
              "      <td>0.158297</td>\n",
              "      <td>0.213465</td>\n",
              "      <td>0.280961</td>\n",
              "      <td>0.082161</td>\n",
              "      <td>0.054212</td>\n",
              "      <td>0.177353</td>\n",
              "      <td>0.171967</td>\n",
              "      <td>0.140361</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016416</td>\n",
              "      <td>0.065066</td>\n",
              "      <td>0.113294</td>\n",
              "      <td>0.249084</td>\n",
              "      <td>0.048593</td>\n",
              "      <td>0.146570</td>\n",
              "      <td>0.088966</td>\n",
              "      <td>0.125445</td>\n",
              "      <td>0.113970</td>\n",
              "      <td>0.061257</td>\n",
              "      <td>-0.018510</td>\n",
              "      <td>0.115044</td>\n",
              "      <td>0.178463</td>\n",
              "      <td>0.144524</td>\n",
              "      <td>0.098360</td>\n",
              "      <td>-0.042493</td>\n",
              "      <td>0.190262</td>\n",
              "      <td>0.153143</td>\n",
              "      <td>0.129936</td>\n",
              "      <td>0.167621</td>\n",
              "      <td>0.240689</td>\n",
              "      <td>0.047773</td>\n",
              "      <td>0.158049</td>\n",
              "      <td>0.017242</td>\n",
              "      <td>0.192288</td>\n",
              "      <td>0.098559</td>\n",
              "      <td>0.234262</td>\n",
              "      <td>0.172853</td>\n",
              "      <td>0.153594</td>\n",
              "      <td>0.259511</td>\n",
              "      <td>0.211723</td>\n",
              "      <td>-0.002448</td>\n",
              "      <td>0.289181</td>\n",
              "      <td>0.101877</td>\n",
              "      <td>0.057986</td>\n",
              "      <td>0.118551</td>\n",
              "      <td>0.005246</td>\n",
              "      <td>0.018182</td>\n",
              "      <td>0.133223</td>\n",
              "      <td>0.102192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000070</th>\n",
              "      <td>0.230919</td>\n",
              "      <td>0.048086</td>\n",
              "      <td>0.194396</td>\n",
              "      <td>0.178085</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.658519</td>\n",
              "      <td>0.103320</td>\n",
              "      <td>0.213751</td>\n",
              "      <td>0.344049</td>\n",
              "      <td>0.187832</td>\n",
              "      <td>0.215465</td>\n",
              "      <td>0.226021</td>\n",
              "      <td>0.029073</td>\n",
              "      <td>0.179910</td>\n",
              "      <td>0.198224</td>\n",
              "      <td>0.239788</td>\n",
              "      <td>0.111998</td>\n",
              "      <td>0.209418</td>\n",
              "      <td>0.262103</td>\n",
              "      <td>0.363887</td>\n",
              "      <td>0.244465</td>\n",
              "      <td>0.167201</td>\n",
              "      <td>0.351404</td>\n",
              "      <td>0.071581</td>\n",
              "      <td>0.286885</td>\n",
              "      <td>-0.196303</td>\n",
              "      <td>0.235813</td>\n",
              "      <td>0.029320</td>\n",
              "      <td>0.166511</td>\n",
              "      <td>0.166894</td>\n",
              "      <td>0.243878</td>\n",
              "      <td>0.293949</td>\n",
              "      <td>0.183960</td>\n",
              "      <td>0.070419</td>\n",
              "      <td>0.150535</td>\n",
              "      <td>0.236201</td>\n",
              "      <td>0.186679</td>\n",
              "      <td>0.268939</td>\n",
              "      <td>0.107885</td>\n",
              "      <td>0.221739</td>\n",
              "      <td>...</td>\n",
              "      <td>0.086512</td>\n",
              "      <td>0.061532</td>\n",
              "      <td>0.316266</td>\n",
              "      <td>0.349720</td>\n",
              "      <td>0.142874</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>0.209065</td>\n",
              "      <td>0.102978</td>\n",
              "      <td>0.225892</td>\n",
              "      <td>0.154792</td>\n",
              "      <td>0.045589</td>\n",
              "      <td>0.165668</td>\n",
              "      <td>0.190191</td>\n",
              "      <td>0.218450</td>\n",
              "      <td>0.419458</td>\n",
              "      <td>0.131596</td>\n",
              "      <td>0.184579</td>\n",
              "      <td>-0.002406</td>\n",
              "      <td>0.238212</td>\n",
              "      <td>0.260696</td>\n",
              "      <td>0.303336</td>\n",
              "      <td>0.166971</td>\n",
              "      <td>0.270145</td>\n",
              "      <td>0.037941</td>\n",
              "      <td>0.070925</td>\n",
              "      <td>0.016534</td>\n",
              "      <td>0.340569</td>\n",
              "      <td>0.391450</td>\n",
              "      <td>0.142830</td>\n",
              "      <td>0.272069</td>\n",
              "      <td>0.212578</td>\n",
              "      <td>-0.019304</td>\n",
              "      <td>0.206811</td>\n",
              "      <td>0.078945</td>\n",
              "      <td>0.159574</td>\n",
              "      <td>-0.169755</td>\n",
              "      <td>0.011747</td>\n",
              "      <td>0.007348</td>\n",
              "      <td>0.377866</td>\n",
              "      <td>-0.103425</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1863 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            000020    000040    000050  ...     99410     99440     99520\n",
              "stock_id                                ...                              \n",
              "000020    1.000000  0.221514 -0.037755  ...  0.170469  0.298094  0.101488\n",
              "000040    0.221514  1.000000 -0.084175  ...  0.106058  0.374286  0.271006\n",
              "000050   -0.037755 -0.084175  1.000000  ...  0.078683  0.081244 -0.111201\n",
              "000060   -0.021159  0.125700 -0.026910  ...  0.018182  0.133223  0.102192\n",
              "000070    0.230919  0.048086  0.194396  ...  0.007348  0.377866 -0.103425\n",
              "\n",
              "[5 rows x 1863 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R23IaMjdYJ6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "afa873a4-d8ea-43e0-d36d-f84a787e2dcd"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/stocks.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock_id</th>\n",
              "      <th>name</th>\n",
              "      <th>date</th>\n",
              "      <th>opening_price</th>\n",
              "      <th>highest_price</th>\n",
              "      <th>lowest_price</th>\n",
              "      <th>closing_price</th>\n",
              "      <th>trading_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>8130</td>\n",
              "      <td>8150</td>\n",
              "      <td>7920</td>\n",
              "      <td>8140</td>\n",
              "      <td>281440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>8040</td>\n",
              "      <td>8250</td>\n",
              "      <td>8000</td>\n",
              "      <td>8190</td>\n",
              "      <td>243179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>8200</td>\n",
              "      <td>8590</td>\n",
              "      <td>8110</td>\n",
              "      <td>8550</td>\n",
              "      <td>609906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>8470</td>\n",
              "      <td>8690</td>\n",
              "      <td>8190</td>\n",
              "      <td>8380</td>\n",
              "      <td>704752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>8210</td>\n",
              "      <td>8900</td>\n",
              "      <td>8130</td>\n",
              "      <td>8770</td>\n",
              "      <td>802330</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  stock_id  name        date  ...  lowest_price  closing_price  trading_volume\n",
              "0   000020  동화약품  2016-01-04  ...          7920           8140          281440\n",
              "1   000020  동화약품  2016-01-05  ...          8000           8190          243179\n",
              "2   000020  동화약품  2016-01-06  ...          8110           8550          609906\n",
              "3   000020  동화약품  2016-01-07  ...          8190           8380          704752\n",
              "4   000020  동화약품  2016-01-08  ...          8130           8770          802330\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9fv6NiqXkAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(corr_df=df, n_epochs=100, dim=32, lr=0.01):\n",
        "  dtype = torch.FloatTensor\n",
        "  epochs = n_epochs\n",
        "  emb_dim = dim\n",
        "  embeddings = Variable(torch.randn(emb_dim, len(df)).type(dtype), requires_grad=True)\n",
        "  lr = lr\n",
        "  optimizer = optim.Adam([embeddings], lr=lr)\n",
        "  mean = np.abs(df).mean().mean()\n",
        "  coef = 2 # Hyper Parameter 변경\n",
        "  loss_track = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    loss = 0\n",
        "    for i in range(len(df)):\n",
        "      v1 = embeddings[:, i].view(emb_dim, -1)\n",
        "      dist = torch.norm(v1 - embeddings, dim=0).view(len(df), 1)\n",
        "      corrs = torch.from_numpy(np.abs(coef*np.array(df.iloc[:, i]))-1).view(1, len(df)).type(torch.FloatTensor)\n",
        "      loss += torch.mm(corrs, dist)/2\n",
        "    loss_track.append(loss.item())\n",
        "    if (epoch+1) % 10 == 0:\n",
        "      print(\"{0}th epoch in process\".format(epoch+1))\n",
        "      print('running loss: {}'.format(loss.item()))\n",
        "      print()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for element in embeddings:\n",
        "        element.clamp_(0,1)\n",
        "\n",
        "  return embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzQw6FxlH5Ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(corr_df=df, n_epochs=100, dim=32, lr=0.01):\n",
        "  dtype = torch.FloatTensor\n",
        "  epochs = n_epochs\n",
        "  emb_dim = dim\n",
        "  embeddings = Variable(torch.randn(emb_dim, len(df)).type(dtype), requires_grad=True)\n",
        "  lr = lr\n",
        "  optimizer = optim.Adam([embeddings], lr=lr)\n",
        "  mean = np.abs(df).mean().mean()\n",
        "  coef = 2 # Hyper Parameter 변경\n",
        "  loss_track = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    loss = 0\n",
        "    for i in range(len(df)):\n",
        "      v1 = embeddings[:, i].view(emb_dim, -1)\n",
        "      dist = torch.norm(v1 - embeddings, dim=0).view(len(df), 1)\n",
        "      corrs = torch.from_numpy(np.abs(coef*np.array(df.iloc[:, i]))-1).view(1, len(df)).type(torch.FloatTensor)\n",
        "      loss += torch.mm(corrs, dist)/2\n",
        "    loss_track.append(loss.item())\n",
        "    if (epoch+1) % 10 == 0:\n",
        "      print(\"{0}th epoch in process\".format(epoch+1))\n",
        "      print('running loss: {}'.format(loss.item()))\n",
        "      print()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for element in embeddings:\n",
        "        element.clamp_(0,1)\n",
        "\n",
        "  return embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lld3RXLKVGEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ta\n",
        "\n",
        "def bias(close=None, m=7):\n",
        "  return close - close.rolling(m).mean()\n",
        "\n",
        "def preprocessing(data=data, year=2016, start_month=7, end_month = 9, corr_df = df):\n",
        "\n",
        "  data['stock_id'] = data['stock_id'].astype(str)\n",
        "  data['year'] = data['date'].apply(lambda x: int(x[0:4]))\n",
        "  data['month'] = data['date'].apply(lambda x: int(x[5:7]))\n",
        "\n",
        "  data = data[(data['year']==year)&(data['month']<=end_month)&(data['month']>=start_month)]\n",
        "  data = data[data['stock_id'].isin(df.columns)]\n",
        "\n",
        "  data['KLength'] = data['closing_price'] - data['opening_price']\n",
        "  data['KUpperLength'] = data['highest_price'] - data[['opening_price', 'closing_price']].max(axis=1)\n",
        "  data['temp'] = data['opening_price']-data['lowest_price']\n",
        "  data['KLowerLength'] = data[['closing_price', 'temp']].min(axis=1)\n",
        "  data['return'] = data['closing_price'].diff()\n",
        "  data = data.drop(columns=['temp'])\n",
        "\n",
        "  data['EMA'] = ta.trend.ema_indicator(close=data['closing_price'])\n",
        "  data['MACD'] = ta.trend.macd(close=data['closing_price'])\n",
        "  data['ROC'] = ta.momentum.roc(close=data['closing_price'])\n",
        "  data['BIAS'] = bias(data['closing_price'])\n",
        "  \n",
        "\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubDYEHvORXt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_optimize(data=data, indicator='KLength', lr=0.005, n_epochs=3000, embeddings=None):\n",
        "  KL = data.pivot(index='date', columns='stock_id', values=indicator)\n",
        "  R = data.pivot(index='date', columns='stock_id', values='return')\n",
        "\n",
        "  if indicator in ['KLength', 'KUpperLength', 'KLowerLength']:\n",
        "    KL = KL.iloc[:-1, ]\n",
        "    R = R.iloc[1:, ]\n",
        "  elif indicator == 'EMA':\n",
        "    KL = KL.iloc[11:-1, ]\n",
        "    R = R.iloc[12:, ]\n",
        "  elif indicator == 'MACD':\n",
        "    KL = KL.iloc[25:-1, ]\n",
        "    R = R.iloc[26:, ]\n",
        "  elif indicator == 'ROC':\n",
        "    KL = KL.iloc[12:-1, ]\n",
        "    R = R.iloc[13:, ]\n",
        "  elif indicator == 'BIAS':\n",
        "    KL = KL.iloc[6:-1, ]\n",
        "    R = R.iloc[7:, ]\n",
        "  else:\n",
        "    print('Unknown Indicator!')\n",
        "    return None\n",
        "\n",
        "  dtype = torch.FloatTensor\n",
        "  weights = Variable(2*torch.rand(1, 32).type(dtype)-1, requires_grad=True)\n",
        "  lr = lr\n",
        "  optimizer = optim.Adam([weights], lr=lr)\n",
        "  epochs = n_epochs\n",
        "  indic = np.array(KL)\n",
        "  returns = np.array(R)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    loss = 0\n",
        "\n",
        "    rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "    opt_ind = torch.from_numpy(indic) * rescale_fc # element-wise\n",
        "  # print('opt_ind: ', opt_ind)\n",
        "    mean_ind = torch.mean(opt_ind, axis=0)\n",
        "  # print('mean_ind: ', mean_ind)\n",
        "    mean_ret = torch.mean(torch.from_numpy(returns), axis=0)\n",
        "  # print('mean_ret: ', mean_ret)\n",
        "\n",
        "    vx = opt_ind - mean_ind\n",
        "    vy = torch.from_numpy(returns) - mean_ret\n",
        "  # print('vx: ', vx)\n",
        "  # print('vy: ', vy)\n",
        "    loss = -torch.abs(torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2))))\n",
        "  # print('loss: ', loss)\n",
        "\n",
        "    if (epoch+1) % 1000 == 0:\n",
        "      print(\"{0}th epoch in process\".format(epoch+1))\n",
        "      print('running loss: {:.4f}'.format(loss.item()))\n",
        "      print()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for weight in weights:\n",
        "        weight.clamp_(0,1)\n",
        "\n",
        "  mean_KL = np.mean(indic, axis=0)\n",
        "  mean_return = np.mean(returns, axis=0)\n",
        "\n",
        "  vx = indic - mean_KL\n",
        "  vy = returns - mean_return\n",
        "\n",
        "  corr1 = np.abs(np.sum(vx*vy) / (np.sqrt(np.sum(vx ** 2)) * np.sqrt(np.sum(vy ** 2))))\n",
        "\n",
        "  rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "  opt_ind = torch.from_numpy(indic) * rescale_fc # element-wise\n",
        "  mean_ind = torch.mean(opt_ind, axis=0)\n",
        "  mean_ret = torch.mean(torch.from_numpy(returns), axis=0)\n",
        "\n",
        "  wx = opt_ind - mean_ind\n",
        "  wy = torch.from_numpy(returns) - mean_ret\n",
        "  corr2 = torch.abs(torch.sum(wx * wy) / (torch.sqrt(torch.sum(wx ** 2)) * torch.sqrt(torch.sum(wy ** 2))))\n",
        "\n",
        "  print(\"Correlation of Raw vs Recaled: {0:.4f} vs {1:.4f}\".format(corr1, corr2))\n",
        "\n",
        "  return weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXjUlAuCMI-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(data=None, weights=None, indicator='KLength'):\n",
        "  KL = data.pivot(index='date', columns='stock_id', values=indicator)\n",
        "  R = data.pivot(index='date', columns='stock_id', values='return')\n",
        "\n",
        "  if indicator in ['KLength', 'KUpperLength', 'KLowerLength']:\n",
        "    KL = KL.iloc[:-1, ]\n",
        "    R = R.iloc[1:, ]\n",
        "  elif indicator == 'EMA':\n",
        "    KL = KL.iloc[11:-1, ]\n",
        "    R = R.iloc[12:, ]\n",
        "  elif indicator == 'MACD':\n",
        "    KL = KL.iloc[25:-1, ]\n",
        "    R = R.iloc[26:, ]\n",
        "  elif indicator == 'ROC':\n",
        "    KL = KL.iloc[12:-1, ]\n",
        "    R = R.iloc[13:, ]\n",
        "  elif indicator == 'BIAS':\n",
        "    KL = KL.iloc[6:-1, ]\n",
        "    R = R.iloc[7:, ]\n",
        "  else:\n",
        "    print('Unknown Indicator!')\n",
        "    return None\n",
        "\n",
        "  indic = np.array(KL)\n",
        "  returns = np.array(R)\n",
        "  mean_KL = np.mean(indic, axis=0)\n",
        "  mean_return = np.mean(returns, axis=0)\n",
        "  vx = indic - mean_KL\n",
        "  vy = returns - mean_return\n",
        "  corr1 = np.abs(np.sum(vx*vy) / (np.sqrt(np.sum(vx ** 2)) * np.sqrt(np.sum(vy ** 2))))\n",
        "\n",
        "  rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "  opt_ind = torch.from_numpy(indic) * rescale_fc\n",
        "  mean_ind = torch.mean(opt_ind, axis=0)\n",
        "\n",
        "  wx = opt_ind - mean_ind\n",
        "  wy = torch.from_numpy(vy)\n",
        "  corr2 = torch.abs(torch.sum(wx * wy) / (torch.sqrt(torch.sum(wx ** 2)) * torch.sqrt(torch.sum(wy ** 2))))\n",
        "\n",
        "  print(\"Correlation of Raw vs Recaled: {0:.4f} vs {1:.4f}\".format(corr1, corr2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhLuytKC5eR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6UvJ9XC5eWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a6dd671-00f9-4b02-efb2-351e54ef9cfb"
      },
      "source": [
        "#### 각 종목별로 Correlation 구해서 평균 내는 방식을 취하면, Correlation Coefficient가 Unit Invariant 하므로 어떤 Weight 곱해서 Rescaling해도 결과가 달라지지 않는다.\n",
        "\n",
        "KL = test_df.pivot(index='date', columns='stock_id', values='KLength')\n",
        "R = test_df.pivot(index='date', columns='stock_id', values='return')\n",
        "KL = KL.iloc[:-1, ]\n",
        "R = R.iloc[1:, ]\n",
        "indic = np.array(KL)\n",
        "returns = np.array(R)\n",
        "mean_KL = np.mean(indic, axis=0)\n",
        "mean_return = np.mean(returns, axis=0)\n",
        "vx = indic - mean_KL\n",
        "vy = returns - mean_return\n",
        "corr1 = np.abs(np.sum(vx*vy, axis=0) / (np.sqrt(np.sum(vx ** 2, axis=0)+1e-10) * np.sqrt(np.sum(vy ** 2, axis=0)+1e-10)))\n",
        "\n",
        "# print(corr1.isnan().sum())\n",
        "# corr1\n",
        "rescale_fc = torch.exp(torch.mm(inds, embeddings)) / torch.sum(torch.exp(torch.mm(inds, embeddings)))\n",
        "opt_ind = torch.from_numpy(indic) * rescale_fc\n",
        "mean_ind = torch.mean(opt_ind, axis=0)\n",
        "\n",
        "wx = opt_ind - mean_ind\n",
        "wy = torch.from_numpy(vy)\n",
        "corr2 = torch.abs(torch.sum(wx * wy, axis=0) / (torch.sqrt(torch.sum(wx ** 2, axis=0)+1e-10) * torch.sqrt(torch.sum(wy ** 2, axis=0)+1e-10)))\n",
        "\n",
        "print(\"Correlation of Raw vs Recaled: {0:.4f} vs {1:.4f}\".format(corr1.mean(), corr2.mean()))\n",
        "\n",
        "#### 내일 할 일\n",
        "#### 여러 가지 Technical Indicator들의 선형결합으로 예측력 시험하기\n",
        "#### 즉, 각 종목에 대한 각 Indicator의 Weight를 학습해서, 이를 이용해서 여러 Indicator 들을 결합, 이 값과 리턴 사이의 상관관계 따져보기\n",
        "\n",
        "#### EX: I_i = weight_1 * I_i,1 + weight_2 * I_i,2 + weight_3 * I_i,3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correlation of Raw vs Recaled: 0.1197 vs 0.1197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OG-RyS75eZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCYgUOYO5ebX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnYJXvf_5eUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va26WZ4fYSVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "1069069e-2478-40d7-c863-46d42526f7ff"
      },
      "source": [
        "embeddings = get_embeddings(corr_df=df)\n",
        "train_df = preprocessing(data=data, year=2016, start_month=1, end_month=6, corr_df=df)\n",
        "test_df = preprocessing(data=data, year=2016, start_month=7, end_month=9, corr_df=df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10th epoch in process\n",
            "running loss: -4036878.75\n",
            "\n",
            "20th epoch in process\n",
            "running loss: -4236393.0\n",
            "\n",
            "30th epoch in process\n",
            "running loss: -4416008.5\n",
            "\n",
            "40th epoch in process\n",
            "running loss: -4566423.0\n",
            "\n",
            "50th epoch in process\n",
            "running loss: -4678634.0\n",
            "\n",
            "60th epoch in process\n",
            "running loss: -4725080.5\n",
            "\n",
            "70th epoch in process\n",
            "running loss: -4728984.0\n",
            "\n",
            "80th epoch in process\n",
            "running loss: -4729123.5\n",
            "\n",
            "90th epoch in process\n",
            "running loss: -4729123.5\n",
            "\n",
            "100th epoch in process\n",
            "running loss: -4729123.5\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNRuR3rP2Etb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e62c65c-68d2-4784-aa4c-354f65f4fed4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2108533, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9qtVNoaNlOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "26687f0f-ec9c-4176-b9fb-aac9d60cc9bd"
      },
      "source": [
        "inds = weight_optimize(indicator='KUpperLength', data=train_df, embeddings=embeddings, n_epochs=1000)\n",
        "test(data=test_df, weights=inds, indicator='KUpperLength')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000th epoch in process\n",
            "running loss: -0.2510\n",
            "\n",
            "Correlation of Raw vs Recaled: 0.2470 vs 0.2510\n",
            "Correlation of Raw vs Recaled: 0.0439 vs 0.0407\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s4Bhj2sSr5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "9b943291-3171-4938-a686-43904f329211"
      },
      "source": [
        "inds = weight_optimize(indicator='KLength', data=train_df, embeddings=embeddings, n_epochs=3000)\n",
        "test(data=test_df, weights=inds, indicator='KLength')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000th epoch in process\n",
            "running loss: -0.2464\n",
            "\n",
            "2000th epoch in process\n",
            "running loss: -0.2484\n",
            "\n",
            "3000th epoch in process\n",
            "running loss: -0.2485\n",
            "\n",
            "Correlation of Raw vs Recaled: 0.2437 vs 0.2485\n",
            "Correlation of Raw vs Recaled: 0.0216 vs 0.0245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jcZSJPCTMZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3a08cde4-0e90-48b3-fa9a-6e55ee651825"
      },
      "source": [
        "inds = weight_optimize(indicator='KLowerLength', lr=0.005, n_epochs=500, embeddings=embeddings, data=train_df)\n",
        "test(data=test_df, weights=inds, indicator='KLowerLength')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correlation of Raw vs Recaled: 0.0306 vs 0.0663\n",
            "Correlation of Raw vs Recaled: 0.0374 vs 0.0209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gahKKo8mYCR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "6a8ad9f1-5721-4c26-80a0-517350e3b3ca"
      },
      "source": [
        "inds = weight_optimize(indicator='EMA', data=train_df, embeddings=embeddings, n_epochs=1000)\n",
        "test(data=test_df, weights=inds, indicator='EMA')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000th epoch in process\n",
            "running loss: -0.0754\n",
            "\n",
            "Correlation of Raw vs Recaled: 0.0665 vs 0.0754\n",
            "Correlation of Raw vs Recaled: 0.1663 vs 0.1417\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw3BYbvc0er4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "bcd91574-88d9-418c-f6cb-6039d5ac4e4a"
      },
      "source": [
        "inds = weight_optimize(indicator='MACD', data=train_df, embeddings=embeddings, n_epochs=2000)\n",
        "test(data=test_df, weights=inds, indicator='MACD')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000th epoch in process\n",
            "running loss: -0.0441\n",
            "\n",
            "2000th epoch in process\n",
            "running loss: -0.0441\n",
            "\n",
            "Correlation of Raw vs Recaled: 0.0346 vs 0.0441\n",
            "Correlation of Raw vs Recaled: 0.0376 vs 0.0429\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWCkVEpIB2Wh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "afe23673-f318-436e-90cf-0025328c75fc"
      },
      "source": [
        "inds = weight_optimize(indicator='ROC', data=train_df, embeddings=embeddings, n_epochs=1500)\n",
        "test(data=test_df, weights=inds, indicator='ROC')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000th epoch in process\n",
            "running loss: -0.0260\n",
            "\n",
            "Correlation of Raw vs Recaled: 0.0073 vs 0.0260\n",
            "Correlation of Raw vs Recaled: 0.0224 vs 0.0081\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHscxGo1B31d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "fbffeab4-fb80-4404-9a45-f115c3f503ce"
      },
      "source": [
        "inds = weight_optimize(indicator='BIAS', data=train_df, embeddings=embeddings, n_epochs=1000)\n",
        "test(data=test_df, weights=inds, indicator='BIAS')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000th epoch in process\n",
            "running loss: -0.0338\n",
            "\n",
            "Correlation of Raw vs Recaled: 0.0212 vs 0.0338\n",
            "Correlation of Raw vs Recaled: 0.0431 vs 0.0930\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiSwsZ3tC2po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}