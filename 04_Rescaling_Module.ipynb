{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Rescaling_Module.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJcmMa7RTxqdfpkKE6WnqA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reyllama/TTIO/blob/master/04_Rescaling_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-cACHlkT1j7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "9108e8d1-9498-4588-f66b-7262f6a1e083"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRuAieuzUfMn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = \"/content/drive/My Drive/corr3.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df = df.set_index(keys='stock_id')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnEB9b_MUxd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor\n",
        "epochs = 100\n",
        "emb_dim = 32\n",
        "embeddings = Variable(torch.randn(emb_dim, len(df)).type(dtype), requires_grad=True)\n",
        "lr = 0.01\n",
        "optimizer = optim.Adam([embeddings], lr=lr)\n",
        "mean = np.abs(df).mean().mean()\n",
        "coef = 1/mean\n",
        "loss_track = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  loss = 0\n",
        "  for i in range(len(df)):\n",
        "    v1 = embeddings[:, i].view(emb_dim, -1)\n",
        "    dist = torch.norm(v1 - embeddings, dim=0).view(len(df), 1)\n",
        "    corrs = torch.from_numpy(np.abs(coef*np.array(df.iloc[:, i]))-1).view(1, len(df)).type(torch.FloatTensor)\n",
        "    loss += torch.mm(corrs, dist)/2\n",
        "  loss_track.append(loss.item())\n",
        "  if (epoch+1) % 5 == 0:\n",
        "    print(\"{0}th epoch in process\".format(epoch+1))\n",
        "    print('running loss: {}'.format(loss.item()))\n",
        "    print()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward(retain_graph=False)\n",
        "  optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for element in embeddings:\n",
        "      element.clamp_(0,1)\n",
        "\n",
        "embeddings[:, 1]  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZKoad26yNlp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.plot(list(range(epochs)), loss_track)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IajAQ7rIZc4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "03eb6c3d-15c4-481a-da8c-54767bf657c0"
      },
      "source": [
        "embeddings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5709, 0.5711, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
              "        [0.5379, 0.5357, 0.0000,  ..., 1.0000, 0.0000, 1.0000],\n",
              "        [0.5088, 0.5078, 1.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [0.5198, 0.5197, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
              "        [0.5329, 0.5329, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.5397, 0.5382, 0.0000,  ..., 0.0000, 1.0000, 0.0000]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8eWvhCbdrYw",
        "colab_type": "text"
      },
      "source": [
        "## Rescaling Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34fi0Cg8Zlvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "3d0419f2-24ba-4b6e-b74a-ee69fc42f44d"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/stocks.csv\")\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock_id</th>\n",
              "      <th>name</th>\n",
              "      <th>date</th>\n",
              "      <th>opening_price</th>\n",
              "      <th>highest_price</th>\n",
              "      <th>lowest_price</th>\n",
              "      <th>closing_price</th>\n",
              "      <th>trading_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>8130</td>\n",
              "      <td>8150</td>\n",
              "      <td>7920</td>\n",
              "      <td>8140</td>\n",
              "      <td>281440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>8040</td>\n",
              "      <td>8250</td>\n",
              "      <td>8000</td>\n",
              "      <td>8190</td>\n",
              "      <td>243179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>8200</td>\n",
              "      <td>8590</td>\n",
              "      <td>8110</td>\n",
              "      <td>8550</td>\n",
              "      <td>609906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>8470</td>\n",
              "      <td>8690</td>\n",
              "      <td>8190</td>\n",
              "      <td>8380</td>\n",
              "      <td>704752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>8210</td>\n",
              "      <td>8900</td>\n",
              "      <td>8130</td>\n",
              "      <td>8770</td>\n",
              "      <td>802330</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  stock_id  name        date  ...  lowest_price  closing_price  trading_volume\n",
              "0   000020  동화약품  2016-01-04  ...          7920           8140          281440\n",
              "1   000020  동화약품  2016-01-05  ...          8000           8190          243179\n",
              "2   000020  동화약품  2016-01-06  ...          8110           8550          609906\n",
              "3   000020  동화약품  2016-01-07  ...          8190           8380          704752\n",
              "4   000020  동화약품  2016-01-08  ...          8130           8770          802330\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uFYSgurgjNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['KLength'] = data['closing_price'] - data['opening_price']\n",
        "data['KUpperLength'] = data['highest_price'] - data[['opening_price', 'closing_price']].max(axis=1)\n",
        "data['temp'] = data['opening_price']-data['lowest_price']\n",
        "data['KLowerLength'] = data[['closing_price', 'temp']].min(axis=1)\n",
        "data['return'] = data['closing_price'].diff()\n",
        "data = data.drop(columns=['temp'])\n",
        "data['stock_id'] = data['stock_id'].astype(str)\n",
        "## 첫날 빼줘야됨 (종목 바뀔때 섞여들어갔다)\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53Wo9fFTw6mI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2383f6bf-b412-4640-c926-89d945a00c56"
      },
      "source": [
        "def year_parser(column):\n",
        "  return int(column[0:4])\n",
        "\n",
        "def month_parser(column):\n",
        "  return int(column[5:7])\n",
        "\n",
        "data['year'] = data['date'].apply(year_parser)\n",
        "data['month'] = data['date'].apply(month_parser)\n",
        "\n",
        "data = data[(data['year']==2016)&(data['month']<=6)]\n",
        "data = data[data['stock_id'].isin(df.columns)]\n",
        "# data = data.fillna(0)\n",
        "\n",
        "KL = data.pivot(index='date', columns='stock_id', values='KLength')\n",
        "R = data.pivot(index='date', columns='stock_id', values='return')\n",
        "\n",
        "KL.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121, 1863)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1CvO91HxkNB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8dde22d3-a9ef-41e8-ea0c-2c7451dd7ee3"
      },
      "source": [
        "print(KL.shape, R.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(121, 2018) (121, 2018)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHYLk-Jf2h6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KL = KL.iloc[:-1, ]\n",
        "R = R.iloc[1:, ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg2JtgELonzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dtype = torch.FloatTensor\n",
        "weights = Variable(torch.rand(1, 32).type(dtype), requires_grad=True)\n",
        "lr = 0.005\n",
        "optimizer = optim.Adam([weights], lr=lr)\n",
        "epochs = 3000\n",
        "indic = np.array(KL)\n",
        "returns = np.array(R)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  loss = 0\n",
        "\n",
        "  rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "  opt_ind = torch.from_numpy(indic) * rescale_fc # element-wise\n",
        "  # print('opt_ind: ', opt_ind)\n",
        "  mean_ind = torch.mean(opt_ind, axis=0)\n",
        "  # print('mean_ind: ', mean_ind)\n",
        "  mean_ret = torch.mean(torch.from_numpy(returns), axis=0)\n",
        "  # print('mean_ret: ', mean_ret)\n",
        "\n",
        "  vx = opt_ind - mean_ind\n",
        "  vy = torch.from_numpy(returns) - mean_ret\n",
        "  # print('vx: ', vx)\n",
        "  # print('vy: ', vy)\n",
        "  loss = -torch.abs(torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2))))\n",
        "  # print('loss: ', loss)\n",
        "\n",
        "  if (epoch+1) % 100 == 0:\n",
        "    print(\"{0}th epoch in process\".format(epoch+1))\n",
        "    print('running loss: {}'.format(loss.item()))\n",
        "    print()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward(retain_graph=False)\n",
        "  optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for weight in weights:\n",
        "      weight.clamp_(0,1)\n",
        "\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfXGFQLcLkwr",
        "colab_type": "text"
      },
      "source": [
        "### Comparison: Raw KLength vs Rescaled KLength"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UGMCx-TLqsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_KL = np.mean(indic, axis=0)\n",
        "mean_return = np.mean(returns, axis=0)\n",
        "\n",
        "vx = indic - mean_KL\n",
        "vy = returns - mean_return\n",
        "\n",
        "corr1 = np.abs(np.sum(vx*vy) / (np.sqrt(np.sum(vx ** 2)) * np.sqrt(np.sum(vy ** 2))))\n",
        "\n",
        "rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "opt_ind = torch.from_numpy(indic) * rescale_fc # element-wise\n",
        "mean_ind = torch.mean(opt_ind, axis=0)\n",
        "mean_ret = torch.mean(torch.from_numpy(returns), axis=0)\n",
        "\n",
        "wx = opt_ind - mean_ind\n",
        "wy = torch.from_numpy(returns) - mean_ret\n",
        "corr2 = torch.abs(torch.sum(wx * wy) / (torch.sqrt(torch.sum(wx ** 2)) * torch.sqrt(torch.sum(wy ** 2))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_alQ2muNTTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f89dd32d-a36f-43c5-977a-1e73c56658bf"
      },
      "source": [
        "print(\"Correlation of Raw vs Recaled: {0:.4f} vs {1:.4f}\".format(corr1, corr2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correlation of Raw vs Recaled: 0.2428 vs 0.2473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5zZJLxF3icT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDVXPF4v3iaH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "02f6ec97-c730-42d7-eec6-11c402f77a33"
      },
      "source": [
        "!pip install ta"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ta\n",
            "  Downloading https://files.pythonhosted.org/packages/90/ec/e4f5aea8c7f0f55f92b52ffbafa389ea82f3a10d9cab2760e40af34c5b3f/ta-0.5.25.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ta) (1.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->ta) (1.12.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.5.25-cp36-none-any.whl size=24880 sha256=570a505dd5ce4b2c21a3fd9fc98c7c94b2e2c03ca52682f343b7a5f830117ce6\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/93/b7/cf649194508e53cee4145ffb949e9f26877a5a8dd12db9ed5b\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.5.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jmyvrxf3iUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJlhSXFs3iR1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssMhq0J53iXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import ta\n",
        "\n",
        "def bias(close=None, m=7):\n",
        "  return close - close.rolling(m).mean()\n",
        "\n",
        "soda = data.copy()\n",
        "soda['EMA'] = ta.trend.ema_indicator(close=data['closing_price'])\n",
        "soda['MACD'] = ta.trend.macd(close=data['closing_price'])\n",
        "soda['ROC'] = ta.momentum.roc(close=data['closing_price'])\n",
        "soda['BIAS'] = bias(soda['closing_price'])\n",
        "soda.iloc[3:28]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2dS9IsTIx94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BxGS-NHIx8s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "05ae65d7-cb18-402c-ebca-56ef10fb3962"
      },
      "source": [
        "path = \"/content/drive/My Drive/stocks_merged.csv\"\n",
        "merg = pd.read_csv(path)\n",
        "merg.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>stock_id</th>\n",
              "      <th>name</th>\n",
              "      <th>date</th>\n",
              "      <th>opening_price</th>\n",
              "      <th>highest_price</th>\n",
              "      <th>lowest_price</th>\n",
              "      <th>closing_price</th>\n",
              "      <th>trading_volume</th>\n",
              "      <th>industry</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>8130</td>\n",
              "      <td>8150</td>\n",
              "      <td>7920</td>\n",
              "      <td>8140</td>\n",
              "      <td>281440</td>\n",
              "      <td>의약품 제조업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>8040</td>\n",
              "      <td>8250</td>\n",
              "      <td>8000</td>\n",
              "      <td>8190</td>\n",
              "      <td>243179</td>\n",
              "      <td>의약품 제조업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>20</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>8200</td>\n",
              "      <td>8590</td>\n",
              "      <td>8110</td>\n",
              "      <td>8550</td>\n",
              "      <td>609906</td>\n",
              "      <td>의약품 제조업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>20</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>8470</td>\n",
              "      <td>8690</td>\n",
              "      <td>8190</td>\n",
              "      <td>8380</td>\n",
              "      <td>704752</td>\n",
              "      <td>의약품 제조업</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>8210</td>\n",
              "      <td>8900</td>\n",
              "      <td>8130</td>\n",
              "      <td>8770</td>\n",
              "      <td>802330</td>\n",
              "      <td>의약품 제조업</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 stock_id  name  ... closing_price  trading_volume  industry\n",
              "0           0       20  동화약품  ...          8140          281440   의약품 제조업\n",
              "1           1       20  동화약품  ...          8190          243179   의약품 제조업\n",
              "2           2       20  동화약품  ...          8550          609906   의약품 제조업\n",
              "3           3       20  동화약품  ...          8380          704752   의약품 제조업\n",
              "4           4       20  동화약품  ...          8770          802330   의약품 제조업\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tASXwZN7I5en",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3f404685-0c0f-4d1f-dbd4-99ecfadbb9c0"
      },
      "source": [
        "merg['industry'].unique().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(148,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB0RMXF4I5Jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "merg['industry'].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsx8pthRIx4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THIQOXgYIx2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssdqBr-q3iPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxMnV8IzSgcv",
        "colab_type": "text"
      },
      "source": [
        "### Modulate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8g0r5FYJ92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "d0469022-0d9f-489c-b29a-66445688f0b3"
      },
      "source": [
        "path = \"/content/drive/My Drive/corr3.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df = df.set_index(keys='stock_id')\n",
        "df.head()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000020</th>\n",
              "      <th>000040</th>\n",
              "      <th>000050</th>\n",
              "      <th>000060</th>\n",
              "      <th>000070</th>\n",
              "      <th>000075</th>\n",
              "      <th>000080</th>\n",
              "      <th>000087</th>\n",
              "      <th>000100</th>\n",
              "      <th>000105</th>\n",
              "      <th>000120</th>\n",
              "      <th>000140</th>\n",
              "      <th>000145</th>\n",
              "      <th>000150</th>\n",
              "      <th>000155</th>\n",
              "      <th>000157</th>\n",
              "      <th>000180</th>\n",
              "      <th>000210</th>\n",
              "      <th>000215</th>\n",
              "      <th>000220</th>\n",
              "      <th>000225</th>\n",
              "      <th>000227</th>\n",
              "      <th>000230</th>\n",
              "      <th>000240</th>\n",
              "      <th>000250</th>\n",
              "      <th>000270</th>\n",
              "      <th>000300</th>\n",
              "      <th>000320</th>\n",
              "      <th>000325</th>\n",
              "      <th>000370</th>\n",
              "      <th>000390</th>\n",
              "      <th>000400</th>\n",
              "      <th>000430</th>\n",
              "      <th>000440</th>\n",
              "      <th>000480</th>\n",
              "      <th>000490</th>\n",
              "      <th>000500</th>\n",
              "      <th>000520</th>\n",
              "      <th>000540</th>\n",
              "      <th>000545</th>\n",
              "      <th>...</th>\n",
              "      <th>95190</th>\n",
              "      <th>95270</th>\n",
              "      <th>95340</th>\n",
              "      <th>95500</th>\n",
              "      <th>95570</th>\n",
              "      <th>95610</th>\n",
              "      <th>95660</th>\n",
              "      <th>95700</th>\n",
              "      <th>95720</th>\n",
              "      <th>95910</th>\n",
              "      <th>96040</th>\n",
              "      <th>96240</th>\n",
              "      <th>96300</th>\n",
              "      <th>96350</th>\n",
              "      <th>96530</th>\n",
              "      <th>96610</th>\n",
              "      <th>96630</th>\n",
              "      <th>96640</th>\n",
              "      <th>96760</th>\n",
              "      <th>96770</th>\n",
              "      <th>96775</th>\n",
              "      <th>96870</th>\n",
              "      <th>97230</th>\n",
              "      <th>97520</th>\n",
              "      <th>97780</th>\n",
              "      <th>97800</th>\n",
              "      <th>97870</th>\n",
              "      <th>97950</th>\n",
              "      <th>97955</th>\n",
              "      <th>98120</th>\n",
              "      <th>98460</th>\n",
              "      <th>98660</th>\n",
              "      <th>99190</th>\n",
              "      <th>99220</th>\n",
              "      <th>99320</th>\n",
              "      <th>99340</th>\n",
              "      <th>99350</th>\n",
              "      <th>99410</th>\n",
              "      <th>99440</th>\n",
              "      <th>99520</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stock_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000020</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.225326</td>\n",
              "      <td>0.190993</td>\n",
              "      <td>0.091289</td>\n",
              "      <td>0.278384</td>\n",
              "      <td>0.106534</td>\n",
              "      <td>0.099041</td>\n",
              "      <td>0.118218</td>\n",
              "      <td>0.412659</td>\n",
              "      <td>0.149035</td>\n",
              "      <td>0.206372</td>\n",
              "      <td>0.345200</td>\n",
              "      <td>0.239751</td>\n",
              "      <td>0.306873</td>\n",
              "      <td>0.139372</td>\n",
              "      <td>0.083818</td>\n",
              "      <td>0.432648</td>\n",
              "      <td>0.320367</td>\n",
              "      <td>0.314789</td>\n",
              "      <td>0.477852</td>\n",
              "      <td>0.390176</td>\n",
              "      <td>0.346164</td>\n",
              "      <td>0.213423</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.410569</td>\n",
              "      <td>0.105879</td>\n",
              "      <td>0.404843</td>\n",
              "      <td>0.133121</td>\n",
              "      <td>0.297274</td>\n",
              "      <td>0.332258</td>\n",
              "      <td>0.313026</td>\n",
              "      <td>0.379187</td>\n",
              "      <td>0.141835</td>\n",
              "      <td>0.161505</td>\n",
              "      <td>0.030559</td>\n",
              "      <td>0.196879</td>\n",
              "      <td>0.188596</td>\n",
              "      <td>0.499444</td>\n",
              "      <td>-0.028242</td>\n",
              "      <td>-0.026712</td>\n",
              "      <td>...</td>\n",
              "      <td>0.209581</td>\n",
              "      <td>0.232547</td>\n",
              "      <td>0.223981</td>\n",
              "      <td>0.328538</td>\n",
              "      <td>0.087554</td>\n",
              "      <td>0.116857</td>\n",
              "      <td>0.409012</td>\n",
              "      <td>0.511532</td>\n",
              "      <td>0.203512</td>\n",
              "      <td>0.285751</td>\n",
              "      <td>0.129244</td>\n",
              "      <td>0.153266</td>\n",
              "      <td>0.126188</td>\n",
              "      <td>0.305188</td>\n",
              "      <td>0.455201</td>\n",
              "      <td>0.086679</td>\n",
              "      <td>0.397978</td>\n",
              "      <td>0.274513</td>\n",
              "      <td>0.518429</td>\n",
              "      <td>0.076621</td>\n",
              "      <td>0.031647</td>\n",
              "      <td>0.166450</td>\n",
              "      <td>0.253614</td>\n",
              "      <td>0.197545</td>\n",
              "      <td>0.058612</td>\n",
              "      <td>0.349249</td>\n",
              "      <td>0.347917</td>\n",
              "      <td>0.187737</td>\n",
              "      <td>0.226750</td>\n",
              "      <td>0.126712</td>\n",
              "      <td>0.085994</td>\n",
              "      <td>0.004352</td>\n",
              "      <td>0.375279</td>\n",
              "      <td>0.250622</td>\n",
              "      <td>0.217417</td>\n",
              "      <td>0.139307</td>\n",
              "      <td>0.094990</td>\n",
              "      <td>0.378860</td>\n",
              "      <td>0.353696</td>\n",
              "      <td>0.209319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000040</th>\n",
              "      <td>0.225326</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.094916</td>\n",
              "      <td>-0.004544</td>\n",
              "      <td>0.059474</td>\n",
              "      <td>0.060820</td>\n",
              "      <td>0.124682</td>\n",
              "      <td>0.056387</td>\n",
              "      <td>0.209455</td>\n",
              "      <td>0.054128</td>\n",
              "      <td>-0.075235</td>\n",
              "      <td>0.119661</td>\n",
              "      <td>0.236891</td>\n",
              "      <td>-0.060359</td>\n",
              "      <td>-0.035623</td>\n",
              "      <td>-0.035829</td>\n",
              "      <td>0.317652</td>\n",
              "      <td>0.176512</td>\n",
              "      <td>0.020059</td>\n",
              "      <td>0.328834</td>\n",
              "      <td>0.247685</td>\n",
              "      <td>0.211691</td>\n",
              "      <td>0.115099</td>\n",
              "      <td>-0.014752</td>\n",
              "      <td>0.139633</td>\n",
              "      <td>-0.096755</td>\n",
              "      <td>0.314768</td>\n",
              "      <td>0.189131</td>\n",
              "      <td>0.358526</td>\n",
              "      <td>-0.004887</td>\n",
              "      <td>0.193405</td>\n",
              "      <td>0.059967</td>\n",
              "      <td>0.100306</td>\n",
              "      <td>0.149209</td>\n",
              "      <td>0.122399</td>\n",
              "      <td>0.201767</td>\n",
              "      <td>0.035985</td>\n",
              "      <td>0.317873</td>\n",
              "      <td>-0.162010</td>\n",
              "      <td>-0.180628</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016408</td>\n",
              "      <td>0.144741</td>\n",
              "      <td>0.088078</td>\n",
              "      <td>0.200713</td>\n",
              "      <td>0.163985</td>\n",
              "      <td>0.314903</td>\n",
              "      <td>0.265392</td>\n",
              "      <td>0.203224</td>\n",
              "      <td>0.180150</td>\n",
              "      <td>0.190553</td>\n",
              "      <td>0.126491</td>\n",
              "      <td>0.150775</td>\n",
              "      <td>0.060059</td>\n",
              "      <td>0.246017</td>\n",
              "      <td>0.192996</td>\n",
              "      <td>0.088002</td>\n",
              "      <td>0.305419</td>\n",
              "      <td>0.062956</td>\n",
              "      <td>0.216271</td>\n",
              "      <td>0.089516</td>\n",
              "      <td>0.072886</td>\n",
              "      <td>0.211917</td>\n",
              "      <td>0.113564</td>\n",
              "      <td>0.218824</td>\n",
              "      <td>0.149922</td>\n",
              "      <td>0.178068</td>\n",
              "      <td>0.321512</td>\n",
              "      <td>0.088847</td>\n",
              "      <td>0.075557</td>\n",
              "      <td>0.054879</td>\n",
              "      <td>0.014856</td>\n",
              "      <td>0.178596</td>\n",
              "      <td>0.206972</td>\n",
              "      <td>0.239557</td>\n",
              "      <td>0.201670</td>\n",
              "      <td>0.112794</td>\n",
              "      <td>0.182726</td>\n",
              "      <td>0.236256</td>\n",
              "      <td>0.229121</td>\n",
              "      <td>0.138442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000050</th>\n",
              "      <td>0.190993</td>\n",
              "      <td>0.094916</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.083876</td>\n",
              "      <td>0.053535</td>\n",
              "      <td>0.275152</td>\n",
              "      <td>-0.268272</td>\n",
              "      <td>-0.078420</td>\n",
              "      <td>0.606344</td>\n",
              "      <td>0.287126</td>\n",
              "      <td>0.116990</td>\n",
              "      <td>-0.094776</td>\n",
              "      <td>-0.187100</td>\n",
              "      <td>0.077364</td>\n",
              "      <td>0.044405</td>\n",
              "      <td>0.031376</td>\n",
              "      <td>0.086244</td>\n",
              "      <td>0.099625</td>\n",
              "      <td>0.065717</td>\n",
              "      <td>0.143305</td>\n",
              "      <td>-0.029988</td>\n",
              "      <td>-0.000439</td>\n",
              "      <td>0.136625</td>\n",
              "      <td>0.036080</td>\n",
              "      <td>0.074330</td>\n",
              "      <td>0.096108</td>\n",
              "      <td>0.037376</td>\n",
              "      <td>-0.057867</td>\n",
              "      <td>-0.014226</td>\n",
              "      <td>-0.187444</td>\n",
              "      <td>0.013196</td>\n",
              "      <td>0.028301</td>\n",
              "      <td>0.104206</td>\n",
              "      <td>-0.081945</td>\n",
              "      <td>-0.027956</td>\n",
              "      <td>0.079866</td>\n",
              "      <td>0.053133</td>\n",
              "      <td>0.010611</td>\n",
              "      <td>-0.010329</td>\n",
              "      <td>0.026074</td>\n",
              "      <td>...</td>\n",
              "      <td>0.135364</td>\n",
              "      <td>-0.037521</td>\n",
              "      <td>0.082185</td>\n",
              "      <td>0.108906</td>\n",
              "      <td>0.072816</td>\n",
              "      <td>0.078859</td>\n",
              "      <td>0.056908</td>\n",
              "      <td>0.129180</td>\n",
              "      <td>-0.035751</td>\n",
              "      <td>0.013647</td>\n",
              "      <td>0.154071</td>\n",
              "      <td>-0.002654</td>\n",
              "      <td>0.084687</td>\n",
              "      <td>0.167558</td>\n",
              "      <td>0.256896</td>\n",
              "      <td>0.053647</td>\n",
              "      <td>0.098211</td>\n",
              "      <td>0.046830</td>\n",
              "      <td>0.451140</td>\n",
              "      <td>0.012075</td>\n",
              "      <td>-0.201710</td>\n",
              "      <td>-0.140452</td>\n",
              "      <td>0.082391</td>\n",
              "      <td>0.032930</td>\n",
              "      <td>0.079592</td>\n",
              "      <td>0.176558</td>\n",
              "      <td>0.064341</td>\n",
              "      <td>0.067198</td>\n",
              "      <td>0.133828</td>\n",
              "      <td>0.052540</td>\n",
              "      <td>0.082745</td>\n",
              "      <td>0.061835</td>\n",
              "      <td>0.090441</td>\n",
              "      <td>-0.011121</td>\n",
              "      <td>0.127440</td>\n",
              "      <td>-0.062998</td>\n",
              "      <td>-0.092143</td>\n",
              "      <td>0.034857</td>\n",
              "      <td>0.005743</td>\n",
              "      <td>0.041519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000060</th>\n",
              "      <td>0.091289</td>\n",
              "      <td>-0.004544</td>\n",
              "      <td>-0.083876</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.123051</td>\n",
              "      <td>-0.029442</td>\n",
              "      <td>0.098188</td>\n",
              "      <td>0.163410</td>\n",
              "      <td>0.002685</td>\n",
              "      <td>0.071211</td>\n",
              "      <td>-0.043771</td>\n",
              "      <td>-0.051418</td>\n",
              "      <td>0.129886</td>\n",
              "      <td>0.203375</td>\n",
              "      <td>0.195282</td>\n",
              "      <td>0.178852</td>\n",
              "      <td>0.050663</td>\n",
              "      <td>0.066275</td>\n",
              "      <td>0.109603</td>\n",
              "      <td>-0.094076</td>\n",
              "      <td>-0.045850</td>\n",
              "      <td>0.051034</td>\n",
              "      <td>0.121892</td>\n",
              "      <td>0.056922</td>\n",
              "      <td>-0.004314</td>\n",
              "      <td>0.090554</td>\n",
              "      <td>0.166817</td>\n",
              "      <td>0.076133</td>\n",
              "      <td>0.061512</td>\n",
              "      <td>0.173798</td>\n",
              "      <td>0.181533</td>\n",
              "      <td>0.223820</td>\n",
              "      <td>-0.088203</td>\n",
              "      <td>0.060220</td>\n",
              "      <td>0.022132</td>\n",
              "      <td>0.076012</td>\n",
              "      <td>0.134598</td>\n",
              "      <td>0.146300</td>\n",
              "      <td>-0.086350</td>\n",
              "      <td>-0.084896</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.026554</td>\n",
              "      <td>0.061883</td>\n",
              "      <td>0.024242</td>\n",
              "      <td>0.119134</td>\n",
              "      <td>-0.119198</td>\n",
              "      <td>0.044423</td>\n",
              "      <td>0.093497</td>\n",
              "      <td>0.095074</td>\n",
              "      <td>0.239250</td>\n",
              "      <td>0.063026</td>\n",
              "      <td>0.053660</td>\n",
              "      <td>-0.017570</td>\n",
              "      <td>0.022427</td>\n",
              "      <td>0.145879</td>\n",
              "      <td>0.009135</td>\n",
              "      <td>0.019071</td>\n",
              "      <td>0.059579</td>\n",
              "      <td>-0.004432</td>\n",
              "      <td>-0.074869</td>\n",
              "      <td>0.135409</td>\n",
              "      <td>0.117887</td>\n",
              "      <td>0.165979</td>\n",
              "      <td>0.108465</td>\n",
              "      <td>0.102076</td>\n",
              "      <td>-0.015843</td>\n",
              "      <td>0.125635</td>\n",
              "      <td>0.013862</td>\n",
              "      <td>0.142093</td>\n",
              "      <td>0.147167</td>\n",
              "      <td>0.080525</td>\n",
              "      <td>0.143968</td>\n",
              "      <td>-0.053646</td>\n",
              "      <td>0.110692</td>\n",
              "      <td>-0.067616</td>\n",
              "      <td>-0.014384</td>\n",
              "      <td>0.021044</td>\n",
              "      <td>0.051751</td>\n",
              "      <td>-0.029011</td>\n",
              "      <td>0.158526</td>\n",
              "      <td>-0.000352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000070</th>\n",
              "      <td>0.278384</td>\n",
              "      <td>0.059474</td>\n",
              "      <td>0.053535</td>\n",
              "      <td>0.123051</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.130724</td>\n",
              "      <td>0.179808</td>\n",
              "      <td>0.259878</td>\n",
              "      <td>0.191164</td>\n",
              "      <td>0.066421</td>\n",
              "      <td>0.237759</td>\n",
              "      <td>0.138221</td>\n",
              "      <td>0.178195</td>\n",
              "      <td>0.072153</td>\n",
              "      <td>0.176960</td>\n",
              "      <td>0.036070</td>\n",
              "      <td>0.226709</td>\n",
              "      <td>0.106451</td>\n",
              "      <td>-0.011214</td>\n",
              "      <td>0.206232</td>\n",
              "      <td>0.106381</td>\n",
              "      <td>0.144500</td>\n",
              "      <td>0.209959</td>\n",
              "      <td>0.026213</td>\n",
              "      <td>0.118763</td>\n",
              "      <td>0.014829</td>\n",
              "      <td>0.098732</td>\n",
              "      <td>0.195508</td>\n",
              "      <td>0.053784</td>\n",
              "      <td>0.183455</td>\n",
              "      <td>0.229235</td>\n",
              "      <td>-0.043288</td>\n",
              "      <td>0.096291</td>\n",
              "      <td>0.068382</td>\n",
              "      <td>0.137581</td>\n",
              "      <td>0.039107</td>\n",
              "      <td>0.109441</td>\n",
              "      <td>0.221605</td>\n",
              "      <td>0.010337</td>\n",
              "      <td>0.026602</td>\n",
              "      <td>...</td>\n",
              "      <td>0.107730</td>\n",
              "      <td>-0.008949</td>\n",
              "      <td>0.089749</td>\n",
              "      <td>0.200663</td>\n",
              "      <td>-0.059648</td>\n",
              "      <td>0.035142</td>\n",
              "      <td>0.202297</td>\n",
              "      <td>0.202196</td>\n",
              "      <td>0.044390</td>\n",
              "      <td>0.280470</td>\n",
              "      <td>0.139783</td>\n",
              "      <td>-0.057903</td>\n",
              "      <td>-0.087070</td>\n",
              "      <td>0.174911</td>\n",
              "      <td>0.033999</td>\n",
              "      <td>0.044249</td>\n",
              "      <td>-0.011471</td>\n",
              "      <td>0.184753</td>\n",
              "      <td>0.206043</td>\n",
              "      <td>0.118627</td>\n",
              "      <td>0.046194</td>\n",
              "      <td>0.145293</td>\n",
              "      <td>0.164505</td>\n",
              "      <td>0.058147</td>\n",
              "      <td>0.007321</td>\n",
              "      <td>0.244106</td>\n",
              "      <td>0.107047</td>\n",
              "      <td>0.246410</td>\n",
              "      <td>0.260994</td>\n",
              "      <td>0.011950</td>\n",
              "      <td>0.028499</td>\n",
              "      <td>0.075769</td>\n",
              "      <td>0.077957</td>\n",
              "      <td>0.207139</td>\n",
              "      <td>0.044418</td>\n",
              "      <td>0.068595</td>\n",
              "      <td>-0.101294</td>\n",
              "      <td>0.316799</td>\n",
              "      <td>0.293462</td>\n",
              "      <td>0.051838</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1863 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            000020    000040    000050  ...     99410     99440     99520\n",
              "stock_id                                ...                              \n",
              "000020    1.000000  0.225326  0.190993  ...  0.378860  0.353696  0.209319\n",
              "000040    0.225326  1.000000  0.094916  ...  0.236256  0.229121  0.138442\n",
              "000050    0.190993  0.094916  1.000000  ...  0.034857  0.005743  0.041519\n",
              "000060    0.091289 -0.004544 -0.083876  ... -0.029011  0.158526 -0.000352\n",
              "000070    0.278384  0.059474  0.053535  ...  0.316799  0.293462  0.051838\n",
              "\n",
              "[5 rows x 1863 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R23IaMjdYJ6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "5be8d679-54b8-49c4-c0ae-9329505c5f61"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/stocks.csv\")\n",
        "data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock_id</th>\n",
              "      <th>name</th>\n",
              "      <th>date</th>\n",
              "      <th>opening_price</th>\n",
              "      <th>highest_price</th>\n",
              "      <th>lowest_price</th>\n",
              "      <th>closing_price</th>\n",
              "      <th>trading_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>8130</td>\n",
              "      <td>8150</td>\n",
              "      <td>7920</td>\n",
              "      <td>8140</td>\n",
              "      <td>281440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>8040</td>\n",
              "      <td>8250</td>\n",
              "      <td>8000</td>\n",
              "      <td>8190</td>\n",
              "      <td>243179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>8200</td>\n",
              "      <td>8590</td>\n",
              "      <td>8110</td>\n",
              "      <td>8550</td>\n",
              "      <td>609906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>8470</td>\n",
              "      <td>8690</td>\n",
              "      <td>8190</td>\n",
              "      <td>8380</td>\n",
              "      <td>704752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>8210</td>\n",
              "      <td>8900</td>\n",
              "      <td>8130</td>\n",
              "      <td>8770</td>\n",
              "      <td>802330</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  stock_id  name        date  ...  lowest_price  closing_price  trading_volume\n",
              "0   000020  동화약품  2016-01-04  ...          7920           8140          281440\n",
              "1   000020  동화약품  2016-01-05  ...          8000           8190          243179\n",
              "2   000020  동화약품  2016-01-06  ...          8110           8550          609906\n",
              "3   000020  동화약품  2016-01-07  ...          8190           8380          704752\n",
              "4   000020  동화약품  2016-01-08  ...          8130           8770          802330\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9fv6NiqXkAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(corr_df=df, n_epochs=100, dim=32, lr=0.01):\n",
        "  dtype = torch.FloatTensor\n",
        "  epochs = n_epochs\n",
        "  emb_dim = dim\n",
        "  embeddings = Variable(torch.randn(emb_dim, len(df)).type(dtype), requires_grad=True)\n",
        "  lr = lr\n",
        "  optimizer = optim.Adam([embeddings], lr=lr)\n",
        "  mean = np.abs(df).mean().mean()\n",
        "  coef = 2 # Hyper Parameter 변경\n",
        "  loss_track = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    loss = 0\n",
        "    for i in range(len(df)):\n",
        "      v1 = embeddings[:, i].view(emb_dim, -1)\n",
        "      dist = torch.norm(v1 - embeddings, dim=0).view(len(df), 1)\n",
        "      corrs = torch.from_numpy(np.abs(coef*np.array(df.iloc[:, i]))-1).view(1, len(df)).type(torch.FloatTensor)\n",
        "      loss += torch.mm(corrs, dist)/2\n",
        "    loss_track.append(loss.item())\n",
        "    if (epoch+1) % 10 == 0:\n",
        "      print(\"{0}th epoch in process\".format(epoch+1))\n",
        "      print('running loss: {}'.format(loss.item()))\n",
        "      print()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for element in embeddings:\n",
        "        element.clamp_(0,1)\n",
        "\n",
        "  return embeddings"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzQw6FxlH5Ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(corr_df=df, n_epochs=100, dim=32, lr=0.01):\n",
        "  dtype = torch.FloatTensor\n",
        "  epochs = n_epochs\n",
        "  emb_dim = dim\n",
        "  embeddings = Variable(torch.randn(emb_dim, len(df)).type(dtype), requires_grad=True)\n",
        "  lr = lr\n",
        "  optimizer = optim.Adam([embeddings], lr=lr)\n",
        "  mean = np.abs(df).mean().mean()\n",
        "  coef = 2 # Hyper Parameter 변경\n",
        "  loss_track = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    loss = 0\n",
        "    for i in range(len(df)):\n",
        "      v1 = embeddings[:, i].view(emb_dim, -1)\n",
        "      dist = torch.norm(v1 - embeddings, dim=0).view(len(df), 1)\n",
        "      corrs = torch.from_numpy(np.abs(coef*np.array(df.iloc[:, i]))-1).view(1, len(df)).type(torch.FloatTensor)\n",
        "      loss += torch.mm(corrs, dist)/2\n",
        "    loss_track.append(loss.item())\n",
        "    if (epoch+1) % 10 == 0:\n",
        "      print(\"{0}th epoch in process\".format(epoch+1))\n",
        "      print('running loss: {}'.format(loss.item()))\n",
        "      print()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for element in embeddings:\n",
        "        element.clamp_(0,1)\n",
        "\n",
        "  return embeddings"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lld3RXLKVGEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "a148d07c-be31-48dd-d03f-5148eb5c901b"
      },
      "source": [
        "!pip install ta\n",
        "import ta\n",
        "\n",
        "def bias(close=None, m=7):\n",
        "  return close - close.rolling(m).mean()\n",
        "\n",
        "def preprocessing(data=data, year=2016, start_month=7, end_month = 9, corr_df = df):\n",
        "\n",
        "  data['stock_id'] = data['stock_id'].astype(str)\n",
        "  data['year'] = data['date'].apply(lambda x: int(x[0:4]))\n",
        "  data['month'] = data['date'].apply(lambda x: int(x[5:7]))\n",
        "\n",
        "  data = data[(data['year']==year)&(data['month']<=end_month)&(data['month']>=start_month)]\n",
        "  data = data[data['stock_id'].isin(df.columns)]\n",
        "\n",
        "  data['KLength'] = data['closing_price'] - data['opening_price']\n",
        "  data['KUpperLength'] = data['highest_price'] - data[['opening_price', 'closing_price']].max(axis=1)\n",
        "  data['temp'] = data['opening_price']-data['lowest_price']\n",
        "  data['KLowerLength'] = data[['closing_price', 'temp']].min(axis=1)\n",
        "  data['return'] = data['closing_price'].diff()\n",
        "  data = data.drop(columns=['temp'])\n",
        "\n",
        "  data['EMA'] = ta.trend.ema_indicator(close=data['closing_price'])\n",
        "  data['MACD'] = ta.trend.macd(close=data['closing_price'])\n",
        "  data['ROC'] = ta.momentum.roc(close=data['closing_price'])\n",
        "  data['BIAS'] = bias(data['closing_price'])\n",
        "  \n",
        "\n",
        "  return data"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ta\n",
            "  Downloading https://files.pythonhosted.org/packages/90/ec/e4f5aea8c7f0f55f92b52ffbafa389ea82f3a10d9cab2760e40af34c5b3f/ta-0.5.25.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from ta) (1.18.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from ta) (1.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->ta) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->ta) (1.12.0)\n",
            "Building wheels for collected packages: ta\n",
            "  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ta: filename=ta-0.5.25-cp36-none-any.whl size=24880 sha256=9a458e6a71f3a4004fd8931a8e6dc6b1f53f4828ea34ef0221d832d6c390b8d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/93/b7/cf649194508e53cee4145ffb949e9f26877a5a8dd12db9ed5b\n",
            "Successfully built ta\n",
            "Installing collected packages: ta\n",
            "Successfully installed ta-0.5.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubDYEHvORXt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_optimize(data=data, indicator='KLength', lr=0.005, n_epochs=3000, embeddings=None):\n",
        "  KL = data.pivot(index='date', columns='stock_id', values=indicator)\n",
        "  R = data.pivot(index='date', columns='stock_id', values='return')\n",
        "\n",
        "  if indicator in ['KLength', 'KUpperLength', 'KLowerLength']:\n",
        "    KL = KL.iloc[:-1, ]\n",
        "    R = R.iloc[1:, ]\n",
        "  elif indicator == 'EMA':\n",
        "    KL = KL.iloc[11:-1, ]\n",
        "    R = R.iloc[12:, ]\n",
        "  elif indicator == 'MACD':\n",
        "    KL = KL.iloc[25:-1, ]\n",
        "    R = R.iloc[26:, ]\n",
        "  elif indicator == 'ROC':\n",
        "    KL = KL.iloc[12:-1, ]\n",
        "    R = R.iloc[13:, ]\n",
        "  elif indicator == 'BIAS':\n",
        "    KL = KL.iloc[6:-1, ]\n",
        "    R = R.iloc[7:, ]\n",
        "  else:\n",
        "    print('Unknown Indicator!')\n",
        "    return None\n",
        "\n",
        "  dtype = torch.FloatTensor\n",
        "  weights = Variable(2*torch.rand(1, 32).type(dtype)-1, requires_grad=True)\n",
        "  lr = lr\n",
        "  optimizer = optim.Adam([weights], lr=lr)\n",
        "  epochs = n_epochs\n",
        "  indic = np.array(KL)\n",
        "  returns = np.array(R)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    loss = 0\n",
        "\n",
        "    rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "    opt_ind = torch.from_numpy(indic) * rescale_fc # element-wise\n",
        "  # print('opt_ind: ', opt_ind)\n",
        "    mean_ind = torch.mean(opt_ind, axis=0)\n",
        "  # print('mean_ind: ', mean_ind)\n",
        "    mean_ret = torch.mean(torch.from_numpy(returns), axis=0)\n",
        "  # print('mean_ret: ', mean_ret)\n",
        "\n",
        "    vx = opt_ind - mean_ind\n",
        "    vy = torch.from_numpy(returns) - mean_ret\n",
        "  # print('vx: ', vx)\n",
        "  # print('vy: ', vy)\n",
        "    loss = -torch.abs(torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2))))\n",
        "  # print('loss: ', loss)\n",
        "\n",
        "    if (epoch+1) % 1000 == 0:\n",
        "      print(\"{0}th epoch in process\".format(epoch+1))\n",
        "      # print('running loss: {:.4f}'.format(loss.item()))\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for weight in weights:\n",
        "        weight.clamp_(0,1)\n",
        "\n",
        "  mean_KL = np.mean(indic, axis=0)\n",
        "  mean_return = np.mean(returns, axis=0)\n",
        "\n",
        "  vx = indic - mean_KL\n",
        "  vy = returns - mean_return\n",
        "\n",
        "  corr1 = np.abs(np.sum(vx*vy) / (np.sqrt(np.sum(vx ** 2)) * np.sqrt(np.sum(vy ** 2))))\n",
        "\n",
        "  rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "  opt_ind = torch.from_numpy(indic) * rescale_fc # element-wise\n",
        "  mean_ind = torch.mean(opt_ind, axis=0)\n",
        "  mean_ret = torch.mean(torch.from_numpy(returns), axis=0)\n",
        "\n",
        "  wx = opt_ind - mean_ind\n",
        "  wy = torch.from_numpy(returns) - mean_ret\n",
        "  corr2 = torch.abs(torch.sum(wx * wy) / (torch.sqrt(torch.sum(wx ** 2)) * torch.sqrt(torch.sum(wy ** 2))))\n",
        "\n",
        "  # print(\"Correlation of Raw vs Recaled: {0:.4f} vs {1:.4f}\".format(corr1, corr2))\n",
        "\n",
        "  return weights"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXjUlAuCMI-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(data=None, weights=None, indicator='KLength'):\n",
        "  KL = data.pivot(index='date', columns='stock_id', values=indicator)\n",
        "  R = data.pivot(index='date', columns='stock_id', values='return')\n",
        "\n",
        "  if indicator in ['KLength', 'KUpperLength', 'KLowerLength']:\n",
        "    KL = KL.iloc[:-1, ]\n",
        "    R = R.iloc[1:, ]\n",
        "  elif indicator == 'EMA':\n",
        "    KL = KL.iloc[11:-1, ]\n",
        "    R = R.iloc[12:, ]\n",
        "  elif indicator == 'MACD':\n",
        "    KL = KL.iloc[25:-1, ]\n",
        "    R = R.iloc[26:, ]\n",
        "  elif indicator == 'ROC':\n",
        "    KL = KL.iloc[12:-1, ]\n",
        "    R = R.iloc[13:, ]\n",
        "  elif indicator == 'BIAS':\n",
        "    KL = KL.iloc[6:-1, ]\n",
        "    R = R.iloc[7:, ]\n",
        "  else:\n",
        "    print('Unknown Indicator!')\n",
        "    return None\n",
        "\n",
        "  indic = np.array(KL)\n",
        "  returns = np.array(R)\n",
        "  mean_KL = np.mean(indic, axis=0)\n",
        "  mean_return = np.mean(returns, axis=0)\n",
        "  vx = indic - mean_KL\n",
        "  vy = returns - mean_return\n",
        "  corr1 = np.abs(np.sum(vx*vy) / (np.sqrt(np.sum(vx ** 2)) * np.sqrt(np.sum(vy ** 2))))\n",
        "\n",
        "  rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "  opt_ind = torch.from_numpy(indic) * rescale_fc\n",
        "  mean_ind = torch.mean(opt_ind, axis=0)\n",
        "\n",
        "  wx = opt_ind - mean_ind\n",
        "  wy = torch.from_numpy(vy)\n",
        "  corr2 = torch.abs(torch.sum(wx * wy) / (torch.sqrt(torch.sum(wx ** 2)) * torch.sqrt(torch.sum(wy ** 2))))\n",
        "\n",
        "  # print(\"Correlation of Raw vs Recaled: {0:.4f} vs {1:.4f}\".format(corr1, corr2))\n",
        "  return corr1, corr2"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhLuytKC5eR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6UvJ9XC5eWv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a6dd671-00f9-4b02-efb2-351e54ef9cfb"
      },
      "source": [
        "#### 각 종목별로 Correlation 구해서 평균 내는 방식을 취하면, Correlation Coefficient가 Unit Invariant 하므로 어떤 Weight 곱해서 Rescaling해도 결과가 달라지지 않는다.\n",
        "\n",
        "KL = test_df.pivot(index='date', columns='stock_id', values='KLength')\n",
        "R = test_df.pivot(index='date', columns='stock_id', values='return')\n",
        "KL = KL.iloc[:-1, ]\n",
        "R = R.iloc[1:, ]\n",
        "indic = np.array(KL)\n",
        "returns = np.array(R)\n",
        "mean_KL = np.mean(indic, axis=0)\n",
        "mean_return = np.mean(returns, axis=0)\n",
        "vx = indic - mean_KL\n",
        "vy = returns - mean_return\n",
        "corr1 = np.abs(np.sum(vx*vy, axis=0) / (np.sqrt(np.sum(vx ** 2, axis=0)+1e-10) * np.sqrt(np.sum(vy ** 2, axis=0)+1e-10)))\n",
        "\n",
        "# print(corr1.isnan().sum())\n",
        "# corr1\n",
        "rescale_fc = torch.exp(torch.mm(inds, embeddings)) / torch.sum(torch.exp(torch.mm(inds, embeddings)))\n",
        "opt_ind = torch.from_numpy(indic) * rescale_fc\n",
        "mean_ind = torch.mean(opt_ind, axis=0)\n",
        "\n",
        "wx = opt_ind - mean_ind\n",
        "wy = torch.from_numpy(vy)\n",
        "corr2 = torch.abs(torch.sum(wx * wy, axis=0) / (torch.sqrt(torch.sum(wx ** 2, axis=0)+1e-10) * torch.sqrt(torch.sum(wy ** 2, axis=0)+1e-10)))\n",
        "\n",
        "print(\"Correlation of Raw vs Recaled: {0:.4f} vs {1:.4f}\".format(corr1.mean(), corr2.mean()))\n",
        "\n",
        "#### 내일 할 일\n",
        "#### 여러 가지 Technical Indicator들의 선형결합으로 예측력 시험하기\n",
        "#### 즉, 각 종목에 대한 각 Indicator의 Weight를 학습해서, 이를 이용해서 여러 Indicator 들을 결합, 이 값과 리턴 사이의 상관관계 따져보기\n",
        "\n",
        "#### EX: I_i = weight_1 * I_i,1 + weight_2 * I_i,2 + weight_3 * I_i,3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correlation of Raw vs Recaled: 0.1197 vs 0.1197\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OG-RyS75eZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCYgUOYO5ebX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnYJXvf_5eUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va26WZ4fYSVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        },
        "outputId": "4bed3206-ec6c-4d5c-fe1a-82aeef00c6c1"
      },
      "source": [
        "embeddings = get_embeddings(corr_df=df)\n",
        "train_df = preprocessing(data=data, year=2016, start_month=7, end_month=12, corr_df=df)\n",
        "test_df = preprocessing(data=data, year=2017, start_month=1, end_month=3, corr_df=df)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10th epoch in process\n",
            "running loss: -4120160.5\n",
            "\n",
            "20th epoch in process\n",
            "running loss: -4325860.5\n",
            "\n",
            "30th epoch in process\n",
            "running loss: -4509828.0\n",
            "\n",
            "40th epoch in process\n",
            "running loss: -4664786.0\n",
            "\n",
            "50th epoch in process\n",
            "running loss: -4782411.5\n",
            "\n",
            "60th epoch in process\n",
            "running loss: -4831067.5\n",
            "\n",
            "70th epoch in process\n",
            "running loss: -4835614.0\n",
            "\n",
            "80th epoch in process\n",
            "running loss: -4835986.5\n",
            "\n",
            "90th epoch in process\n",
            "running loss: -4836029.0\n",
            "\n",
            "100th epoch in process\n",
            "running loss: -4836029.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNRuR3rP2Etb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "1e2965aa-5faa-406f-c9c7-62f8cf26ae32"
      },
      "source": [
        "embeddings[7]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0.,  ..., 1., 0., 0.], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gahKKo8mYCR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "de9abbd8-5a84-465d-c682-59ca773a493a"
      },
      "source": [
        "t1, t2 = 0, 0\n",
        "e = 50\n",
        "for _ in range(e):\n",
        "  inds = weight_optimize(indicator='EMA', data=train_df, embeddings=embeddings, n_epochs=300)\n",
        "  x, y = test(data=test_df, weights=inds, indicator='EMA')\n",
        "  t1 += x\n",
        "  t2 += y\n",
        "print()\n",
        "print(\"Average Corr: {0:.4f} vs {1:.4f}\".format(t1/e, t2/e))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average Corr: 0.1671 vs 0.1507\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw3BYbvc0er4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a244b07f-783c-450a-a57c-dd6f9afdf8db"
      },
      "source": [
        "t1, t2 = 0, 0\n",
        "e = 50\n",
        "for _ in range(e):\n",
        "  inds = weight_optimize(indicator='MACD', data=train_df, embeddings=embeddings, n_epochs=300)\n",
        "  x, y = test(data=test_df, weights=inds, indicator='MACD')\n",
        "  t1 += x\n",
        "  t2 += y\n",
        "print()\n",
        "print(\"Average Corr: {0:.4f} vs {1:.4f}\".format(t1/e, t2/e))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average Corr: 0.0475 vs 0.0292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s4Bhj2sSr5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "21f98c63-7638-4cc7-f860-5e638de559a8"
      },
      "source": [
        "t1, t2 = 0, 0\n",
        "e = 50\n",
        "for _ in range(e):\n",
        "  inds = weight_optimize(indicator='KLength', data=train_df, embeddings=embeddings, n_epochs=80)\n",
        "  x, y = test(data=test_df, weights=inds, indicator='KLength')\n",
        "  t1 += x\n",
        "  t2 += y\n",
        "print()\n",
        "print(\"Average Corr: {0:.4f} vs {1:.4f}\".format(t1/e, t2/e))"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average Corr: 0.0600 vs 0.0200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9qtVNoaNlOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "outputId": "2de5bf03-9195-4806-e2fd-c245ac641c67"
      },
      "source": [
        "t1, t2 = 0, 0\n",
        "e = 50\n",
        "for _ in range(e):\n",
        "  inds = weight_optimize(indicator='KUpperLength', data=train_df, embeddings=embeddings, n_epochs=1000)\n",
        "  x, y = test(data=test_df, weights=inds, indicator='KUpperLength')\n",
        "  t1 += x\n",
        "  t2 += y\n",
        "print()\n",
        "print(\"Average Corr: {0:.4f} vs {1:.4f}\".format(t1/e, t2/e))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "1000th epoch in process\n",
            "\n",
            "Average Corr: 0.0753 vs 0.0777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jcZSJPCTMZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "a7cff439-320f-4b97-898d-a37a5a0344b3"
      },
      "source": [
        "t1, t2 = 0, 0\n",
        "e = 50\n",
        "for _ in range(e):\n",
        "  inds = weight_optimize(indicator='KLowerLength', data=train_df, embeddings=embeddings, n_epochs=300)\n",
        "  x, y = test(data=test_df, weights=inds, indicator='KLowerLength')\n",
        "  t1 += x\n",
        "  t2 += y\n",
        "print()\n",
        "print(\"Average Corr: {0:.4f} vs {1:.4f}\".format(t1/e, t2/e))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average Corr: 0.0619 vs 0.0181\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWCkVEpIB2Wh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "00299dde-bb78-4234-bca6-159ae3bfc4a9"
      },
      "source": [
        "t1, t2 = 0, 0\n",
        "e = 50\n",
        "for _ in range(e):\n",
        "  inds = weight_optimize(indicator='ROC', data=train_df, embeddings=embeddings, n_epochs=300)\n",
        "  x, y = test(data=test_df, weights=inds, indicator='ROC')\n",
        "  t1 += x\n",
        "  t2 += y\n",
        "print()\n",
        "print(\"Average Corr: {0:.4f} vs {1:.4f}\".format(t1/e, t2/e))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average Corr: 0.0205 vs 0.0391\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHscxGo1B31d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "44241d69-3b1e-4aad-f3c5-6343ad1e0b33"
      },
      "source": [
        "t1, t2 = 0, 0\n",
        "e = 50\n",
        "for _ in range(e):\n",
        "  inds = weight_optimize(indicator='BIAS', data=train_df, embeddings=embeddings, n_epochs=300)\n",
        "  x, y = test(data=test_df, weights=inds, indicator='BIAS')\n",
        "  t1 += x\n",
        "  t2 += y\n",
        "print()\n",
        "print(\"Average Corr: {0:.4f} vs {1:.4f}\".format(t1/e, t2/e))"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average Corr: 0.0777 vs 0.0567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiSwsZ3tC2po",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "34434a96-7343-4333-ed2d-343e27ff0da3"
      },
      "source": [
        "(0.1663+0.0376+0.0216+0.0439+0.0374+0.0224+0.0431)/7, (0.1417+0.0388+0.0129+0.0419+0.0351+0.0441+0.0922)/7"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.05318571428571428, 0.0581)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KqogkPUzN-r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}