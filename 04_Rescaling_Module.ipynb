{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_Rescaling_Module.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOyFAt4OIm8U9iEvfGaOntT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reyllama/TTIO/blob/master/04_Rescaling_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a-cACHlkT1j7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "375bf3fd-b977-4b3b-8276-56cdc1874fa1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.autograd import Variable\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRuAieuzUfMn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "1ddf3fcb-85e2-49f9-dc20-3b0d9ca31d1f"
      },
      "source": [
        "path = \"/content/drive/My Drive/corr3.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df = df.set_index(keys='stock_id')\n",
        "df.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000020</th>\n",
              "      <th>000040</th>\n",
              "      <th>000050</th>\n",
              "      <th>000060</th>\n",
              "      <th>000070</th>\n",
              "      <th>000075</th>\n",
              "      <th>000080</th>\n",
              "      <th>000087</th>\n",
              "      <th>000100</th>\n",
              "      <th>000105</th>\n",
              "      <th>000120</th>\n",
              "      <th>000140</th>\n",
              "      <th>000145</th>\n",
              "      <th>000150</th>\n",
              "      <th>000155</th>\n",
              "      <th>000157</th>\n",
              "      <th>000180</th>\n",
              "      <th>000210</th>\n",
              "      <th>000215</th>\n",
              "      <th>000220</th>\n",
              "      <th>000225</th>\n",
              "      <th>000227</th>\n",
              "      <th>000230</th>\n",
              "      <th>000240</th>\n",
              "      <th>000250</th>\n",
              "      <th>000270</th>\n",
              "      <th>000300</th>\n",
              "      <th>000320</th>\n",
              "      <th>000325</th>\n",
              "      <th>000370</th>\n",
              "      <th>000390</th>\n",
              "      <th>000400</th>\n",
              "      <th>000430</th>\n",
              "      <th>000440</th>\n",
              "      <th>000480</th>\n",
              "      <th>000490</th>\n",
              "      <th>000500</th>\n",
              "      <th>000520</th>\n",
              "      <th>000540</th>\n",
              "      <th>000545</th>\n",
              "      <th>...</th>\n",
              "      <th>95190</th>\n",
              "      <th>95270</th>\n",
              "      <th>95340</th>\n",
              "      <th>95500</th>\n",
              "      <th>95570</th>\n",
              "      <th>95610</th>\n",
              "      <th>95660</th>\n",
              "      <th>95700</th>\n",
              "      <th>95720</th>\n",
              "      <th>95910</th>\n",
              "      <th>96040</th>\n",
              "      <th>96240</th>\n",
              "      <th>96300</th>\n",
              "      <th>96350</th>\n",
              "      <th>96530</th>\n",
              "      <th>96610</th>\n",
              "      <th>96630</th>\n",
              "      <th>96640</th>\n",
              "      <th>96760</th>\n",
              "      <th>96770</th>\n",
              "      <th>96775</th>\n",
              "      <th>96870</th>\n",
              "      <th>97230</th>\n",
              "      <th>97520</th>\n",
              "      <th>97780</th>\n",
              "      <th>97800</th>\n",
              "      <th>97870</th>\n",
              "      <th>97950</th>\n",
              "      <th>97955</th>\n",
              "      <th>98120</th>\n",
              "      <th>98460</th>\n",
              "      <th>98660</th>\n",
              "      <th>99190</th>\n",
              "      <th>99220</th>\n",
              "      <th>99320</th>\n",
              "      <th>99340</th>\n",
              "      <th>99350</th>\n",
              "      <th>99410</th>\n",
              "      <th>99440</th>\n",
              "      <th>99520</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stock_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000020</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.225326</td>\n",
              "      <td>0.190993</td>\n",
              "      <td>0.091289</td>\n",
              "      <td>0.278384</td>\n",
              "      <td>0.106534</td>\n",
              "      <td>0.099041</td>\n",
              "      <td>0.118218</td>\n",
              "      <td>0.412659</td>\n",
              "      <td>0.149035</td>\n",
              "      <td>0.206372</td>\n",
              "      <td>0.345200</td>\n",
              "      <td>0.239751</td>\n",
              "      <td>0.306873</td>\n",
              "      <td>0.139372</td>\n",
              "      <td>0.083818</td>\n",
              "      <td>0.432648</td>\n",
              "      <td>0.320367</td>\n",
              "      <td>0.314789</td>\n",
              "      <td>0.477852</td>\n",
              "      <td>0.390176</td>\n",
              "      <td>0.346164</td>\n",
              "      <td>0.213423</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.410569</td>\n",
              "      <td>0.105879</td>\n",
              "      <td>0.404843</td>\n",
              "      <td>0.133121</td>\n",
              "      <td>0.297274</td>\n",
              "      <td>0.332258</td>\n",
              "      <td>0.313026</td>\n",
              "      <td>0.379187</td>\n",
              "      <td>0.141835</td>\n",
              "      <td>0.161505</td>\n",
              "      <td>0.030559</td>\n",
              "      <td>0.196879</td>\n",
              "      <td>0.188596</td>\n",
              "      <td>0.499444</td>\n",
              "      <td>-0.028242</td>\n",
              "      <td>-0.026712</td>\n",
              "      <td>...</td>\n",
              "      <td>0.209581</td>\n",
              "      <td>0.232547</td>\n",
              "      <td>0.223981</td>\n",
              "      <td>0.328538</td>\n",
              "      <td>0.087554</td>\n",
              "      <td>0.116857</td>\n",
              "      <td>0.409012</td>\n",
              "      <td>0.511532</td>\n",
              "      <td>0.203512</td>\n",
              "      <td>0.285751</td>\n",
              "      <td>0.129244</td>\n",
              "      <td>0.153266</td>\n",
              "      <td>0.126188</td>\n",
              "      <td>0.305188</td>\n",
              "      <td>0.455201</td>\n",
              "      <td>0.086679</td>\n",
              "      <td>0.397978</td>\n",
              "      <td>0.274513</td>\n",
              "      <td>0.518429</td>\n",
              "      <td>0.076621</td>\n",
              "      <td>0.031647</td>\n",
              "      <td>0.166450</td>\n",
              "      <td>0.253614</td>\n",
              "      <td>0.197545</td>\n",
              "      <td>0.058612</td>\n",
              "      <td>0.349249</td>\n",
              "      <td>0.347917</td>\n",
              "      <td>0.187737</td>\n",
              "      <td>0.226750</td>\n",
              "      <td>0.126712</td>\n",
              "      <td>0.085994</td>\n",
              "      <td>0.004352</td>\n",
              "      <td>0.375279</td>\n",
              "      <td>0.250622</td>\n",
              "      <td>0.217417</td>\n",
              "      <td>0.139307</td>\n",
              "      <td>0.094990</td>\n",
              "      <td>0.378860</td>\n",
              "      <td>0.353696</td>\n",
              "      <td>0.209319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000040</th>\n",
              "      <td>0.225326</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.094916</td>\n",
              "      <td>-0.004544</td>\n",
              "      <td>0.059474</td>\n",
              "      <td>0.060820</td>\n",
              "      <td>0.124682</td>\n",
              "      <td>0.056387</td>\n",
              "      <td>0.209455</td>\n",
              "      <td>0.054128</td>\n",
              "      <td>-0.075235</td>\n",
              "      <td>0.119661</td>\n",
              "      <td>0.236891</td>\n",
              "      <td>-0.060359</td>\n",
              "      <td>-0.035623</td>\n",
              "      <td>-0.035829</td>\n",
              "      <td>0.317652</td>\n",
              "      <td>0.176512</td>\n",
              "      <td>0.020059</td>\n",
              "      <td>0.328834</td>\n",
              "      <td>0.247685</td>\n",
              "      <td>0.211691</td>\n",
              "      <td>0.115099</td>\n",
              "      <td>-0.014752</td>\n",
              "      <td>0.139633</td>\n",
              "      <td>-0.096755</td>\n",
              "      <td>0.314768</td>\n",
              "      <td>0.189131</td>\n",
              "      <td>0.358526</td>\n",
              "      <td>-0.004887</td>\n",
              "      <td>0.193405</td>\n",
              "      <td>0.059967</td>\n",
              "      <td>0.100306</td>\n",
              "      <td>0.149209</td>\n",
              "      <td>0.122399</td>\n",
              "      <td>0.201767</td>\n",
              "      <td>0.035985</td>\n",
              "      <td>0.317873</td>\n",
              "      <td>-0.162010</td>\n",
              "      <td>-0.180628</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016408</td>\n",
              "      <td>0.144741</td>\n",
              "      <td>0.088078</td>\n",
              "      <td>0.200713</td>\n",
              "      <td>0.163985</td>\n",
              "      <td>0.314903</td>\n",
              "      <td>0.265392</td>\n",
              "      <td>0.203224</td>\n",
              "      <td>0.180150</td>\n",
              "      <td>0.190553</td>\n",
              "      <td>0.126491</td>\n",
              "      <td>0.150775</td>\n",
              "      <td>0.060059</td>\n",
              "      <td>0.246017</td>\n",
              "      <td>0.192996</td>\n",
              "      <td>0.088002</td>\n",
              "      <td>0.305419</td>\n",
              "      <td>0.062956</td>\n",
              "      <td>0.216271</td>\n",
              "      <td>0.089516</td>\n",
              "      <td>0.072886</td>\n",
              "      <td>0.211917</td>\n",
              "      <td>0.113564</td>\n",
              "      <td>0.218824</td>\n",
              "      <td>0.149922</td>\n",
              "      <td>0.178068</td>\n",
              "      <td>0.321512</td>\n",
              "      <td>0.088847</td>\n",
              "      <td>0.075557</td>\n",
              "      <td>0.054879</td>\n",
              "      <td>0.014856</td>\n",
              "      <td>0.178596</td>\n",
              "      <td>0.206972</td>\n",
              "      <td>0.239557</td>\n",
              "      <td>0.201670</td>\n",
              "      <td>0.112794</td>\n",
              "      <td>0.182726</td>\n",
              "      <td>0.236256</td>\n",
              "      <td>0.229121</td>\n",
              "      <td>0.138442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000050</th>\n",
              "      <td>0.190993</td>\n",
              "      <td>0.094916</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.083876</td>\n",
              "      <td>0.053535</td>\n",
              "      <td>0.275152</td>\n",
              "      <td>-0.268272</td>\n",
              "      <td>-0.078420</td>\n",
              "      <td>0.606344</td>\n",
              "      <td>0.287126</td>\n",
              "      <td>0.116990</td>\n",
              "      <td>-0.094776</td>\n",
              "      <td>-0.187100</td>\n",
              "      <td>0.077364</td>\n",
              "      <td>0.044405</td>\n",
              "      <td>0.031376</td>\n",
              "      <td>0.086244</td>\n",
              "      <td>0.099625</td>\n",
              "      <td>0.065717</td>\n",
              "      <td>0.143305</td>\n",
              "      <td>-0.029988</td>\n",
              "      <td>-0.000439</td>\n",
              "      <td>0.136625</td>\n",
              "      <td>0.036080</td>\n",
              "      <td>0.074330</td>\n",
              "      <td>0.096108</td>\n",
              "      <td>0.037376</td>\n",
              "      <td>-0.057867</td>\n",
              "      <td>-0.014226</td>\n",
              "      <td>-0.187444</td>\n",
              "      <td>0.013196</td>\n",
              "      <td>0.028301</td>\n",
              "      <td>0.104206</td>\n",
              "      <td>-0.081945</td>\n",
              "      <td>-0.027956</td>\n",
              "      <td>0.079866</td>\n",
              "      <td>0.053133</td>\n",
              "      <td>0.010611</td>\n",
              "      <td>-0.010329</td>\n",
              "      <td>0.026074</td>\n",
              "      <td>...</td>\n",
              "      <td>0.135364</td>\n",
              "      <td>-0.037521</td>\n",
              "      <td>0.082185</td>\n",
              "      <td>0.108906</td>\n",
              "      <td>0.072816</td>\n",
              "      <td>0.078859</td>\n",
              "      <td>0.056908</td>\n",
              "      <td>0.129180</td>\n",
              "      <td>-0.035751</td>\n",
              "      <td>0.013647</td>\n",
              "      <td>0.154071</td>\n",
              "      <td>-0.002654</td>\n",
              "      <td>0.084687</td>\n",
              "      <td>0.167558</td>\n",
              "      <td>0.256896</td>\n",
              "      <td>0.053647</td>\n",
              "      <td>0.098211</td>\n",
              "      <td>0.046830</td>\n",
              "      <td>0.451140</td>\n",
              "      <td>0.012075</td>\n",
              "      <td>-0.201710</td>\n",
              "      <td>-0.140452</td>\n",
              "      <td>0.082391</td>\n",
              "      <td>0.032930</td>\n",
              "      <td>0.079592</td>\n",
              "      <td>0.176558</td>\n",
              "      <td>0.064341</td>\n",
              "      <td>0.067198</td>\n",
              "      <td>0.133828</td>\n",
              "      <td>0.052540</td>\n",
              "      <td>0.082745</td>\n",
              "      <td>0.061835</td>\n",
              "      <td>0.090441</td>\n",
              "      <td>-0.011121</td>\n",
              "      <td>0.127440</td>\n",
              "      <td>-0.062998</td>\n",
              "      <td>-0.092143</td>\n",
              "      <td>0.034857</td>\n",
              "      <td>0.005743</td>\n",
              "      <td>0.041519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000060</th>\n",
              "      <td>0.091289</td>\n",
              "      <td>-0.004544</td>\n",
              "      <td>-0.083876</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.123051</td>\n",
              "      <td>-0.029442</td>\n",
              "      <td>0.098188</td>\n",
              "      <td>0.163410</td>\n",
              "      <td>0.002685</td>\n",
              "      <td>0.071211</td>\n",
              "      <td>-0.043771</td>\n",
              "      <td>-0.051418</td>\n",
              "      <td>0.129886</td>\n",
              "      <td>0.203375</td>\n",
              "      <td>0.195282</td>\n",
              "      <td>0.178852</td>\n",
              "      <td>0.050663</td>\n",
              "      <td>0.066275</td>\n",
              "      <td>0.109603</td>\n",
              "      <td>-0.094076</td>\n",
              "      <td>-0.045850</td>\n",
              "      <td>0.051034</td>\n",
              "      <td>0.121892</td>\n",
              "      <td>0.056922</td>\n",
              "      <td>-0.004314</td>\n",
              "      <td>0.090554</td>\n",
              "      <td>0.166817</td>\n",
              "      <td>0.076133</td>\n",
              "      <td>0.061512</td>\n",
              "      <td>0.173798</td>\n",
              "      <td>0.181533</td>\n",
              "      <td>0.223820</td>\n",
              "      <td>-0.088203</td>\n",
              "      <td>0.060220</td>\n",
              "      <td>0.022132</td>\n",
              "      <td>0.076012</td>\n",
              "      <td>0.134598</td>\n",
              "      <td>0.146300</td>\n",
              "      <td>-0.086350</td>\n",
              "      <td>-0.084896</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.026554</td>\n",
              "      <td>0.061883</td>\n",
              "      <td>0.024242</td>\n",
              "      <td>0.119134</td>\n",
              "      <td>-0.119198</td>\n",
              "      <td>0.044423</td>\n",
              "      <td>0.093497</td>\n",
              "      <td>0.095074</td>\n",
              "      <td>0.239250</td>\n",
              "      <td>0.063026</td>\n",
              "      <td>0.053660</td>\n",
              "      <td>-0.017570</td>\n",
              "      <td>0.022427</td>\n",
              "      <td>0.145879</td>\n",
              "      <td>0.009135</td>\n",
              "      <td>0.019071</td>\n",
              "      <td>0.059579</td>\n",
              "      <td>-0.004432</td>\n",
              "      <td>-0.074869</td>\n",
              "      <td>0.135409</td>\n",
              "      <td>0.117887</td>\n",
              "      <td>0.165979</td>\n",
              "      <td>0.108465</td>\n",
              "      <td>0.102076</td>\n",
              "      <td>-0.015843</td>\n",
              "      <td>0.125635</td>\n",
              "      <td>0.013862</td>\n",
              "      <td>0.142093</td>\n",
              "      <td>0.147167</td>\n",
              "      <td>0.080525</td>\n",
              "      <td>0.143968</td>\n",
              "      <td>-0.053646</td>\n",
              "      <td>0.110692</td>\n",
              "      <td>-0.067616</td>\n",
              "      <td>-0.014384</td>\n",
              "      <td>0.021044</td>\n",
              "      <td>0.051751</td>\n",
              "      <td>-0.029011</td>\n",
              "      <td>0.158526</td>\n",
              "      <td>-0.000352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000070</th>\n",
              "      <td>0.278384</td>\n",
              "      <td>0.059474</td>\n",
              "      <td>0.053535</td>\n",
              "      <td>0.123051</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.130724</td>\n",
              "      <td>0.179808</td>\n",
              "      <td>0.259878</td>\n",
              "      <td>0.191164</td>\n",
              "      <td>0.066421</td>\n",
              "      <td>0.237759</td>\n",
              "      <td>0.138221</td>\n",
              "      <td>0.178195</td>\n",
              "      <td>0.072153</td>\n",
              "      <td>0.176960</td>\n",
              "      <td>0.036070</td>\n",
              "      <td>0.226709</td>\n",
              "      <td>0.106451</td>\n",
              "      <td>-0.011214</td>\n",
              "      <td>0.206232</td>\n",
              "      <td>0.106381</td>\n",
              "      <td>0.144500</td>\n",
              "      <td>0.209959</td>\n",
              "      <td>0.026213</td>\n",
              "      <td>0.118763</td>\n",
              "      <td>0.014829</td>\n",
              "      <td>0.098732</td>\n",
              "      <td>0.195508</td>\n",
              "      <td>0.053784</td>\n",
              "      <td>0.183455</td>\n",
              "      <td>0.229235</td>\n",
              "      <td>-0.043288</td>\n",
              "      <td>0.096291</td>\n",
              "      <td>0.068382</td>\n",
              "      <td>0.137581</td>\n",
              "      <td>0.039107</td>\n",
              "      <td>0.109441</td>\n",
              "      <td>0.221605</td>\n",
              "      <td>0.010337</td>\n",
              "      <td>0.026602</td>\n",
              "      <td>...</td>\n",
              "      <td>0.107730</td>\n",
              "      <td>-0.008949</td>\n",
              "      <td>0.089749</td>\n",
              "      <td>0.200663</td>\n",
              "      <td>-0.059648</td>\n",
              "      <td>0.035142</td>\n",
              "      <td>0.202297</td>\n",
              "      <td>0.202196</td>\n",
              "      <td>0.044390</td>\n",
              "      <td>0.280470</td>\n",
              "      <td>0.139783</td>\n",
              "      <td>-0.057903</td>\n",
              "      <td>-0.087070</td>\n",
              "      <td>0.174911</td>\n",
              "      <td>0.033999</td>\n",
              "      <td>0.044249</td>\n",
              "      <td>-0.011471</td>\n",
              "      <td>0.184753</td>\n",
              "      <td>0.206043</td>\n",
              "      <td>0.118627</td>\n",
              "      <td>0.046194</td>\n",
              "      <td>0.145293</td>\n",
              "      <td>0.164505</td>\n",
              "      <td>0.058147</td>\n",
              "      <td>0.007321</td>\n",
              "      <td>0.244106</td>\n",
              "      <td>0.107047</td>\n",
              "      <td>0.246410</td>\n",
              "      <td>0.260994</td>\n",
              "      <td>0.011950</td>\n",
              "      <td>0.028499</td>\n",
              "      <td>0.075769</td>\n",
              "      <td>0.077957</td>\n",
              "      <td>0.207139</td>\n",
              "      <td>0.044418</td>\n",
              "      <td>0.068595</td>\n",
              "      <td>-0.101294</td>\n",
              "      <td>0.316799</td>\n",
              "      <td>0.293462</td>\n",
              "      <td>0.051838</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1863 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            000020    000040    000050  ...     99410     99440     99520\n",
              "stock_id                                ...                              \n",
              "000020    1.000000  0.225326  0.190993  ...  0.378860  0.353696  0.209319\n",
              "000040    0.225326  1.000000  0.094916  ...  0.236256  0.229121  0.138442\n",
              "000050    0.190993  0.094916  1.000000  ...  0.034857  0.005743  0.041519\n",
              "000060    0.091289 -0.004544 -0.083876  ... -0.029011  0.158526 -0.000352\n",
              "000070    0.278384  0.059474  0.053535  ...  0.316799  0.293462  0.051838\n",
              "\n",
              "[5 rows x 1863 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnEB9b_MUxd_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c20f6cba-198a-46fe-ec17-4a48ae56baac"
      },
      "source": [
        "dtype = torch.FloatTensor\n",
        "epochs = 100\n",
        "emb_dim = 32\n",
        "embeddings = Variable(torch.randn(emb_dim, len(df)).type(dtype), requires_grad=True)\n",
        "lr = 0.01\n",
        "optimizer = optim.Adam([embeddings], lr=lr)\n",
        "mean = np.abs(df).mean().mean()\n",
        "coef = 1/mean\n",
        "loss_track = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  loss = 0\n",
        "  for i in range(len(df)):\n",
        "    v1 = embeddings[:, i].view(emb_dim, -1)\n",
        "    dist = torch.norm(v1 - embeddings, dim=0).view(len(df), 1)\n",
        "    corrs = torch.from_numpy(np.abs(coef*np.array(df.iloc[:, i]))-1).view(1, len(df)).type(torch.FloatTensor)\n",
        "    loss += torch.mm(corrs, dist)/2\n",
        "  loss_track.append(loss.item())\n",
        "  if (epoch+1) % 5 == 0:\n",
        "    print(\"{0}th epoch in process\".format(epoch+1))\n",
        "    print('running loss: {}'.format(loss.item()))\n",
        "    print()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward(retain_graph=False)\n",
        "  optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for element in embeddings:\n",
        "      element.clamp_(0,1)\n",
        "\n",
        "embeddings[:, 1]  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5th epoch in process\n",
            "running loss: -97831.3671875\n",
            "\n",
            "10th epoch in process\n",
            "running loss: -218682.34375\n",
            "\n",
            "15th epoch in process\n",
            "running loss: -340606.78125\n",
            "\n",
            "20th epoch in process\n",
            "running loss: -463022.84375\n",
            "\n",
            "25th epoch in process\n",
            "running loss: -585659.0\n",
            "\n",
            "30th epoch in process\n",
            "running loss: -708346.1875\n",
            "\n",
            "35th epoch in process\n",
            "running loss: -830881.75\n",
            "\n",
            "40th epoch in process\n",
            "running loss: -952611.25\n",
            "\n",
            "45th epoch in process\n",
            "running loss: -1070280.875\n",
            "\n",
            "50th epoch in process\n",
            "running loss: -1168618.625\n",
            "\n",
            "55th epoch in process\n",
            "running loss: -1181287.25\n",
            "\n",
            "60th epoch in process\n",
            "running loss: -1185593.125\n",
            "\n",
            "65th epoch in process\n",
            "running loss: -1209998.5\n",
            "\n",
            "70th epoch in process\n",
            "running loss: -1225115.5\n",
            "\n",
            "75th epoch in process\n",
            "running loss: -1227955.125\n",
            "\n",
            "80th epoch in process\n",
            "running loss: -1238704.25\n",
            "\n",
            "85th epoch in process\n",
            "running loss: -1242066.625\n",
            "\n",
            "90th epoch in process\n",
            "running loss: -1246125.125\n",
            "\n",
            "95th epoch in process\n",
            "running loss: -1250521.625\n",
            "\n",
            "100th epoch in process\n",
            "running loss: -1254425.875\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5711, 0.5357, 0.5078, 0.4733, 0.5553, 0.5402, 0.5506, 0.4912, 0.5515,\n",
              "        0.5293, 0.4965, 0.5365, 0.5250, 0.5272, 0.5324, 0.5115, 0.5403, 0.5241,\n",
              "        0.5117, 0.5242, 0.5466, 0.4941, 0.4811, 0.5217, 0.5078, 0.5238, 0.5280,\n",
              "        0.5249, 0.5247, 0.5197, 0.5329, 0.5382], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZKoad26yNlp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "c6a12a45-7527-44ed-f075-65862d66d515"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.plot(list(range(epochs)), loss_track)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IajAQ7rIZc4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "03eb6c3d-15c4-481a-da8c-54767bf657c0"
      },
      "source": [
        "embeddings"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5709, 0.5711, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
              "        [0.5379, 0.5357, 0.0000,  ..., 1.0000, 0.0000, 1.0000],\n",
              "        [0.5088, 0.5078, 1.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
              "        ...,\n",
              "        [0.5198, 0.5197, 0.0000,  ..., 0.0000, 0.0000, 1.0000],\n",
              "        [0.5329, 0.5329, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
              "        [0.5397, 0.5382, 0.0000,  ..., 0.0000, 1.0000, 0.0000]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8eWvhCbdrYw",
        "colab_type": "text"
      },
      "source": [
        "## Rescaling Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34fi0Cg8Zlvf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "16b22aa6-dc6e-409b-c80e-c00a57df5f82"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/stocks.csv\")\n",
        "data.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock_id</th>\n",
              "      <th>name</th>\n",
              "      <th>date</th>\n",
              "      <th>opening_price</th>\n",
              "      <th>highest_price</th>\n",
              "      <th>lowest_price</th>\n",
              "      <th>closing_price</th>\n",
              "      <th>trading_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>8130</td>\n",
              "      <td>8150</td>\n",
              "      <td>7920</td>\n",
              "      <td>8140</td>\n",
              "      <td>281440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>8040</td>\n",
              "      <td>8250</td>\n",
              "      <td>8000</td>\n",
              "      <td>8190</td>\n",
              "      <td>243179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>8200</td>\n",
              "      <td>8590</td>\n",
              "      <td>8110</td>\n",
              "      <td>8550</td>\n",
              "      <td>609906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>8470</td>\n",
              "      <td>8690</td>\n",
              "      <td>8190</td>\n",
              "      <td>8380</td>\n",
              "      <td>704752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>8210</td>\n",
              "      <td>8900</td>\n",
              "      <td>8130</td>\n",
              "      <td>8770</td>\n",
              "      <td>802330</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  stock_id  name        date  ...  lowest_price  closing_price  trading_volume\n",
              "0   000020  동화약품  2016-01-04  ...          7920           8140          281440\n",
              "1   000020  동화약품  2016-01-05  ...          8000           8190          243179\n",
              "2   000020  동화약품  2016-01-06  ...          8110           8550          609906\n",
              "3   000020  동화약품  2016-01-07  ...          8190           8380          704752\n",
              "4   000020  동화약품  2016-01-08  ...          8130           8770          802330\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uFYSgurgjNp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7f4b6f46-7817-42a6-f117-50a9de1e2a6e"
      },
      "source": [
        "data['KLength'] = data['closing_price'] - data['opening_price']\n",
        "data['KUpperLength'] = data['highest_price'] - data[['opening_price', 'closing_price']].max(axis=1)\n",
        "data['temp'] = data['opening_price']-data['lowest_price']\n",
        "data['KLowerLength'] = data[['closing_price', 'temp']].min(axis=1)\n",
        "data['return'] = data['closing_price'].diff()\n",
        "data = data.drop(columns=['temp'])\n",
        "data['stock_id'] = data['stock_id'].astype(str)\n",
        "## 첫날 빼줘야됨 (종목 바뀔때 섞여들어갔다)\n",
        "data.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock_id</th>\n",
              "      <th>name</th>\n",
              "      <th>date</th>\n",
              "      <th>opening_price</th>\n",
              "      <th>highest_price</th>\n",
              "      <th>lowest_price</th>\n",
              "      <th>closing_price</th>\n",
              "      <th>trading_volume</th>\n",
              "      <th>KLength</th>\n",
              "      <th>KUpperLength</th>\n",
              "      <th>KLowerLength</th>\n",
              "      <th>return</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>8130</td>\n",
              "      <td>8150</td>\n",
              "      <td>7920</td>\n",
              "      <td>8140</td>\n",
              "      <td>281440</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>210</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>8040</td>\n",
              "      <td>8250</td>\n",
              "      <td>8000</td>\n",
              "      <td>8190</td>\n",
              "      <td>243179</td>\n",
              "      <td>150</td>\n",
              "      <td>60</td>\n",
              "      <td>40</td>\n",
              "      <td>50.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>8200</td>\n",
              "      <td>8590</td>\n",
              "      <td>8110</td>\n",
              "      <td>8550</td>\n",
              "      <td>609906</td>\n",
              "      <td>350</td>\n",
              "      <td>40</td>\n",
              "      <td>90</td>\n",
              "      <td>360.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>8470</td>\n",
              "      <td>8690</td>\n",
              "      <td>8190</td>\n",
              "      <td>8380</td>\n",
              "      <td>704752</td>\n",
              "      <td>-90</td>\n",
              "      <td>220</td>\n",
              "      <td>280</td>\n",
              "      <td>-170.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>8210</td>\n",
              "      <td>8900</td>\n",
              "      <td>8130</td>\n",
              "      <td>8770</td>\n",
              "      <td>802330</td>\n",
              "      <td>560</td>\n",
              "      <td>130</td>\n",
              "      <td>80</td>\n",
              "      <td>390.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  stock_id  name        date  ...  KUpperLength  KLowerLength  return\n",
              "0   000020  동화약품  2016-01-04  ...            10           210     NaN\n",
              "1   000020  동화약품  2016-01-05  ...            60            40    50.0\n",
              "2   000020  동화약품  2016-01-06  ...            40            90   360.0\n",
              "3   000020  동화약품  2016-01-07  ...           220           280  -170.0\n",
              "4   000020  동화약품  2016-01-08  ...           130            80   390.0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53Wo9fFTw6mI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2383f6bf-b412-4640-c926-89d945a00c56"
      },
      "source": [
        "def year_parser(column):\n",
        "  return int(column[0:4])\n",
        "\n",
        "def month_parser(column):\n",
        "  return int(column[5:7])\n",
        "\n",
        "data['year'] = data['date'].apply(year_parser)\n",
        "data['month'] = data['date'].apply(month_parser)\n",
        "\n",
        "data = data[(data['year']==2016)&(data['month']<=6)]\n",
        "data = data[data['stock_id'].isin(df.columns)]\n",
        "# data = data.fillna(0)\n",
        "\n",
        "KL = data.pivot(index='date', columns='stock_id', values='KLength')\n",
        "R = data.pivot(index='date', columns='stock_id', values='return')\n",
        "\n",
        "KL.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(121, 1863)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef10hyRW178v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "c71fd574-c934-449a-e374-d6ac66524b85"
      },
      "source": [
        "KL.isna().sum().sort_values()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "stock_id\n",
              "000020    0\n",
              "3450      0\n",
              "3419      0\n",
              "327       0\n",
              "32040     0\n",
              "         ..\n",
              "100700    0\n",
              "100660    0\n",
              "100250    0\n",
              "101490    0\n",
              "99830     0\n",
              "Length: 2018, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1CvO91HxkNB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8dde22d3-a9ef-41e8-ea0c-2c7451dd7ee3"
      },
      "source": [
        "print(KL.shape, R.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(121, 2018) (121, 2018)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHYLk-Jf2h6u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "KL = KL.iloc[:-1, ]\n",
        "R = R.iloc[1:, ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg2JtgELonzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9375fa29-d196-4307-f380-57c80aa64a9b"
      },
      "source": [
        "dtype = torch.FloatTensor\n",
        "weights = Variable(torch.rand(1, 32).type(dtype), requires_grad=True)\n",
        "lr = 0.005\n",
        "optimizer = optim.Adam([weights], lr=lr)\n",
        "epochs = 3000\n",
        "indic = np.array(KL)\n",
        "returns = np.array(R)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  loss = 0\n",
        "\n",
        "  rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "  opt_ind = torch.from_numpy(indic) * rescale_fc # element-wise\n",
        "  # print('opt_ind: ', opt_ind)\n",
        "  mean_ind = torch.mean(opt_ind, axis=0)\n",
        "  # print('mean_ind: ', mean_ind)\n",
        "  mean_ret = torch.mean(torch.from_numpy(returns), axis=0)\n",
        "  # print('mean_ret: ', mean_ret)\n",
        "\n",
        "  vx = opt_ind - mean_ind\n",
        "  vy = torch.from_numpy(returns) - mean_ret\n",
        "  # print('vx: ', vx)\n",
        "  # print('vy: ', vy)\n",
        "  loss = -torch.abs(torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2))))\n",
        "  # print('loss: ', loss)\n",
        "\n",
        "  if (epoch+1) % 100 == 0:\n",
        "    print(\"{0}th epoch in process\".format(epoch+1))\n",
        "    print('running loss: {}'.format(loss.item()))\n",
        "    print()\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward(retain_graph=False)\n",
        "  optimizer.step()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for weight in weights:\n",
        "      weight.clamp_(0,1)\n",
        "\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100th epoch in process\n",
            "running loss: -0.2413029877296743\n",
            "\n",
            "200th epoch in process\n",
            "running loss: -0.24220027865892022\n",
            "\n",
            "300th epoch in process\n",
            "running loss: -0.2433607470256074\n",
            "\n",
            "400th epoch in process\n",
            "running loss: -0.24543400677086655\n",
            "\n",
            "500th epoch in process\n",
            "running loss: -0.24583387057521544\n",
            "\n",
            "600th epoch in process\n",
            "running loss: -0.24600854653032972\n",
            "\n",
            "700th epoch in process\n",
            "running loss: -0.24611431502817757\n",
            "\n",
            "800th epoch in process\n",
            "running loss: -0.246189614892902\n",
            "\n",
            "900th epoch in process\n",
            "running loss: -0.2462489608625843\n",
            "\n",
            "1000th epoch in process\n",
            "running loss: -0.2463010816420498\n",
            "\n",
            "1100th epoch in process\n",
            "running loss: -0.24635144835720707\n",
            "\n",
            "1200th epoch in process\n",
            "running loss: -0.24640622208476395\n",
            "\n",
            "1300th epoch in process\n",
            "running loss: -0.2464809736225682\n",
            "\n",
            "1400th epoch in process\n",
            "running loss: -0.24659266764373328\n",
            "\n",
            "1500th epoch in process\n",
            "running loss: -0.24675104941482542\n",
            "\n",
            "1600th epoch in process\n",
            "running loss: -0.24691597106675583\n",
            "\n",
            "1700th epoch in process\n",
            "running loss: -0.24702813548669358\n",
            "\n",
            "1800th epoch in process\n",
            "running loss: -0.24710432097669843\n",
            "\n",
            "1900th epoch in process\n",
            "running loss: -0.24714335500514945\n",
            "\n",
            "2000th epoch in process\n",
            "running loss: -0.2471698209022594\n",
            "\n",
            "2100th epoch in process\n",
            "running loss: -0.24719539826180031\n",
            "\n",
            "2200th epoch in process\n",
            "running loss: -0.24721449987892571\n",
            "\n",
            "2300th epoch in process\n",
            "running loss: -0.2472321926648264\n",
            "\n",
            "2400th epoch in process\n",
            "running loss: -0.247246209678103\n",
            "\n",
            "2500th epoch in process\n",
            "running loss: -0.2472599573142003\n",
            "\n",
            "2600th epoch in process\n",
            "running loss: -0.2472741016119141\n",
            "\n",
            "2700th epoch in process\n",
            "running loss: -0.24728862005898816\n",
            "\n",
            "2800th epoch in process\n",
            "running loss: -0.24730347658863958\n",
            "\n",
            "2900th epoch in process\n",
            "running loss: -0.24731857934944323\n",
            "\n",
            "3000th epoch in process\n",
            "running loss: -0.2473302436858053\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.4009, 0.0000, 0.0000, 0.1772, 0.3616, 0.5250, 0.0000, 0.0000,\n",
              "         0.0000, 0.5362, 0.0000, 0.0518, 0.0000, 1.0000, 0.2056, 0.0000, 0.4593,\n",
              "         0.0000, 1.0000, 0.0000, 0.6060, 0.9208, 0.0000, 0.3253, 0.0000, 0.0000,\n",
              "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000]], requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfXGFQLcLkwr",
        "colab_type": "text"
      },
      "source": [
        "### Comparison: Raw KLength vs Rescaled KLength"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UGMCx-TLqsa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mean_KL = np.mean(indic, axis=0)\n",
        "mean_return = np.mean(returns, axis=0)\n",
        "\n",
        "vx = indic - mean_KL\n",
        "vy = returns - mean_return\n",
        "\n",
        "corr1 = np.abs(np.sum(vx*vy) / (np.sqrt(np.sum(vx ** 2)) * np.sqrt(np.sum(vy ** 2))))\n",
        "\n",
        "rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "opt_ind = torch.from_numpy(indic) * rescale_fc # element-wise\n",
        "mean_ind = torch.mean(opt_ind, axis=0)\n",
        "mean_ret = torch.mean(torch.from_numpy(returns), axis=0)\n",
        "\n",
        "wx = opt_ind - mean_ind\n",
        "wy = torch.from_numpy(returns) - mean_ret\n",
        "corr2 = torch.abs(torch.sum(wx * wy) / (torch.sqrt(torch.sum(wx ** 2)) * torch.sqrt(torch.sum(wy ** 2))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_alQ2muNTTF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f89dd32d-a36f-43c5-977a-1e73c56658bf"
      },
      "source": [
        "print(\"Correlation of Raw vs Recaled: {0:.4f} vs {1:.4f}\".format(corr1, corr2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correlation of Raw vs Recaled: 0.2428 vs 0.2473\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPaXR8mGUZaD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtqLQEz9UZcd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBvJxIItUZfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxMnV8IzSgcv",
        "colab_type": "text"
      },
      "source": [
        "### Modulate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XX8g0r5FYJ92",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "065c8a89-769e-49da-c0be-fd838109952f"
      },
      "source": [
        "path = \"/content/drive/My Drive/corr1.csv\"\n",
        "df = pd.read_csv(path)\n",
        "df = df.set_index(keys='stock_id')\n",
        "df.head()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>000020</th>\n",
              "      <th>000040</th>\n",
              "      <th>000050</th>\n",
              "      <th>000060</th>\n",
              "      <th>000070</th>\n",
              "      <th>000075</th>\n",
              "      <th>000080</th>\n",
              "      <th>000087</th>\n",
              "      <th>000100</th>\n",
              "      <th>000105</th>\n",
              "      <th>000120</th>\n",
              "      <th>000140</th>\n",
              "      <th>000145</th>\n",
              "      <th>000150</th>\n",
              "      <th>000155</th>\n",
              "      <th>000157</th>\n",
              "      <th>000180</th>\n",
              "      <th>000210</th>\n",
              "      <th>000215</th>\n",
              "      <th>000220</th>\n",
              "      <th>000225</th>\n",
              "      <th>000227</th>\n",
              "      <th>000230</th>\n",
              "      <th>000240</th>\n",
              "      <th>000250</th>\n",
              "      <th>000270</th>\n",
              "      <th>000300</th>\n",
              "      <th>000320</th>\n",
              "      <th>000325</th>\n",
              "      <th>000370</th>\n",
              "      <th>000390</th>\n",
              "      <th>000400</th>\n",
              "      <th>000430</th>\n",
              "      <th>000440</th>\n",
              "      <th>000480</th>\n",
              "      <th>000490</th>\n",
              "      <th>000500</th>\n",
              "      <th>000520</th>\n",
              "      <th>000540</th>\n",
              "      <th>000545</th>\n",
              "      <th>...</th>\n",
              "      <th>95190</th>\n",
              "      <th>95270</th>\n",
              "      <th>95340</th>\n",
              "      <th>95500</th>\n",
              "      <th>95570</th>\n",
              "      <th>95610</th>\n",
              "      <th>95660</th>\n",
              "      <th>95700</th>\n",
              "      <th>95720</th>\n",
              "      <th>95910</th>\n",
              "      <th>96040</th>\n",
              "      <th>96240</th>\n",
              "      <th>96300</th>\n",
              "      <th>96350</th>\n",
              "      <th>96530</th>\n",
              "      <th>96610</th>\n",
              "      <th>96630</th>\n",
              "      <th>96640</th>\n",
              "      <th>96760</th>\n",
              "      <th>96770</th>\n",
              "      <th>96775</th>\n",
              "      <th>96870</th>\n",
              "      <th>97230</th>\n",
              "      <th>97520</th>\n",
              "      <th>97780</th>\n",
              "      <th>97800</th>\n",
              "      <th>97870</th>\n",
              "      <th>97950</th>\n",
              "      <th>97955</th>\n",
              "      <th>98120</th>\n",
              "      <th>98460</th>\n",
              "      <th>98660</th>\n",
              "      <th>99190</th>\n",
              "      <th>99220</th>\n",
              "      <th>99320</th>\n",
              "      <th>99340</th>\n",
              "      <th>99350</th>\n",
              "      <th>99410</th>\n",
              "      <th>99440</th>\n",
              "      <th>99520</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>stock_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>000020</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.221514</td>\n",
              "      <td>-0.037755</td>\n",
              "      <td>-0.021159</td>\n",
              "      <td>0.230919</td>\n",
              "      <td>0.259171</td>\n",
              "      <td>0.176753</td>\n",
              "      <td>0.195048</td>\n",
              "      <td>0.215654</td>\n",
              "      <td>0.175516</td>\n",
              "      <td>0.208703</td>\n",
              "      <td>0.139837</td>\n",
              "      <td>0.071031</td>\n",
              "      <td>0.116629</td>\n",
              "      <td>0.085471</td>\n",
              "      <td>0.165149</td>\n",
              "      <td>0.124488</td>\n",
              "      <td>0.078928</td>\n",
              "      <td>0.049496</td>\n",
              "      <td>0.537236</td>\n",
              "      <td>0.512802</td>\n",
              "      <td>0.303855</td>\n",
              "      <td>0.483129</td>\n",
              "      <td>0.017378</td>\n",
              "      <td>0.482491</td>\n",
              "      <td>-0.072407</td>\n",
              "      <td>0.017935</td>\n",
              "      <td>0.133918</td>\n",
              "      <td>0.041311</td>\n",
              "      <td>0.148041</td>\n",
              "      <td>0.110374</td>\n",
              "      <td>0.294617</td>\n",
              "      <td>0.040400</td>\n",
              "      <td>0.118770</td>\n",
              "      <td>-0.026300</td>\n",
              "      <td>0.162403</td>\n",
              "      <td>0.135262</td>\n",
              "      <td>0.439909</td>\n",
              "      <td>0.150139</td>\n",
              "      <td>0.018031</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.019455</td>\n",
              "      <td>0.068774</td>\n",
              "      <td>0.035582</td>\n",
              "      <td>0.072378</td>\n",
              "      <td>0.177056</td>\n",
              "      <td>0.094984</td>\n",
              "      <td>0.257213</td>\n",
              "      <td>0.118036</td>\n",
              "      <td>0.061175</td>\n",
              "      <td>0.049229</td>\n",
              "      <td>-0.120927</td>\n",
              "      <td>0.027107</td>\n",
              "      <td>0.229460</td>\n",
              "      <td>0.137070</td>\n",
              "      <td>0.333912</td>\n",
              "      <td>0.253663</td>\n",
              "      <td>-0.004647</td>\n",
              "      <td>0.073918</td>\n",
              "      <td>0.436779</td>\n",
              "      <td>0.070719</td>\n",
              "      <td>0.038662</td>\n",
              "      <td>-0.009037</td>\n",
              "      <td>-0.067703</td>\n",
              "      <td>0.160585</td>\n",
              "      <td>0.272692</td>\n",
              "      <td>0.061822</td>\n",
              "      <td>0.225241</td>\n",
              "      <td>0.039099</td>\n",
              "      <td>-0.051827</td>\n",
              "      <td>0.112372</td>\n",
              "      <td>0.146558</td>\n",
              "      <td>0.079731</td>\n",
              "      <td>0.119611</td>\n",
              "      <td>0.284219</td>\n",
              "      <td>0.065122</td>\n",
              "      <td>-0.193870</td>\n",
              "      <td>-0.055491</td>\n",
              "      <td>0.170469</td>\n",
              "      <td>0.298094</td>\n",
              "      <td>0.101488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000040</th>\n",
              "      <td>0.221514</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.084175</td>\n",
              "      <td>0.125700</td>\n",
              "      <td>0.048086</td>\n",
              "      <td>0.144288</td>\n",
              "      <td>-0.026518</td>\n",
              "      <td>0.139692</td>\n",
              "      <td>0.059997</td>\n",
              "      <td>0.230597</td>\n",
              "      <td>0.052476</td>\n",
              "      <td>0.017729</td>\n",
              "      <td>0.078381</td>\n",
              "      <td>0.209605</td>\n",
              "      <td>0.249582</td>\n",
              "      <td>0.245019</td>\n",
              "      <td>0.194707</td>\n",
              "      <td>0.179482</td>\n",
              "      <td>0.216908</td>\n",
              "      <td>0.249301</td>\n",
              "      <td>0.259880</td>\n",
              "      <td>0.179810</td>\n",
              "      <td>0.216462</td>\n",
              "      <td>0.096105</td>\n",
              "      <td>0.369667</td>\n",
              "      <td>0.131545</td>\n",
              "      <td>0.340488</td>\n",
              "      <td>0.217145</td>\n",
              "      <td>-0.060981</td>\n",
              "      <td>0.220581</td>\n",
              "      <td>0.082751</td>\n",
              "      <td>0.271047</td>\n",
              "      <td>0.300337</td>\n",
              "      <td>0.120322</td>\n",
              "      <td>0.053789</td>\n",
              "      <td>0.174838</td>\n",
              "      <td>0.239307</td>\n",
              "      <td>0.215961</td>\n",
              "      <td>0.197419</td>\n",
              "      <td>0.051451</td>\n",
              "      <td>...</td>\n",
              "      <td>0.268494</td>\n",
              "      <td>0.198407</td>\n",
              "      <td>0.206406</td>\n",
              "      <td>0.414345</td>\n",
              "      <td>0.101782</td>\n",
              "      <td>0.059960</td>\n",
              "      <td>0.227716</td>\n",
              "      <td>0.063983</td>\n",
              "      <td>0.198506</td>\n",
              "      <td>0.071940</td>\n",
              "      <td>-0.059623</td>\n",
              "      <td>0.270323</td>\n",
              "      <td>0.338363</td>\n",
              "      <td>0.194589</td>\n",
              "      <td>0.144394</td>\n",
              "      <td>0.157667</td>\n",
              "      <td>0.114744</td>\n",
              "      <td>0.003995</td>\n",
              "      <td>0.296121</td>\n",
              "      <td>0.238160</td>\n",
              "      <td>0.193186</td>\n",
              "      <td>0.199345</td>\n",
              "      <td>0.176108</td>\n",
              "      <td>0.322742</td>\n",
              "      <td>0.215993</td>\n",
              "      <td>0.116542</td>\n",
              "      <td>0.265938</td>\n",
              "      <td>-0.006009</td>\n",
              "      <td>-0.078675</td>\n",
              "      <td>0.207658</td>\n",
              "      <td>0.136085</td>\n",
              "      <td>0.270371</td>\n",
              "      <td>0.137788</td>\n",
              "      <td>0.219789</td>\n",
              "      <td>0.093931</td>\n",
              "      <td>-0.145495</td>\n",
              "      <td>-0.084699</td>\n",
              "      <td>0.106058</td>\n",
              "      <td>0.374286</td>\n",
              "      <td>0.271006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000050</th>\n",
              "      <td>-0.037755</td>\n",
              "      <td>-0.084175</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.026910</td>\n",
              "      <td>0.194396</td>\n",
              "      <td>0.145192</td>\n",
              "      <td>0.064836</td>\n",
              "      <td>0.065237</td>\n",
              "      <td>0.176480</td>\n",
              "      <td>0.184645</td>\n",
              "      <td>0.139954</td>\n",
              "      <td>0.074693</td>\n",
              "      <td>-0.034289</td>\n",
              "      <td>0.035887</td>\n",
              "      <td>0.030783</td>\n",
              "      <td>-0.029888</td>\n",
              "      <td>0.065450</td>\n",
              "      <td>-0.033895</td>\n",
              "      <td>0.003912</td>\n",
              "      <td>-0.018252</td>\n",
              "      <td>-0.050283</td>\n",
              "      <td>-0.105596</td>\n",
              "      <td>0.237094</td>\n",
              "      <td>0.159021</td>\n",
              "      <td>0.055958</td>\n",
              "      <td>-0.161801</td>\n",
              "      <td>0.105222</td>\n",
              "      <td>0.147823</td>\n",
              "      <td>0.026685</td>\n",
              "      <td>0.059532</td>\n",
              "      <td>0.117234</td>\n",
              "      <td>0.064063</td>\n",
              "      <td>0.016387</td>\n",
              "      <td>-0.015661</td>\n",
              "      <td>0.142240</td>\n",
              "      <td>0.177168</td>\n",
              "      <td>-0.066760</td>\n",
              "      <td>0.106400</td>\n",
              "      <td>0.167397</td>\n",
              "      <td>0.047480</td>\n",
              "      <td>...</td>\n",
              "      <td>0.185434</td>\n",
              "      <td>0.091975</td>\n",
              "      <td>0.040803</td>\n",
              "      <td>0.066808</td>\n",
              "      <td>-0.015634</td>\n",
              "      <td>-0.007347</td>\n",
              "      <td>0.165473</td>\n",
              "      <td>0.041894</td>\n",
              "      <td>0.193574</td>\n",
              "      <td>0.004915</td>\n",
              "      <td>0.085066</td>\n",
              "      <td>0.082473</td>\n",
              "      <td>-0.012954</td>\n",
              "      <td>-0.084595</td>\n",
              "      <td>0.112413</td>\n",
              "      <td>0.189654</td>\n",
              "      <td>0.146540</td>\n",
              "      <td>-0.075025</td>\n",
              "      <td>-0.006074</td>\n",
              "      <td>0.014898</td>\n",
              "      <td>0.053050</td>\n",
              "      <td>0.100744</td>\n",
              "      <td>0.187599</td>\n",
              "      <td>0.086372</td>\n",
              "      <td>-0.100047</td>\n",
              "      <td>-0.065204</td>\n",
              "      <td>-0.016283</td>\n",
              "      <td>0.050333</td>\n",
              "      <td>0.018721</td>\n",
              "      <td>0.032135</td>\n",
              "      <td>0.194629</td>\n",
              "      <td>-0.034360</td>\n",
              "      <td>0.241911</td>\n",
              "      <td>-0.094872</td>\n",
              "      <td>0.076623</td>\n",
              "      <td>0.101066</td>\n",
              "      <td>-0.186058</td>\n",
              "      <td>0.078683</td>\n",
              "      <td>0.081244</td>\n",
              "      <td>-0.111201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000060</th>\n",
              "      <td>-0.021159</td>\n",
              "      <td>0.125700</td>\n",
              "      <td>-0.026910</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.178085</td>\n",
              "      <td>0.176415</td>\n",
              "      <td>0.025524</td>\n",
              "      <td>0.103304</td>\n",
              "      <td>0.094681</td>\n",
              "      <td>0.087511</td>\n",
              "      <td>0.031110</td>\n",
              "      <td>0.115337</td>\n",
              "      <td>0.369805</td>\n",
              "      <td>0.158645</td>\n",
              "      <td>0.135941</td>\n",
              "      <td>0.104001</td>\n",
              "      <td>0.026601</td>\n",
              "      <td>0.296269</td>\n",
              "      <td>0.305429</td>\n",
              "      <td>0.199097</td>\n",
              "      <td>0.127579</td>\n",
              "      <td>0.156409</td>\n",
              "      <td>-0.046473</td>\n",
              "      <td>0.031214</td>\n",
              "      <td>0.126763</td>\n",
              "      <td>0.006368</td>\n",
              "      <td>0.272023</td>\n",
              "      <td>0.066901</td>\n",
              "      <td>0.042691</td>\n",
              "      <td>0.142887</td>\n",
              "      <td>0.253146</td>\n",
              "      <td>0.276613</td>\n",
              "      <td>0.158297</td>\n",
              "      <td>0.213465</td>\n",
              "      <td>0.280961</td>\n",
              "      <td>0.082161</td>\n",
              "      <td>0.054212</td>\n",
              "      <td>0.177353</td>\n",
              "      <td>0.171967</td>\n",
              "      <td>0.140361</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.016416</td>\n",
              "      <td>0.065066</td>\n",
              "      <td>0.113294</td>\n",
              "      <td>0.249084</td>\n",
              "      <td>0.048593</td>\n",
              "      <td>0.146570</td>\n",
              "      <td>0.088966</td>\n",
              "      <td>0.125445</td>\n",
              "      <td>0.113970</td>\n",
              "      <td>0.061257</td>\n",
              "      <td>-0.018510</td>\n",
              "      <td>0.115044</td>\n",
              "      <td>0.178463</td>\n",
              "      <td>0.144524</td>\n",
              "      <td>0.098360</td>\n",
              "      <td>-0.042493</td>\n",
              "      <td>0.190262</td>\n",
              "      <td>0.153143</td>\n",
              "      <td>0.129936</td>\n",
              "      <td>0.167621</td>\n",
              "      <td>0.240689</td>\n",
              "      <td>0.047773</td>\n",
              "      <td>0.158049</td>\n",
              "      <td>0.017242</td>\n",
              "      <td>0.192288</td>\n",
              "      <td>0.098559</td>\n",
              "      <td>0.234262</td>\n",
              "      <td>0.172853</td>\n",
              "      <td>0.153594</td>\n",
              "      <td>0.259511</td>\n",
              "      <td>0.211723</td>\n",
              "      <td>-0.002448</td>\n",
              "      <td>0.289181</td>\n",
              "      <td>0.101877</td>\n",
              "      <td>0.057986</td>\n",
              "      <td>0.118551</td>\n",
              "      <td>0.005246</td>\n",
              "      <td>0.018182</td>\n",
              "      <td>0.133223</td>\n",
              "      <td>0.102192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>000070</th>\n",
              "      <td>0.230919</td>\n",
              "      <td>0.048086</td>\n",
              "      <td>0.194396</td>\n",
              "      <td>0.178085</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.658519</td>\n",
              "      <td>0.103320</td>\n",
              "      <td>0.213751</td>\n",
              "      <td>0.344049</td>\n",
              "      <td>0.187832</td>\n",
              "      <td>0.215465</td>\n",
              "      <td>0.226021</td>\n",
              "      <td>0.029073</td>\n",
              "      <td>0.179910</td>\n",
              "      <td>0.198224</td>\n",
              "      <td>0.239788</td>\n",
              "      <td>0.111998</td>\n",
              "      <td>0.209418</td>\n",
              "      <td>0.262103</td>\n",
              "      <td>0.363887</td>\n",
              "      <td>0.244465</td>\n",
              "      <td>0.167201</td>\n",
              "      <td>0.351404</td>\n",
              "      <td>0.071581</td>\n",
              "      <td>0.286885</td>\n",
              "      <td>-0.196303</td>\n",
              "      <td>0.235813</td>\n",
              "      <td>0.029320</td>\n",
              "      <td>0.166511</td>\n",
              "      <td>0.166894</td>\n",
              "      <td>0.243878</td>\n",
              "      <td>0.293949</td>\n",
              "      <td>0.183960</td>\n",
              "      <td>0.070419</td>\n",
              "      <td>0.150535</td>\n",
              "      <td>0.236201</td>\n",
              "      <td>0.186679</td>\n",
              "      <td>0.268939</td>\n",
              "      <td>0.107885</td>\n",
              "      <td>0.221739</td>\n",
              "      <td>...</td>\n",
              "      <td>0.086512</td>\n",
              "      <td>0.061532</td>\n",
              "      <td>0.316266</td>\n",
              "      <td>0.349720</td>\n",
              "      <td>0.142874</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>0.209065</td>\n",
              "      <td>0.102978</td>\n",
              "      <td>0.225892</td>\n",
              "      <td>0.154792</td>\n",
              "      <td>0.045589</td>\n",
              "      <td>0.165668</td>\n",
              "      <td>0.190191</td>\n",
              "      <td>0.218450</td>\n",
              "      <td>0.419458</td>\n",
              "      <td>0.131596</td>\n",
              "      <td>0.184579</td>\n",
              "      <td>-0.002406</td>\n",
              "      <td>0.238212</td>\n",
              "      <td>0.260696</td>\n",
              "      <td>0.303336</td>\n",
              "      <td>0.166971</td>\n",
              "      <td>0.270145</td>\n",
              "      <td>0.037941</td>\n",
              "      <td>0.070925</td>\n",
              "      <td>0.016534</td>\n",
              "      <td>0.340569</td>\n",
              "      <td>0.391450</td>\n",
              "      <td>0.142830</td>\n",
              "      <td>0.272069</td>\n",
              "      <td>0.212578</td>\n",
              "      <td>-0.019304</td>\n",
              "      <td>0.206811</td>\n",
              "      <td>0.078945</td>\n",
              "      <td>0.159574</td>\n",
              "      <td>-0.169755</td>\n",
              "      <td>0.011747</td>\n",
              "      <td>0.007348</td>\n",
              "      <td>0.377866</td>\n",
              "      <td>-0.103425</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1863 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            000020    000040    000050  ...     99410     99440     99520\n",
              "stock_id                                ...                              \n",
              "000020    1.000000  0.221514 -0.037755  ...  0.170469  0.298094  0.101488\n",
              "000040    0.221514  1.000000 -0.084175  ...  0.106058  0.374286  0.271006\n",
              "000050   -0.037755 -0.084175  1.000000  ...  0.078683  0.081244 -0.111201\n",
              "000060   -0.021159  0.125700 -0.026910  ...  0.018182  0.133223  0.102192\n",
              "000070    0.230919  0.048086  0.194396  ...  0.007348  0.377866 -0.103425\n",
              "\n",
              "[5 rows x 1863 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R23IaMjdYJ6z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "3a9495f8-3d9d-4bb7-caa6-bbf65025ac7e"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/My Drive/stocks.csv\")\n",
        "data.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>stock_id</th>\n",
              "      <th>name</th>\n",
              "      <th>date</th>\n",
              "      <th>opening_price</th>\n",
              "      <th>highest_price</th>\n",
              "      <th>lowest_price</th>\n",
              "      <th>closing_price</th>\n",
              "      <th>trading_volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-04</td>\n",
              "      <td>8130</td>\n",
              "      <td>8150</td>\n",
              "      <td>7920</td>\n",
              "      <td>8140</td>\n",
              "      <td>281440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-05</td>\n",
              "      <td>8040</td>\n",
              "      <td>8250</td>\n",
              "      <td>8000</td>\n",
              "      <td>8190</td>\n",
              "      <td>243179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-06</td>\n",
              "      <td>8200</td>\n",
              "      <td>8590</td>\n",
              "      <td>8110</td>\n",
              "      <td>8550</td>\n",
              "      <td>609906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-07</td>\n",
              "      <td>8470</td>\n",
              "      <td>8690</td>\n",
              "      <td>8190</td>\n",
              "      <td>8380</td>\n",
              "      <td>704752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000020</td>\n",
              "      <td>동화약품</td>\n",
              "      <td>2016-01-08</td>\n",
              "      <td>8210</td>\n",
              "      <td>8900</td>\n",
              "      <td>8130</td>\n",
              "      <td>8770</td>\n",
              "      <td>802330</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  stock_id  name        date  ...  lowest_price  closing_price  trading_volume\n",
              "0   000020  동화약품  2016-01-04  ...          7920           8140          281440\n",
              "1   000020  동화약품  2016-01-05  ...          8000           8190          243179\n",
              "2   000020  동화약품  2016-01-06  ...          8110           8550          609906\n",
              "3   000020  동화약품  2016-01-07  ...          8190           8380          704752\n",
              "4   000020  동화약품  2016-01-08  ...          8130           8770          802330\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9fv6NiqXkAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(corr_df=df, n_epochs=100, dim=32, lr=0.01):\n",
        "  dtype = torch.FloatTensor\n",
        "  epochs = n_epochs\n",
        "  emb_dim = dim\n",
        "  embeddings = Variable(torch.randn(emb_dim, len(df)).type(dtype), requires_grad=True)\n",
        "  lr = lr\n",
        "  optimizer = optim.Adam([embeddings], lr=lr)\n",
        "  mean = np.abs(df).mean().mean()\n",
        "  coef = 2 # Hyper Parameter 변경\n",
        "  loss_track = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    loss = 0\n",
        "    for i in range(len(df)):\n",
        "      v1 = embeddings[:, i].view(emb_dim, -1)\n",
        "      dist = torch.norm(v1 - embeddings, dim=0).view(len(df), 1)\n",
        "      corrs = torch.from_numpy(np.abs(coef*np.array(df.iloc[:, i]))-1).view(1, len(df)).type(torch.FloatTensor)\n",
        "      loss += torch.mm(corrs, dist)/2\n",
        "    loss_track.append(loss.item())\n",
        "    if (epoch+1) % 10 == 0:\n",
        "      print(\"{0}th epoch in process\".format(epoch+1))\n",
        "      print('running loss: {}'.format(loss.item()))\n",
        "      print()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for element in embeddings:\n",
        "        element.clamp_(0,1)\n",
        "\n",
        "  return embeddings"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lld3RXLKVGEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessing(data=data, year=2016, start_month=7, end_month = 9, corr_df = df):\n",
        "  data['KLength'] = data['closing_price'] - data['opening_price']\n",
        "  data['KUpperLength'] = data['highest_price'] - data[['opening_price', 'closing_price']].max(axis=1)\n",
        "  data['temp'] = data['opening_price']-data['lowest_price']\n",
        "  data['KLowerLength'] = data[['closing_price', 'temp']].min(axis=1)\n",
        "  data['return'] = data['closing_price'].diff()\n",
        "  data = data.drop(columns=['temp'])\n",
        "  data['stock_id'] = data['stock_id'].astype(str)\n",
        "  data['year'] = data['date'].apply(lambda x: int(x[0:4]))\n",
        "  data['month'] = data['date'].apply(lambda x: int(x[5:7]))\n",
        "  print(data.shape)\n",
        "  data = data[(data['year']==year)&(data['month']<=end_month)&(data['month']>=start_month)]\n",
        "  data = data[data['stock_id'].isin(df.columns)]\n",
        "\n",
        "  return data"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubDYEHvORXt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weight_optimize(data=data, indicator='KLength', lr=0.005, n_epochs=3000, embeddings=None):\n",
        "  KL = data.pivot(index='date', columns='stock_id', values=indicator)\n",
        "  R = data.pivot(index='date', columns='stock_id', values='return')\n",
        "\n",
        "  KL = KL.iloc[:-1, ]\n",
        "  R = R.iloc[1:, ]\n",
        "\n",
        "\n",
        "  dtype = torch.FloatTensor\n",
        "  weights = Variable(2*torch.rand(1, 32).type(dtype)-1, requires_grad=True)\n",
        "  lr = lr\n",
        "  optimizer = optim.Adam([weights], lr=lr)\n",
        "  epochs = n_epochs\n",
        "  indic = np.array(KL)\n",
        "  returns = np.array(R)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    loss = 0\n",
        "\n",
        "    rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "    opt_ind = torch.from_numpy(indic) * rescale_fc # element-wise\n",
        "  # print('opt_ind: ', opt_ind)\n",
        "    mean_ind = torch.mean(opt_ind, axis=0)\n",
        "  # print('mean_ind: ', mean_ind)\n",
        "    mean_ret = torch.mean(torch.from_numpy(returns), axis=0)\n",
        "  # print('mean_ret: ', mean_ret)\n",
        "\n",
        "    vx = opt_ind - mean_ind\n",
        "    vy = torch.from_numpy(returns) - mean_ret\n",
        "  # print('vx: ', vx)\n",
        "  # print('vy: ', vy)\n",
        "    loss = -torch.abs(torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2))))\n",
        "  # print('loss: ', loss)\n",
        "\n",
        "    if (epoch+1) % 1000 == 0:\n",
        "      print(\"{0}th epoch in process\".format(epoch+1))\n",
        "      print('running loss: {:.4f}'.format(loss.item()))\n",
        "      print()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward(retain_graph=False)\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for weight in weights:\n",
        "        weight.clamp_(0,1)\n",
        "\n",
        "  mean_KL = np.mean(indic, axis=0)\n",
        "  mean_return = np.mean(returns, axis=0)\n",
        "\n",
        "  vx = indic - mean_KL\n",
        "  vy = returns - mean_return\n",
        "\n",
        "  corr1 = np.abs(np.sum(vx*vy) / (np.sqrt(np.sum(vx ** 2)) * np.sqrt(np.sum(vy ** 2))))\n",
        "\n",
        "  rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "  opt_ind = torch.from_numpy(indic) * rescale_fc # element-wise\n",
        "  mean_ind = torch.mean(opt_ind, axis=0)\n",
        "  mean_ret = torch.mean(torch.from_numpy(returns), axis=0)\n",
        "\n",
        "  wx = opt_ind - mean_ind\n",
        "  wy = torch.from_numpy(returns) - mean_ret\n",
        "  corr2 = torch.abs(torch.sum(wx * wy) / (torch.sqrt(torch.sum(wx ** 2)) * torch.sqrt(torch.sum(wy ** 2))))\n",
        "\n",
        "  print(\"Correlation of Raw vs Recaled: {0:.4f} vs {1:.4f}\".format(corr1, corr2))\n",
        "\n",
        "  return weights"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXjUlAuCMI-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(data=None, weights=None, indicator='KLength'):\n",
        "  KL = data.pivot(index='date', columns='stock_id', values=indicator)\n",
        "  R = data.pivot(index='date', columns='stock_id', values='return')\n",
        "  KL = KL.iloc[:-1, ]\n",
        "  R = R.iloc[1:, ]\n",
        "  indic = np.array(KL)\n",
        "  returns = np.array(R)\n",
        "  mean_KL = np.mean(indic, axis=0)\n",
        "  mean_return = np.mean(returns, axis=0)\n",
        "  vx = indic - mean_KL\n",
        "  vy = returns - mean_return\n",
        "  corr1 = np.abs(np.sum(vx*vy) / (np.sqrt(np.sum(vx ** 2)) * np.sqrt(np.sum(vy ** 2))))\n",
        "\n",
        "  rescale_fc = torch.exp(torch.mm(weights, embeddings)) / torch.sum(torch.exp(torch.mm(weights, embeddings)))\n",
        "  opt_ind = torch.from_numpy(indic) * rescale_fc\n",
        "  mean_ind = torch.mean(opt_ind, axis=0)\n",
        "\n",
        "  wx = opt_ind - mean_ind\n",
        "  wy = torch.from_numpy(vy)\n",
        "  corr2 = torch.abs(torch.sum(wx * wy) / (torch.sqrt(torch.sum(wx ** 2)) * torch.sqrt(torch.sum(wy ** 2))))\n",
        "\n",
        "  print(\"Correlation of Raw vs Recaled: {0:.4f} vs {1:.4f}\".format(corr1, corr2))"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "va26WZ4fYSVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings = get_embeddings(corr_df=df)\n",
        "test_df = preprocessing(data=data, year=2016, start_month=7, end_month=9, corr_df=df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNRuR3rP2Etb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e62c65c-68d2-4784-aa4c-354f65f4fed4"
      },
      "source": [
        "train_df = preprocessing(data=data, year=2016, start_month=1, end_month=6, corr_df=df)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2108533, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9qtVNoaNlOt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "96a23fd1-7eee-47bf-a1e8-ea091e4199ac"
      },
      "source": [
        "inds = weight_optimize(indicator='KUpperLength', data=train_df, embeddings=embeddings, n_epochs=1000)\n",
        "test(data=test_df, weights=inds, indicator='KUpperLength')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000th epoch in process\n",
            "running loss: -0.2500\n",
            "\n",
            "Correlation of Raw vs Recaled: 0.2464 vs 0.2500\n",
            "Correlation of Raw vs Recaled: 0.0439 vs 0.0481\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-s4Bhj2sSr5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "e81fd1b9-70a6-44a4-9400-befcfa89e98d"
      },
      "source": [
        "inds = weight_optimize(indicator='KLength', data=train_df, embeddings=embeddings, n_epochs=3000)\n",
        "test(data=test_df, weights=inds, indicator='KLength')"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000th epoch in process\n",
            "running loss: -0.2479\n",
            "\n",
            "2000th epoch in process\n",
            "running loss: -0.2480\n",
            "\n",
            "3000th epoch in process\n",
            "running loss: -0.2480\n",
            "\n",
            "Correlation of Raw vs Recaled: 0.2429 vs 0.2480\n",
            "Correlation of Raw vs Recaled: 0.0216 vs 0.0314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jcZSJPCTMZW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "20103227-b5f9-4011-bacd-8092c125dec4"
      },
      "source": [
        "inds = weight_optimize(indicator='KLowerLength', lr=0.005, n_epochs=500, embeddings=embeddings, data=train_df)\n",
        "test(data=test_df, weights=inds, indicator='KLowerLength')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correlation of Raw vs Recaled: 0.0300 vs 0.0673\n",
            "Correlation of Raw vs Recaled: 0.0374 vs 0.0289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gahKKo8mYCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fw3BYbvc0er4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}